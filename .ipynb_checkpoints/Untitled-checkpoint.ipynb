{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9098c1-6d6e-4dbc-aa1a-9744f2255890",
   "metadata": {},
   "source": [
    "# –ù–∞—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –¥–∏–ø–ª–æ–º–∞ –Ω–∞ —Ç–µ–º—É \"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b129c-7acc-4f4a-a941-5bb075e3adf4",
   "metadata": {},
   "source": [
    "## –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed01eca-110e-41b3-9c0e-3b3641007bc3",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑ —Å–ª–æ–µ–≤:\n",
    "- –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π\n",
    "- –°–≤–µ—Ä—Ç–æ—á–Ω—ã–π\n",
    "- –†–µ–∫—É—Ä–µ–Ω—Ç–Ω—ã–π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8cd352-6d82-4fc4-9346-9bc25d7fa331",
   "metadata": {},
   "source": [
    "### –î–∞—Ç–∞—Å–µ—Ç—ã:\n",
    "- –£—Ä–∞–≤–Ω–µ–Ω–∏–µ –ú–∞–∫–∫–µ—è-–ì–ª–∞—Å—Å–∞ (–≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è)\n",
    "- Daily Sunspots Dataset (–≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è)\n",
    "- Forest Fires Data Set (–≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å—Ü–µ–Ω–∞—Ä–∏—è —Å –≤—ã—Å–æ–∫–æ–π –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å—é –∏ —à—É–º–æ–º)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc921f-b60f-4530-8a75-6578634e4d1a",
   "metadata": {},
   "source": [
    "\n",
    "–£—Ä–∞–≤–Ω–µ–Ω–∏–µ –ú–∞–∫–∫–µ—è-–ì–ª–∞—Å—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ö–∞–æ—Ç–∏—á–µ—Å–∫–∏—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤:\n",
    "\n",
    "$$\n",
    "\\frac{dx(t)}{dt} = \\frac{\\beta x(t - \\tau)}{1 + x(t - \\tau)^n} - \\gamma x(t)\n",
    "$$\n",
    "\n",
    "–≥–¥–µ:\n",
    "\n",
    "- $x(t)$ ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –≤ –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ $t$\n",
    "- $\\beta$, $\\gamma$, $n$, $\\tau$ ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—â–µ –≤—Å–µ–≥–æ –ø—Ä–∏–≤–æ–¥—è—Ç—Å—è –≤ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ:\n",
    "\n",
    "- $\\beta = 0.2$\n",
    "- $\\gamma = 0.1$\n",
    "- $n = 10$\n",
    "- $\\tau = 17$ (—Ç–∞–∫ –∂–µ –ø–æ–ø—Ä–æ–±—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ 30)\n",
    "\n",
    "–î–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è —É—Ä–∞–≤–Ω–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ –≠–π–ª–µ—Ä–∞:\n",
    "1) –ó–∞–¥–∞–µ–º —à–∞–≥ dt –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–¥–µ—Ä–∂–∫—É $\\tau$ –≤ –∫–æ–ª-–≤–æ —à–∞–≥–æ–≤: $tau\\_steps = \\tau/dt$\n",
    "2) –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ tau_steps –∑–Ω–∞—á–µ–Ω–∏–π x (–ª—É—á—à–µ –≤—Å–µ–≥–æ —Ä–∞–≤–Ω—ã–º–∏ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é —Å –Ω–µ–±–æ–ª—å—à–∏–º —à—É–º–æ–º).\n",
    "3) –î–ª—è –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞ ùë° ‚â• tau_steps –≤—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —Ñ–æ—Ä–º—É–ª–µ:\n",
    "$$\n",
    "x[t] = x[t-1] + dt \\left( \\frac{\\beta \\, x[t-tau\\_steps]}{1 + x[t-tau\\_steps]^n} - \\gamma \\, x[t-1] \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c02e400-06a8-4002-802d-dec69ce42958",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1060640044.py, line 26)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"units\": 64 # int\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "chromosome = [\n",
    "    {\n",
    "        \"layer\": \"Dense\",\n",
    "        \"units\": 256, # int\n",
    "        \"activation\": 'relu', # relu, sigmoid, softmax, tanh\n",
    "        \"kernel_regularizer\": 'L1', # L1, L2, L1L2\n",
    "        \"coef_regularizer\": [0.01, 0.02], # [L1, L2] - int, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    },\n",
    "#\"\"\"    \n",
    "#  –¢—É—Ç –ø–æ—è–≤–∏–ª–∞—Å—å –∏–¥–µ—è –æ–± –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã—Ö RNN, –Ω–æ —ç—Ç–æ –ø–æ—Ç–æ–º\n",
    "#  {\n",
    "#        \"layer\": \"RNN\",\n",
    "#        \"cells\":[ # SimpleRNNCell, LSTMCell, GRUCell\n",
    "#            { \n",
    "#                \"cell\": \"LSTMcell\"\n",
    "#            },\n",
    "#            {\n",
    "#                \"cell\": \"GRUcell\"\n",
    "#            }\n",
    "#        ]\n",
    "#    },\n",
    "#\"\"\"\n",
    "    {\n",
    "        \"layer\": \"RNN\",\n",
    "        # cell - SimpleRNNCell\n",
    "        \"units\": 64 # int\n",
    "        # return_sequences=True –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ–π ‚Äî —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π (LSTM, GRU, RNN, Conv1D) \n",
    "        # return_sequences=False –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ–π - Dense\n",
    "        # 'return_state' –¥—É–º–∞—é –ø—É—Å–∫–∞–π –æ—Å—Ç–∞–µ—Ç—Å—è False\n",
    "        # 'go_backwards': False # –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç False, —Ç. –∫. –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä bidirectional, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–±—ã—á–Ω–æ –ª—É—á—à–µ —á–µ–º go_backwards\n",
    "        'bidirectional': False # True / False\n",
    "        'stateful': True # True / False\n",
    "        # unroll: False\n",
    "        # time_major True, –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç —Ñ–æ—Ä–º–∞—Ç [time, batch, features].\n",
    "        # time_major False (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), —Ñ–æ—Ä–º–∞—Ç [batch, time, features].\n",
    " \n",
    "        \"activation\": 'relu', # relu, sigmoid, softmax, tanh\n",
    "        'dropout': 0 # float –î–æ–ª—è —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —é–Ω–∏—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (–º–µ–∂–¥—É 0 –∏ 1).\n",
    "        \"kernel_regularizer\": 'L1', # L1, L2, L1L2\n",
    "        \"coef_regularizer\": [0.01, 0.02], # [L1, L2] - int, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    },\n",
    "    # LSTM –ø–æ–∫–∞ –Ω–µ—Ç, –Ω–æ –µ—Å–ª–∏ —á—Ç–æ - –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å (—É–∂ —Ç—è–∂–µ–ª–∞—è –æ–Ω–∞ —Å–ª–∏—à–∫–æ–º)\n",
    "    {\n",
    "        \"layer\": \"GRU\",\n",
    "        \"units\": 64, # int\n",
    "        # return_sequences=True –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ–π ‚Äî —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π (LSTM, GRU, RNN, Conv1D) \n",
    "        # return_sequences=False –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ–π - Dense\n",
    "        # 'return_state' –¥—É–º–∞—é –ø—É—Å–∫–∞–π –æ—Å—Ç–∞–µ—Ç—Å—è False\n",
    "        # 'go_backwards': False # –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç False, —Ç. –∫. –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä bidirectional, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–±—ã—á–Ω–æ –ª—É—á—à–µ —á–µ–º go_backwards\n",
    "        'bidirectional': False # True / False\n",
    "        'stateful': True # True / False —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ (—Ç—Ä–µ–±—É–µ—Ç —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ batch_size).\n",
    "        # unroll: False\n",
    "        # time_major True, –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç —Ñ–æ—Ä–º–∞—Ç [time, batch, features].\n",
    "        # time_major False (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), —Ñ–æ—Ä–º–∞—Ç [batch, time, features].\n",
    "        \"activation\": 'relu', # relu, sigmoid, softmax, tanh\n",
    "        # recurrent_activation –ø—É—Å—Ç—å –æ—Å—Ç–∞–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é sigmoid\n",
    "        'dropout': 0 # float –î–æ–ª—è —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —é–Ω–∏—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (–º–µ–∂–¥—É 0 –∏ 1).\n",
    "        \"kernel_regularizer\": 'L1', # L1, L2, L1L2\n",
    "        \"coef_regularizer\": [0.01, 0.02], # [L1, L2] - int, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    },\n",
    "    {\n",
    "        \"layer\": \"Conv1D\",\n",
    "        'filters': 32, # int\n",
    "        'kernel_size': 3, # int\n",
    "        #'strides' : 1 –ü–æ–∫–∞ —á—Ç–æ –ø—É—Å–∫–∞–π –±—É–¥–µ—Ç 1, –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ –ø—Ä–∏–¥—É–º–∞—Ç—å —á—Ç–æ-—Ç–æ –ø–æ —Ç–∏–ø—É —Ç–æ–≥–æ, —á—Ç–æ —Å—Ç—Ä–∞–π–¥ –º–µ–Ω—å—à–µ –æ–∫–Ω–∞\n",
    "        # padding –ü—É—Å–∫–∞–π –ø–æ–∫–∞ –±—É–¥–µ—Ç –≤–µ–∑–¥–µ valid\n",
    "        \"activation\": 'relu', # relu, sigmoid, softmax, tanh\n",
    "        # dilation_rate –ü–æ–∫–∞ –±—É–¥–µ—Ç 1\n",
    "        \"kernel_regularizer\": 'L1', # L1, L2, L1L2\n",
    "        \"coef_regularizer\": [0.01, 0.02], # [L1, L2] - int, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "        # groups 1\n",
    "        # data_format 'channels_last' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é): [batch, steps, channels].\n",
    "        # data_format 'channels_first': [batch, channels, steps].\n",
    "    }\n",
    "    # Conv2D –ø–æ–∫–∞ –Ω–µ—Ç\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd291b60-082d-49ae-a5cd-2d9f6c8e6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_mackey_glass(beta=0.2, gamma=0.1, n=10, tau=17, dt=0.1, total_time=1000, burn_in_time=100):\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö–∞–æ—Ç–∏—á–µ—Å–∫–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –ø–æ —É—Ä–∞–≤–Ω–µ–Ω–∏—é –ú–∞–∫–∫–µ—è-–ì–ª–∞—Å—Å–∞\n",
    "    —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º burn-in –ø–µ—Ä–∏–æ–¥–∞ –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—á–∞–ª—å–Ω—ã—Ö —Å–∫–∞—á–∫–æ–≤.\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    - beta, gamma, n, tau: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "    - dt: —à–∞–≥ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "    - total_time: –≤—Ä–µ–º—è, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥—É—Ç —Å–æ–±—Ä–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ burn-in\n",
    "    - burn_in_time: –≤—Ä–µ–º—è –ø—Ä–æ–≥—Ä–µ–≤–∞, –¥–∞–Ω–Ω—ã–µ –∑–∞ –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è (–∏–Ω–∞—á–µ –Ω–∞—á–∞–ª–æ —Ä—è–¥–∞ –±—É–¥–µ—Ç —Å–ª–∏—à–∫–æ–º —Ö–∞–æ—Ç–∏—á–Ω—ã–º)\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    - t_axis: –≤—Ä–µ–º–µ–Ω–Ω–∞—è –æ—Å—å –¥–ª—è –∑–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    - x: –º–∞—Å—Å–∏–≤ –∑–Ω–∞—á–µ–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "    \"\"\"\n",
    "    total_steps = int((total_time + burn_in_time) / dt)\n",
    "    burn_in_steps = int(burn_in_time / dt)\n",
    "    tau_steps = int(tau / dt)\n",
    "    \n",
    "    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–≤–Ω–æ–≤–µ—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ x0\n",
    "    x0 = ((beta / gamma) - 1)**(1/n)  # –Ω—É–∂–Ω–æ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏, –±–ª–∏–∑–∫–∏–º–∏ –∫ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é\n",
    "    \n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞: –ø–µ—Ä–≤—ã–µ tau_steps –∑–∞–¥–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ–º x0 —Å –Ω–µ–±–æ–ª—å—à–∏–º —à—É–º–æ–º\n",
    "    x = np.zeros(total_steps)\n",
    "    x[:tau_steps] = x0 + 0.01 * np.random.randn(tau_steps)\n",
    "    \n",
    "    # –°–∏–º—É–ª—è—Ü–∏—è —É—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–º –≠–π–ª–µ—Ä–∞\n",
    "    for t in range(tau_steps, total_steps):\n",
    "        dx = dt * (beta * x[t - tau_steps] / (1 + x[t - tau_steps]**n) - gamma * x[t - 1])\n",
    "        x[t] = x[t - 1] + dx\n",
    "\n",
    "    \n",
    "    # –û—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—Ä–µ–º—è –ø—Ä–æ–≥—Ä–µ–≤–∞\n",
    "    x = x[burn_in_steps:]\n",
    "    t_axis = np.linspace(0, total_time, len(x))\n",
    "    \n",
    "    return t_axis, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3e2a068-2f60-463e-bc4b-5769e2ff659b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "t, x = generate_mackey_glass(\n",
    "    beta=0.2, \n",
    "    gamma=0.1, \n",
    "    n=10, \n",
    "    tau=17, \n",
    "    dt=0.1, \n",
    "    total_time=1000, \n",
    "    burn_in_time=100\n",
    ")\n",
    "\n",
    "# –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t, x, label=\"Mackey-Glass\")\n",
    "plt.xlabel(\"–í—Ä–µ–º—è\")\n",
    "plt.ylabel(\"x(t)\")\n",
    "plt.title(\"–•–∞–æ—Ç–∏—á–µ—Å–∫–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –ø–æ —É—Ä–∞–≤–Ω–µ–Ω–∏—é –ú–∞–∫–∫–µ—è-–ì–ª–∞—Å—Å–∞\\n(–ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ–≤–∞)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe63e43-ba2c-46e4-96a1-692f6b92bbc8",
   "metadata": {},
   "source": [
    "# Daily Sunspots Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d856c16-583f-4e51-b07e-2c34fdd1c16d",
   "metadata": {},
   "source": [
    "—Å—Å—ã–ª–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç: https://www.kaggle.com/datasets/patrickfleith/daily-sunspots-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6d9820-4003-429f-978f-470214811642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: –ö–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ + —Ä–∞–∑–≤–µ–¥—ã–≤–∞—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de9c952-4935-418b-9a7d-535e5c26774a",
   "metadata": {},
   "source": [
    "# Forest Fires Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687dde50-05e4-49f6-9a8a-f48f9da755f1",
   "metadata": {},
   "source": [
    "—Å—Å—ã–ª–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç: https://www.kaggle.com/datasets/elikplim/forest-fires-data-set/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431524e6-1e47-47fb-ad6e-53fac2ba5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: –ö–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ + —Ä–∞–∑–≤–µ–¥—ã–≤–∞—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b639ca57-0afb-489d-960c-df58f4f2bee2",
   "metadata": {},
   "source": [
    "# –ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5742cf-9011-4614-b5c0-5a9a820c0af1",
   "metadata": {},
   "source": [
    "## –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ —Ö—Ä–æ–º–æ—Å–æ–º—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03df72be-9659-4a25-9d0d-149941b197b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 14:39:36.477684: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746617976.608506    1881 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746617976.643370    1881 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746617976.928487    1881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746617976.928528    1881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746617976.928530    1881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746617976.928531    1881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-07 14:39:36.958725: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –º–æ–¥–µ–ª—å Keras\n",
    "def build_model(chromosome): # –í–∏–¥ —Ö—Ä–æ–º–æ—Å–æ–º—ã: [[—Ç–∏–ø_—Å–ª–æ—è, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã...], [—Ç–∏–ø_—Å–ª–æ—è, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã...]...]\n",
    "    model = Sequential()\n",
    "    i = 0\n",
    "    \n",
    "    for layer in chromosome:\n",
    "        # Dense [... 0, units, activation, ...]\n",
    "        if layer[0] == 0:  # Dense\n",
    "            units = layer[1]\n",
    "            activation = layer[2]\n",
    "            model.add(Dense(units, activation=activation))\n",
    "        # TODO: RNN, GRU, LSTM, Conv1D\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c549edf-4627-4cb0-b052-fbc2c86d299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: –†–∞—Å–ø–∏—Å–∞—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b449934f-560b-4d50-b20d-543a286770cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GRU, SimpleRNN, Flatten, GlobalAveragePooling1D, Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cacc0877-c6fd-4641-8fc5-fcc625ac0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def random_RNN_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'RNN'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3, 0.4])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False]) if not layer['bidirectional'] else False\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "def random_GRU_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'GRU'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    \n",
    "    layer['activation'] = random.choice(['tanh', 'relu', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False]) if not layer['bidirectional'] else False\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_Conv1D_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'Conv1D'\n",
    "    layer['filters'] = random.choice([])\n",
    "    layer['kernel_size'] = random.choice([])\n",
    "    layer['activation'] = random.choice(['tanh', 'relu', 'sigmoid'])\n",
    "    \n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [ 0.0001, 0.001, 0.01, 0.1 ]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_Conv1D_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'Conv1D'\n",
    "    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "    layer['strides'] = random.choice([1, 2])\n",
    "    layer['padding'] = random.choice(['valid', 'same'])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid', None])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dilation_rate'] = random.choice([1, 2])\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc0d797-323e-4734-8aca-ce79f2b90926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_layer():\n",
    "    layer_type = random.choice([\n",
    "        'dense', 'conv1d', 'gru', 'rnn',\n",
    "        'flatten', 'global_avg_pooling1d'\n",
    "    ])\n",
    "        \n",
    "    if layer_type == 'dense':\n",
    "        return random_dense_layer()\n",
    "\n",
    "    elif layer_type == 'conv1d':\n",
    "        return random_Conv1D_layer()\n",
    "        \n",
    "    elif layer_type == 'gru':\n",
    "        return random_GRU_layer()\n",
    "\n",
    "    elif layer_type == 'rnn':\n",
    "        return random_RNN_layer()\n",
    "        \n",
    "    return {'layer':layer_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00bc4ea-f39a-4fa8-8812-daafd2472769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_population(pop_size, min_layers=3, max_layers=6):\n",
    "    population = []\n",
    "    \n",
    "    for _ in range(pop_size):\n",
    "        # –°–ª—É—á–∞–π–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤\n",
    "        num_layers = random.randint(min_layers, max_layers)\n",
    "        \n",
    "        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–µ–≤\n",
    "        genome = []\n",
    "        for _ in range(num_layers):\n",
    "            layer = create_random_layer()\n",
    "            \n",
    "            # –£—Å–ª–æ–≤–∏—è –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π\n",
    "            if layer['layer'] in ['flatten', 'global_avg_pooling1d']:\n",
    "                # –†–∞–∑–º–µ—â–∞–µ–º —ç—Ç–∏ —Å–ª–æ–∏ –≤ –∫–æ–Ω—Ü–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å —à–∞–Ω—Å–æ–º 0.7 \n",
    "                if random.random() < 0.7:\n",
    "                    genome.append(layer)\n",
    "                    break  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            genome.append(layer)\n",
    "        \n",
    "        population.append(genome)\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99624e-d77b-485b-94c4-c6afdc5533a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–ª–≥–æ—Ä–∏—Ç–º–∞\n",
    "POPULATION_SIZE = 20\n",
    "GENERATIONS = 10\n",
    "TOURNAMENT_SIZE = 3\n",
    "MUTATION_RATE = 0.2\n",
    "ELITE_SIZE = 2\n",
    "EPOCHS = 5\n",
    "    \n",
    "\n",
    "\n",
    "def generate_population(pop_size):\n",
    "    return [[create_random_layer() for _ in range(random.randint(2, 5))] \n",
    "            for _ in range(pop_size)]\n",
    "\n",
    "def build_model(genome, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    for layer_config in genome:\n",
    "        if layer_config['type'] == 'dense':\n",
    "            model.add(Dense(units=layer_config['units'], \n",
    "                          activation=layer_config['activation']))\n",
    "            \n",
    "        elif layer_config['type'] == 'conv1d':\n",
    "            model.add(Conv1D(filters=layer_config['filters'],\n",
    "                          kernel_size=layer_config['kernel_size'],\n",
    "                          activation=layer_config['activation']))\n",
    "            \n",
    "        elif layer_config['type'] == 'gru':\n",
    "            model.add(GRU(units=layer_config['units'],\n",
    "                        activation=layer_config['activation']))\n",
    "            \n",
    "        elif layer_config['type'] == 'rnn':\n",
    "            model.add(SimpleRNN(units=layer_config['units'],\n",
    "                              activation=layer_config['activation']))\n",
    "            \n",
    "        elif layer_config['type'] == 'flatten':\n",
    "            model.add(Flatten())\n",
    "            \n",
    "        elif layer_config['type'] == 'global_avg_pooling1d':\n",
    "            model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def evaluate(genome, X_train, y_train, X_val, y_val, input_shape):\n",
    "    try:\n",
    "        model = build_model(genome, input_shape)\n",
    "        history = model.fit(X_train, y_train,\n",
    "                          epochs=EPOCHS,\n",
    "                          validation_data=(X_val, y_val),\n",
    "                          verbose=0)\n",
    "        return history.history['val_loss'][-1]\n",
    "    except:\n",
    "        return float('inf')\n",
    "\n",
    "def mutate(genome):\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        if len(genome) > 1 and random.random() < 0.3:\n",
    "            del genome[random.randint(0, len(genome)-1)]\n",
    "            \n",
    "    if random.random() < MUTATION_RATE:\n",
    "        genome.insert(random.randint(0, len(genome)), create_random_layer())\n",
    "        \n",
    "    for layer in genome:\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            if layer['type'] in ['dense', 'gru', 'rnn']:\n",
    "                layer['units'] = random.choice([32, 64, 128, 256])\n",
    "            elif layer['type'] == 'conv1d':\n",
    "                layer['filters'] = random.choice([32, 64, 128])\n",
    "                layer['kernel_size'] = random.choice([3, 5, 7])\n",
    "                \n",
    "    return genome\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    min_length = min(len(parent1), len(parent2))\n",
    "    crossover_point = random.randint(1, min_length-1)\n",
    "    return parent1[:crossover_point] + parent2[crossover_point:]\n",
    "\n",
    "def select_parent(population, fitness):\n",
    "    tournament = random.sample(list(zip(population, fitness)), TOURNAMENT_SIZE)\n",
    "    tournament.sort(key=lambda x: x[1])\n",
    "    return tournament[0][0]\n",
    "\n",
    "def genetic_algorithm(X_train, y_train, X_val, y_val, input_shape):\n",
    "    population = generate_population(POPULATION_SIZE)\n",
    "    \n",
    "    for generation in range(GENERATIONS):\n",
    "        fitness = [evaluate(genome, X_train, y_train, X_val, y_val, input_shape)\n",
    "                  for genome in population]\n",
    "        \n",
    "        sorted_pop = [x for _, x in sorted(zip(fitness, population), \n",
    "                     key=lambda x: x[0])]\n",
    "        \n",
    "        new_population = sorted_pop[:ELITE_SIZE]\n",
    "        \n",
    "        while len(new_population) < POPULATION_SIZE:\n",
    "            parent1 = select_parent(population, fitness)\n",
    "            parent2 = select_parent(population, fitness)\n",
    "            child = crossover(parent1, parent2)\n",
    "            child = mutate(child)\n",
    "            new_population.append(child)\n",
    "            \n",
    "        population = new_population\n",
    "        print(f'Generation {generation+1}, Best Loss: {min(fitness):.4f}')\n",
    "    \n",
    "    best_idx = np.argmin(fitness)\n",
    "    return population[best_idx]\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "if __name__ == \"__main__\":\n",
    "    # –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
    "    # X_train, y_train, X_val, y_val, input_shape = ...\n",
    "    \n",
    "    # best_architecture = genetic_algorithm(X_train, y_train, X_val, y_val, input_shape)\n",
    "    # print(\"Best Architecture:\", best_architecture)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ced9c9-3ba5-483b-8f17-382f514c405a",
   "metadata": {},
   "source": [
    "# –ò–º–ø–æ—Ä—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024c3111-b1e5-4425-93b4-4faa104d90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GRU, SimpleRNN, Flatten, GlobalAveragePooling1D, Input\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8909713-ba4a-4da5-9d26-b2e4cdfb328a",
   "metadata": {},
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–æ–µ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "023cdb4e-5dd9-46f6-8534-8ac30be39367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "def random_dense_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'dense'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'linear'])\n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    \n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –æ–±—ã—á–Ω–æ–≥–æ —Ä–µ–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ —Å–ª–æ—è \n",
    "def random_RNN_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'RNN'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ GRU —Ä–µ–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ —Å–ª–æ—è \n",
    "def random_GRU_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'GRU'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['tanh', 'relu', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –æ–¥–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è \n",
    "def random_Conv1D_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'Conv1D'\n",
    "    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "    layer['strides'] = random.choice([1, 2])\n",
    "    layer['padding'] = random.choice(['valid', 'same'])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid', 'elu'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dilation_rate'] = random.choice([1, 2])\n",
    "    layer['max_pooling'] = random.choice([None, 2, 3])\n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è \n",
    "def create_random_layer(prev_layer=None):\n",
    "    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ª–æ–µ–≤\n",
    "    if prev_layer is None or prev_layer.get('layer') not in ['RNN', 'GRU'] or not prev_layer.get('return_sequences', False):\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    else:\n",
    "        # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–ª–æ–π - —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å return_sequences=True\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    \n",
    "    # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ flatten/pooling\n",
    "    if prev_layer and prev_layer.get('layer') in ['flatten', 'global_avg_pooling1d']:\n",
    "        layer_types = ['dense']\n",
    "        \n",
    "    layer_type = random.choice(layer_types)\n",
    "        \n",
    "    if layer_type == 'dense':\n",
    "        return random_dense_layer()\n",
    "    elif layer_type == 'conv1d':\n",
    "        return random_Conv1D_layer()\n",
    "    elif layer_type == 'gru':\n",
    "        return random_GRU_layer()\n",
    "    elif layer_type == 'rnn':\n",
    "        return random_RNN_layer()\n",
    "        \n",
    "    return {'layer': layer_type}\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "def generate_random_architecture(min_layers=2, max_layers=10):\n",
    "    num_layers = random.randint(min_layers, max_layers)\n",
    "    architecture = []\n",
    "    \n",
    "    # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π\n",
    "    prev_layer = None\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        new_layer = create_random_layer(prev_layer)\n",
    "        architecture.append(new_layer)\n",
    "        prev_layer = new_layer\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ —Å–ª–æ–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
    "        if i < num_layers - 1 and new_layer.get('layer') in ['Conv1D', 'RNN', 'GRU'] and \\\n",
    "           new_layer.get('return_sequences', True) and random.random() > 0.5:\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–π —É–ø–ª–æ—â–µ–Ω–∏—è –∏–ª–∏ –ø—É–ª–∏–Ω–≥–∞ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.5\n",
    "            flatten_type = random.choice(['flatten', 'global_avg_pooling1d'])\n",
    "            architecture.append({'layer': flatten_type})\n",
    "            prev_layer = {'layer': flatten_type}\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    architecture.append({\n",
    "        'layer': 'dense',\n",
    "        'units': 1,\n",
    "        'activation': 'linear'\n",
    "    })\n",
    "    \n",
    "    return architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d693b-c534-4d55-9068-57437a8c4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ –º–æ–¥–µ–ª—å Keras\n",
    "def architecture_to_model(architecture, input_shape):\n",
    "    model = Sequential()\n",
    "    first_layer = True\n",
    "    \n",
    "    for layer in architecture:\n",
    "        layer_type = layer['layer']\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º Input shape –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è\n",
    "        if first_layer:\n",
    "            if layer_type == 'dense':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D(input_shape=input_shape))\n",
    "                \n",
    "            first_layer = False\n",
    "            \n",
    "        else:\n",
    "            # –°–ª–æ–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ\n",
    "            if layer_type == 'dense':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten())\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "def evaluate_architecture(architecture, X_train, y_train, X_val, y_val, input_shape, epochs=50, batch_size=32):\n",
    "    try:\n",
    "        model = architecture_to_model(architecture, input_shape)\n",
    "        \n",
    "        # –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "        optimizer_choice = random.choice(['adam', 'rmsprop', 'sgd'])\n",
    "        learning_rate = random.choice([0.001, 0.01, 0.0001])\n",
    "        \n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_choice == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=learning_rate)\n",
    "        else:\n",
    "            optimizer = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        # Early stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        val_loss = min(history.history['val_loss'])  # –ë–µ—Ä–µ–º –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º —à—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏\n",
    "        num_params = model.count_params()\n",
    "        complexity_penalty = np.log(num_params) / 10.0  # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å\n",
    "        \n",
    "        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_score = val_loss + complexity_penalty\n",
    "        \n",
    "        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏\n",
    "        tf.keras.backend.clear_session()\n",
    "        del model\n",
    "        \n",
    "        return fitness_score, val_loss, num_params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {e}\")\n",
    "        return float('inf'), float('inf'), 0\n",
    "\n",
    "# –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º\n",
    "class GeneticNNOptimizer:\n",
    "    def __init__(self, input_shape, X_train, y_train, X_val, y_val, \n",
    "                 population_size=20, num_generations=10, \n",
    "                 mutation_rate=0.2, crossover_rate=0.7):\n",
    "        self.input_shape = input_shape\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.population_size = population_size\n",
    "        self.num_generations = num_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.best_architecture = None\n",
    "        self.best_fitness = float('inf')\n",
    "        self.history = []\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            architecture = generate_random_architecture()\n",
    "            population.append(architecture)\n",
    "        return population\n",
    "    \n",
    "    def evaluate_population(self, population):\n",
    "        fitness_scores = []\n",
    "        for architecture in population:\n",
    "            fitness, val_loss, num_params = evaluate_architecture(\n",
    "                architecture, \n",
    "                self.X_train, self.y_train, \n",
    "                self.X_val, self.y_val, \n",
    "                self.input_shape\n",
    "            )\n",
    "            fitness_scores.append((fitness, architecture, val_loss, num_params))\n",
    "        \n",
    "        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏—Å–ø–æ—Å–æ–±–ª–µ–Ω–Ω–æ—Å—Ç–∏ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_scores.sort(key=lambda x: x[0])\n",
    "        return fitness_scores\n",
    "    \n",
    "    def selection(self, fitness_scores):\n",
    "        # –û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –æ—Å–æ–±–µ–π (—ç–ª–∏—Ç–∏–∑–º) + —Ç—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä\n",
    "        elite_count = max(1, int(self.population_size * 0.1))  # 10% —ç–ª–∏—Ç–∏–∑–º–∞\n",
    "        selected = [score[1] for score in fitness_scores[:elite_count]]\n",
    "        \n",
    "        # –¢—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø–æ–∑–∏—Ü–∏–π\n",
    "        while len(selected) < self.population_size:\n",
    "            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ 3 –æ—Å–æ–±–∏ –¥–ª—è —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "            tournament = random.sample(fitness_scores, k=3)\n",
    "            tournament.sort(key=lambda x: x[0])\n",
    "            selected.append(tournament[0][1])  # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –∏–∑ —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def crossover(self, parent1, parent2):\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1.copy(), parent2.copy()\n",
    "        \n",
    "        # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π (–≤—ã—Ö–æ–¥–Ω–æ–π) –ø–µ—Ä–µ–¥ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ–º\n",
    "        p1 = parent1[:-1].copy()\n",
    "        p2 = parent2[:-1].copy()\n",
    "        \n",
    "        # –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ\n",
    "        if len(p1) > 1 and len(p2) > 1:\n",
    "            crossover_point1 = random.randint(1, len(p1) - 1)\n",
    "            crossover_point2 = random.randint(1, len(p2) - 1)\n",
    "            \n",
    "            child1 = p1[:crossover_point1] + p2[crossover_point2:]\n",
    "            child2 = p2[:crossover_point2] + p1[crossover_point1:]\n",
    "        else:\n",
    "            child1, child2 = p1.copy(), p2.copy()\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        output_layer = {\n",
    "            'layer': 'dense',\n",
    "            'units': 1,\n",
    "            'activation': 'linear'\n",
    "        }\n",
    "        \n",
    "        child1.append(output_layer)\n",
    "        child2.append(output_layer)\n",
    "        \n",
    "        return child1, child2\n",
    "    \n",
    "    def mutate(self, architecture):\n",
    "        if random.random() > self.mutation_rate:\n",
    "            return architecture\n",
    "        \n",
    "        # –ö–ª–æ–Ω–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –±–µ–∑ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "        arch_copy = architecture[:-1].copy()\n",
    "        output_layer = architecture[-1].copy()\n",
    "        \n",
    "        mutation_type = random.choice(['add', 'remove', 'modify'])\n",
    "        \n",
    "        if mutation_type == 'add' and len(arch_copy) < 10:\n",
    "            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            insert_position = random.randint(0, len(arch_copy))\n",
    "            if insert_position == 0:\n",
    "                new_layer = create_random_layer()\n",
    "            else:\n",
    "                new_layer = create_random_layer(arch_copy[insert_position-1])\n",
    "            arch_copy.insert(insert_position, new_layer)\n",
    "            \n",
    "        elif mutation_type == 'remove' and len(arch_copy) > 1:\n",
    "            # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            remove_position = random.randint(0, len(arch_copy) - 1)\n",
    "            arch_copy.pop(remove_position)\n",
    "            \n",
    "        elif mutation_type == 'modify' and len(arch_copy) > 0:\n",
    "            # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            modify_position = random.randint(0, len(arch_copy) - 1)\n",
    "            layer = arch_copy[modify_position]\n",
    "            \n",
    "            if layer['layer'] == 'dense':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Dense —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "                \n",
    "            elif layer['layer'] == 'Conv1D':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Conv1D —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "                \n",
    "            elif layer['layer'] in ['RNN', 'GRU']:\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–ª–æ–∏\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['return_sequences'] = random.choice([True, False])\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        arch_copy.append(output_layer)\n",
    "        return arch_copy\n",
    "    \n",
    "    def evolve(self):\n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "        population = self.initialize_population()\n",
    "        \n",
    "        for generation in range(self.num_generations):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # –û—Ü–µ–Ω–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "            fitness_scores = self.evaluate_population(population)\n",
    "            generation_best_fitness = fitness_scores[0][0]\n",
    "            generation_best_architecture = fitness_scores[0][1]\n",
    "            generation_best_val_loss = fitness_scores[0][2]\n",
    "            generation_best_params = fitness_scores[0][3]\n",
    "            \n",
    "            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "            if generation_best_fitness < self.best_fitness:\n",
    "                self.best_fitness = generation_best_fitness\n",
    "                self.best_architecture = generation_best_architecture\n",
    "            \n",
    "            # –ó–∞–ø–∏—Å—å –∏—Å—Ç–æ—Ä–∏–∏\n",
    "            self.history.append({\n",
    "                'generation': generation,\n",
    "                'best_fitness': generation_best_fitness,\n",
    "                'best_val_loss': generation_best_val_loss,\n",
    "                'best_params': generation_best_params\n",
    "            })\n",
    "            \n",
    "            # –í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n",
    "            end_time = time.time()\n",
    "            print(f\"–ü–æ–∫–æ–ª–µ–Ω–∏–µ {generation + 1}/{self.num_generations} - –õ—É—á—à–∞—è –æ—à–∏–±–∫–∞: {generation_best_val_loss:.6f}, \"\n",
    "                  f\"–§–∏—Ç–Ω–µ—Å: {generation_best_fitness:.6f}, –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {generation_best_params}, \"\n",
    "                  f\"–í—Ä–µ–º—è: {end_time - start_time:.2f} —Å–µ–∫.\")\n",
    "            \n",
    "            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ü–∏–∫–ª–∞\n",
    "            if generation == self.num_generations - 1:\n",
    "                break\n",
    "            \n",
    "            # –û—Ç–±–æ—Ä\n",
    "            selected = self.selection(fitness_scores)\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è\n",
    "            new_population = []\n",
    "            \n",
    "            # –≠–ª–∏—Ç–∏–∑–º - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –æ—Å–æ–±–∏\n",
    "            new_population.append(generation_best_architecture)\n",
    "            \n",
    "            # –°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –∏ –º—É—Ç–∞—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–π\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(selected, k=2)\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                \n",
    "                child1 = self.mutate(child1)\n",
    "                child2 = self.mutate(child2)\n",
    "                \n",
    "                new_population.append(child1)\n",
    "                if len(new_population) < self.population_size:\n",
    "                    new_population.append(child2)\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "        final_fitness_scores = self.evaluate_population(population)\n",
    "        final_best = final_fitness_scores[0]\n",
    "        \n",
    "        if final_best[0] < self.best_fitness:\n",
    "            self.best_fitness = final_best[0]\n",
    "            self.best_architecture = final_best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a783e02-cf82-44db-8dc6-b6613a6a3a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GRU, SimpleRNN, Flatten, GlobalAveragePooling1D, Input\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö —Å–ª–æ–µ–≤\n",
    "def random_dense_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'dense'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    \n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_RNN_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'RNN'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_GRU_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'GRU'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['tanh', 'relu', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_Conv1D_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'Conv1D'\n",
    "    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "    layer['strides'] = random.choice([1, 2])\n",
    "    layer['padding'] = random.choice(['valid', 'same'])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid', 'elu'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dilation_rate'] = random.choice([1, 2])\n",
    "    layer['max_pooling'] = random.choice([None, 2, 3])\n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def create_random_layer(prev_layer=None):\n",
    "    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ª–æ–µ–≤\n",
    "    if prev_layer is None or prev_layer.get('layer') not in ['RNN', 'GRU'] or not prev_layer.get('return_sequences', False):\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    else:\n",
    "        # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–ª–æ–π - —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å return_sequences=True\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    \n",
    "    # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ flatten/pooling\n",
    "    if prev_layer and prev_layer.get('layer') in ['flatten', 'global_avg_pooling1d']:\n",
    "        layer_types = ['dense']\n",
    "        \n",
    "    layer_type = random.choice(layer_types)\n",
    "        \n",
    "    if layer_type == 'dense':\n",
    "        return random_dense_layer()\n",
    "    elif layer_type == 'conv1d':\n",
    "        return random_Conv1D_layer()\n",
    "    elif layer_type == 'gru':\n",
    "        return random_GRU_layer()\n",
    "    elif layer_type == 'rnn':\n",
    "        return random_RNN_layer()\n",
    "        \n",
    "    return {'layer': layer_type}\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "def generate_random_architecture(min_layers=2, max_layers=10):\n",
    "    num_layers = random.randint(min_layers, max_layers)\n",
    "    architecture = []\n",
    "    \n",
    "    # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π\n",
    "    prev_layer = None\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        new_layer = create_random_layer(prev_layer)\n",
    "        architecture.append(new_layer)\n",
    "        prev_layer = new_layer\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ —Å–ª–æ–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
    "        if i < num_layers - 1 and new_layer.get('layer') in ['Conv1D', 'RNN', 'GRU'] and \\\n",
    "           new_layer.get('return_sequences', True) and random.random() > 0.5:\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–π —É–ø–ª–æ—â–µ–Ω–∏—è –∏–ª–∏ –ø—É–ª–∏–Ω–≥–∞ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.5\n",
    "            flatten_type = random.choice(['flatten', 'global_avg_pooling1d'])\n",
    "            architecture.append({'layer': flatten_type})\n",
    "            prev_layer = {'layer': flatten_type}\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    architecture.append({\n",
    "        'layer': 'dense',\n",
    "        'units': 1,\n",
    "        'activation': 'linear'\n",
    "    })\n",
    "    \n",
    "    return architecture\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ –º–æ–¥–µ–ª—å Keras\n",
    "def architecture_to_model(architecture, input_shape):\n",
    "    model = Sequential()\n",
    "    first_layer = True\n",
    "    \n",
    "    for layer in architecture:\n",
    "        layer_type = layer['layer']\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º Input shape –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è\n",
    "        if first_layer:\n",
    "            if layer_type == 'dense':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D(input_shape=input_shape))\n",
    "                \n",
    "            first_layer = False\n",
    "            \n",
    "        else:\n",
    "            # –°–ª–æ–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ\n",
    "            if layer_type == 'dense':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten())\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "def evaluate_architecture(architecture, X_train, y_train, X_val, y_val, input_shape, epochs=50, batch_size=32):\n",
    "    try:\n",
    "        model = architecture_to_model(architecture, input_shape)\n",
    "        \n",
    "        # –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "        optimizer_choice = random.choice(['adam', 'rmsprop', 'sgd'])\n",
    "        learning_rate = random.choice([0.001, 0.01, 0.0001])\n",
    "        \n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_choice == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=learning_rate)\n",
    "        else:\n",
    "            optimizer = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        # Early stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        val_loss = min(history.history['val_loss'])  # –ë–µ—Ä–µ–º –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º —à—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏\n",
    "        num_params = model.count_params()\n",
    "        complexity_penalty = np.log(num_params) / 10.0  # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å\n",
    "        \n",
    "        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_score = val_loss + complexity_penalty\n",
    "        \n",
    "        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏\n",
    "        tf.keras.backend.clear_session()\n",
    "        del model\n",
    "        \n",
    "        return fitness_score, val_loss, num_params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {e}\")\n",
    "        return float('inf'), float('inf'), 0\n",
    "\n",
    "# –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º\n",
    "class GeneticNNOptimizer:\n",
    "    def __init__(self, input_shape, X_train, y_train, X_val, y_val, \n",
    "                 population_size=20, num_generations=10, \n",
    "                 mutation_rate=0.2, crossover_rate=0.7):\n",
    "        self.input_shape = input_shape\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.population_size = population_size\n",
    "        self.num_generations = num_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.best_architecture = None\n",
    "        self.best_fitness = float('inf')\n",
    "        self.history = []\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            architecture = generate_random_architecture()\n",
    "            population.append(architecture)\n",
    "        return population\n",
    "    \n",
    "    def evaluate_population(self, population):\n",
    "        fitness_scores = []\n",
    "        for architecture in population:\n",
    "            fitness, val_loss, num_params = evaluate_architecture(\n",
    "                architecture, \n",
    "                self.X_train, self.y_train, \n",
    "                self.X_val, self.y_val, \n",
    "                self.input_shape\n",
    "            )\n",
    "            fitness_scores.append((fitness, architecture, val_loss, num_params))\n",
    "        \n",
    "        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏—Å–ø–æ—Å–æ–±–ª–µ–Ω–Ω–æ—Å—Ç–∏ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_scores.sort(key=lambda x: x[0])\n",
    "        return fitness_scores\n",
    "    \n",
    "    def selection(self, fitness_scores):\n",
    "        # –û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –æ—Å–æ–±–µ–π (—ç–ª–∏—Ç–∏–∑–º) + —Ç—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä\n",
    "        elite_count = max(1, int(self.population_size * 0.1))  # 10% —ç–ª–∏—Ç–∏–∑–º–∞\n",
    "        selected = [score[1] for score in fitness_scores[:elite_count]]\n",
    "        \n",
    "        # –¢—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø–æ–∑–∏—Ü–∏–π\n",
    "        while len(selected) < self.population_size:\n",
    "            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ 3 –æ—Å–æ–±–∏ –¥–ª—è —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "            tournament = random.sample(fitness_scores, k=3)\n",
    "            tournament.sort(key=lambda x: x[0])\n",
    "            selected.append(tournament[0][1])  # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –∏–∑ —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def crossover(self, parent1, parent2):\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1.copy(), parent2.copy()\n",
    "        \n",
    "        # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π (–≤—ã—Ö–æ–¥–Ω–æ–π) –ø–µ—Ä–µ–¥ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ–º\n",
    "        p1 = parent1[:-1].copy()\n",
    "        p2 = parent2[:-1].copy()\n",
    "        \n",
    "        # –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ\n",
    "        if len(p1) > 1 and len(p2) > 1:\n",
    "            crossover_point1 = random.randint(1, len(p1) - 1)\n",
    "            crossover_point2 = random.randint(1, len(p2) - 1)\n",
    "            \n",
    "            child1 = p1[:crossover_point1] + p2[crossover_point2:]\n",
    "            child2 = p2[:crossover_point2] + p1[crossover_point1:]\n",
    "        else:\n",
    "            child1, child2 = p1.copy(), p2.copy()\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        output_layer = {\n",
    "            'layer': 'dense',\n",
    "            'units': 1,\n",
    "            'activation': 'linear'\n",
    "        }\n",
    "        \n",
    "        child1.append(output_layer)\n",
    "        child2.append(output_layer)\n",
    "        \n",
    "        return child1, child2\n",
    "    \n",
    "    def mutate(self, architecture):\n",
    "        if random.random() > self.mutation_rate:\n",
    "            return architecture\n",
    "        \n",
    "        # –ö–ª–æ–Ω–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –±–µ–∑ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "        arch_copy = architecture[:-1].copy()\n",
    "        output_layer = architecture[-1].copy()\n",
    "        \n",
    "        mutation_type = random.choice(['add', 'remove', 'modify'])\n",
    "        \n",
    "        if mutation_type == 'add' and len(arch_copy) < 10:\n",
    "            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            insert_position = random.randint(0, len(arch_copy))\n",
    "            if insert_position == 0:\n",
    "                new_layer = create_random_layer()\n",
    "            else:\n",
    "                new_layer = create_random_layer(arch_copy[insert_position-1])\n",
    "            arch_copy.insert(insert_position, new_layer)\n",
    "            \n",
    "        elif mutation_type == 'remove' and len(arch_copy) > 1:\n",
    "            # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            remove_position = random.randint(0, len(arch_copy) - 1)\n",
    "            arch_copy.pop(remove_position)\n",
    "            \n",
    "        elif mutation_type == 'modify' and len(arch_copy) > 0:\n",
    "            # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            modify_position = random.randint(0, len(arch_copy) - 1)\n",
    "            layer = arch_copy[modify_position]\n",
    "            \n",
    "            if layer['layer'] == 'dense':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Dense —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "                \n",
    "            elif layer['layer'] == 'Conv1D':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Conv1D —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "                \n",
    "            elif layer['layer'] in ['RNN', 'GRU']:\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–ª–æ–∏\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['return_sequences'] = random.choice([True, False])\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        arch_copy.append(output_layer)\n",
    "        return arch_copy\n",
    "    \n",
    "    def evolve(self):\n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "        population = self.initialize_population()\n",
    "        \n",
    "        for generation in range(self.num_generations):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # –û—Ü–µ–Ω–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "            fitness_scores = self.evaluate_population(population)\n",
    "            generation_best_fitness = fitness_scores[0][0]\n",
    "            generation_best_architecture = fitness_scores[0][1]\n",
    "            generation_best_val_loss = fitness_scores[0][2]\n",
    "            generation_best_params = fitness_scores[0][3]\n",
    "            \n",
    "            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "            if generation_best_fitness < self.best_fitness:\n",
    "                self.best_fitness = generation_best_fitness\n",
    "                self.best_architecture = generation_best_architecture\n",
    "            \n",
    "            # –ó–∞–ø–∏—Å—å –∏—Å—Ç–æ—Ä–∏–∏\n",
    "            self.history.append({\n",
    "                'generation': generation,\n",
    "                'best_fitness': generation_best_fitness,\n",
    "                'best_val_loss': generation_best_val_loss,\n",
    "                'best_params': generation_best_params\n",
    "            })\n",
    "            \n",
    "            # –í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n",
    "            end_time = time.time()\n",
    "            print(f\"–ü–æ–∫–æ–ª–µ–Ω–∏–µ {generation + 1}/{self.num_generations} - –õ—É—á—à–∞—è –æ—à–∏–±–∫–∞: {generation_best_val_loss:.6f}, \"\n",
    "                  f\"–§–∏—Ç–Ω–µ—Å: {generation_best_fitness:.6f}, –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {generation_best_params}, \"\n",
    "                  f\"–í—Ä–µ–º—è: {end_time - start_time:.2f} —Å–µ–∫.\")\n",
    "            \n",
    "            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ü–∏–∫–ª–∞\n",
    "            if generation == self.num_generations - 1:\n",
    "                break\n",
    "            \n",
    "            # –û—Ç–±–æ—Ä\n",
    "            selected = self.selection(fitness_scores)\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è\n",
    "            new_population = []\n",
    "            \n",
    "            # –≠–ª–∏—Ç–∏–∑–º - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –æ—Å–æ–±–∏\n",
    "            new_population.append(generation_best_architecture)\n",
    "            \n",
    "            # –°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –∏ –º—É—Ç–∞—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–π\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(selected, k=2)\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                \n",
    "                child1 = self.mutate(child1)\n",
    "                child2 = self.mutate(child2)\n",
    "                \n",
    "                new_population.append(child1)\n",
    "                if len(new_population) < self.population_size:\n",
    "                    new_population.append(child2)\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "        final_fitness_scores = self.evaluate_population(population)\n",
    "        final_best = final_fitness_scores[0]\n",
    "        \n",
    "        if final_best[0] < self.best_fitness:\n",
    "            self.best_fitness = final_best[0]\n",
    "            self.best_architecture = final_best[1]\n",
    "            \n",
    "    def plot_evolution(self):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ —ç–≤–æ–ª—é—Ü–∏–∏\"\"\"\n",
    "        generations = [h['generation'] for h in self.history]\n",
    "        best_fitness = [h['best_fitness'] for h in self.history]\n",
    "        val_losses = [h['best_val_loss'] for h in self.history]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(generations, best_fitness, 'b-', marker='o')\n",
    "        plt.title('–≠–≤–æ–ª—é—Ü–∏—è —Ñ–∏—Ç–Ω–µ—Å-—Ñ—É–Ω–∫—Ü–∏–∏')\n",
    "        plt.xlabel('–ü–æ–∫–æ–ª–µ–Ω–∏–µ')\n",
    "        plt.ylabel('–§–∏—Ç–Ω–µ—Å (–Ω–∏–∂–µ = –ª—É—á—à–µ)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(generations, val_losses, 'r-', marker='o')\n",
    "        plt.title('–≠–≤–æ–ª—é—Ü–∏—è –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏')\n",
    "        plt.xlabel('–ü–æ–∫–æ–ª–µ–Ω–∏–µ')\n",
    "        plt.ylabel('–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (MSE)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('evolution_progress.png')\n",
    "        plt.show()\n",
    "    \n",
    "    def train_best_model(self, X_test=None, y_test=None, epochs=100, batch_size=32):\n",
    "        \"\"\"–û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return None\n",
    "            \n",
    "        print(\"–û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...\")\n",
    "        best_model = architecture_to_model(self.best_architecture, self.input_shape)\n",
    "        \n",
    "        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "        best_model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae', 'mse']\n",
    "        )\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "        best_model.summary()\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        history = best_model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(self.X_val, self.y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], 'b-')\n",
    "        plt.plot(history.history['val_loss'], 'r-')\n",
    "        plt.title('–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å')\n",
    "        plt.xlabel('–≠–ø–æ—Ö–∞')\n",
    "        plt.ylabel('–ü–æ—Ç–µ—Ä–∏ (MSE)')\n",
    "        plt.legend(['–û–±—É—á–µ–Ω–∏–µ', '–í–∞–ª–∏–¥–∞—Ü–∏—è'])\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['mae'], 'b-')\n",
    "        plt.plot(history.history['val_mae'], 'r-')\n",
    "        plt.title('–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')\n",
    "        plt.xlabel('–≠–ø–æ—Ö–∞')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend(['–û–±—É—á–µ–Ω–∏–µ', '–í–∞–ª–∏–¥–∞—Ü–∏—è'])\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã\n",
    "        if X_test is not None and y_test is not None:\n",
    "            test_results = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "            print(f\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "            print(f\"MSE: {test_results[1]:.6f}\")\n",
    "            print(f\"MAE: {test_results[0]:.6f}\")\n",
    "            \n",
    "            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            \n",
    "            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(y_test[:100], 'b-', label='–†–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
    "            plt.plot(y_pred[:100], 'r-', label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')\n",
    "            plt.title('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ vs —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
    "            plt.xlabel('–û–±—Ä–∞–∑–µ—Ü')\n",
    "            plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig('predictions.png')\n",
    "            plt.show()\n",
    "        \n",
    "        return best_model\n",
    "    \n",
    "    def save_best_architecture(self, filename='best_architecture.json'):\n",
    "        \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ —Ñ–∞–π–ª\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return\n",
    "            \n",
    "        import json\n",
    "        \n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç\n",
    "        architecture_dict = {\n",
    "            'fitness': self.best_fitness,\n",
    "            'architecture': self.best_architecture\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(architecture_dict, f, indent=4)\n",
    "            \n",
    "        print(f\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filename}\")\n",
    "    \n",
    "    def visualize_architecture(self):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–∏–¥–µ\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return\n",
    "            \n",
    "        print(\"–õ—É—á—à–∞—è –Ω–∞–π–¥–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:\")\n",
    "        print(f\"–§–∏—Ç–Ω–µ—Å: {self.best_fitness:.6f}\")\n",
    "        print(\"–°—Ç—Ä—É–∫—Ç—É—Ä–∞:\")\n",
    "        \n",
    "        for i, layer in enumerate(self.best_architecture):\n",
    "            layer_type = layer['layer']\n",
    "            \n",
    "            if layer_type == 'dense':\n",
    "                print(f\"  {i+1}. Dense: {layer.get('units')} units, activation={layer.get('activation')}\")\n",
    "                if layer.get('batch_normalization', False):\n",
    "                    print(f\"     + BatchNormalization\")\n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                print(f\"  {i+1}. Conv1D: filters={layer.get('filters')}, kernel_size={layer.get('kernel_size')}, \"\n",
    "                      f\"stride={layer.get('strides')}, activation={layer.get('activation')}\")\n",
    "                if layer.get('max_pooling'):\n",
    "                    print(f\"     + MaxPooling1D({layer.get('max_pooling')})\")\n",
    "                if layer.get('batch_normalization', False):\n",
    "                    print(f\"     + BatchNormalization\")\n",
    "                    \n",
    "            elif layer_type == 'RNN':\n",
    "                print(f\"  {i+1}. SimpleRNN: {layer.get('units')} units, activation={layer.get('activation')}, \"\n",
    "                      f\"return_sequences={layer.get('return_sequences')}\")\n",
    "                if layer.get('bidirectional', False):\n",
    "                    print(f\"     + Bidirectional\")\n",
    "                if layer.get('dropout', 0) > 0 or layer.get('recurrent_dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')}), RecurrentDropout({layer.get('recurrent_dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                print(f\"  {i+1}. GRU: {layer.get('units')} units, activation={layer.get('activation')}, \"\n",
    "                      f\"return_sequences={layer.get('return_sequences')}\")\n",
    "                if layer.get('bidirectional', False):\n",
    "                    print(f\"     + Bidirectional\")\n",
    "                if layer.get('dropout', 0) > 0 or layer.get('recurrent_dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')}), RecurrentDropout({layer.get('recurrent_dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                print(f\"  {i+1}. Flatten\")\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                print(f\"  {i+1}. GlobalAveragePooling1D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98648933-d120-4e2d-9b42-66402dfe83d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a340221-ef55-4b2d-8ddb-a674a7ef56b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124b4d1-c096-46e0-9deb-6d79f674c35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb4d44-fb0e-4e04-8f22-bb2a1e98eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GRU, SimpleRNN, Flatten, GlobalAveragePooling1D, Input\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö —Å–ª–æ–µ–≤\n",
    "def random_dense_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'dense'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    \n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_RNN_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'RNN'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_GRU_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'GRU'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['tanh', 'relu', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_Conv1D_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'Conv1D'\n",
    "    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "    layer['strides'] = random.choice([1, 2])\n",
    "    layer['padding'] = random.choice(['valid', 'same'])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid', 'elu'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dilation_rate'] = random.choice([1, 2])\n",
    "    layer['max_pooling'] = random.choice([None, 2, 3])\n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def create_random_layer(prev_layer=None):\n",
    "    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ª–æ–µ–≤\n",
    "    if prev_layer is None or prev_layer.get('layer') not in ['RNN', 'GRU'] or not prev_layer.get('return_sequences', False):\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    else:\n",
    "        # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–ª–æ–π - —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å return_sequences=True\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    \n",
    "    # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ flatten/pooling\n",
    "    if prev_layer and prev_layer.get('layer') in ['flatten', 'global_avg_pooling1d']:\n",
    "        layer_types = ['dense']\n",
    "        \n",
    "    layer_type = random.choice(layer_types)\n",
    "        \n",
    "    if layer_type == 'dense':\n",
    "        return random_dense_layer()\n",
    "    elif layer_type == 'conv1d':\n",
    "        return random_Conv1D_layer()\n",
    "    elif layer_type == 'gru':\n",
    "        return random_GRU_layer()\n",
    "    elif layer_type == 'rnn':\n",
    "        return random_RNN_layer()\n",
    "        \n",
    "    return {'layer': layer_type}\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "def generate_random_architecture(min_layers=2, max_layers=10):\n",
    "    num_layers = random.randint(min_layers, max_layers)\n",
    "    architecture = []\n",
    "    \n",
    "    # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π\n",
    "    prev_layer = None\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        new_layer = create_random_layer(prev_layer)\n",
    "        architecture.append(new_layer)\n",
    "        prev_layer = new_layer\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ —Å–ª–æ–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
    "        if i < num_layers - 1 and new_layer.get('layer') in ['Conv1D', 'RNN', 'GRU'] and \\\n",
    "           new_layer.get('return_sequences', True) and random.random() > 0.5:\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–π —É–ø–ª–æ—â–µ–Ω–∏—è –∏–ª–∏ –ø—É–ª–∏–Ω–≥–∞ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.5\n",
    "            flatten_type = random.choice(['flatten', 'global_avg_pooling1d'])\n",
    "            architecture.append({'layer': flatten_type})\n",
    "            prev_layer = {'layer': flatten_type}\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    architecture.append({\n",
    "        'layer': 'dense',\n",
    "        'units': 1,\n",
    "        'activation': 'linear'\n",
    "    })\n",
    "    \n",
    "    return architecture\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ –º–æ–¥–µ–ª—å Keras\n",
    "def architecture_to_model(architecture, input_shape):\n",
    "    model = Sequential()\n",
    "    first_layer = True\n",
    "    \n",
    "    for layer in architecture:\n",
    "        layer_type = layer['layer']\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º Input shape –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è\n",
    "        if first_layer:\n",
    "            if layer_type == 'dense':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D(input_shape=input_shape))\n",
    "                \n",
    "            first_layer = False\n",
    "            \n",
    "        else:\n",
    "            # –°–ª–æ–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ\n",
    "            if layer_type == 'dense':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten())\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "def evaluate_architecture(architecture, X_train, y_train, X_val, y_val, input_shape, epochs=50, batch_size=32):\n",
    "    try:\n",
    "        model = architecture_to_model(architecture, input_shape)\n",
    "        \n",
    "        # –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "        optimizer_choice = random.choice(['adam', 'rmsprop', 'sgd'])\n",
    "        learning_rate = random.choice([0.001, 0.01, 0.0001])\n",
    "        \n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_choice == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=learning_rate)\n",
    "        else:\n",
    "            optimizer = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        # Early stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        val_loss = min(history.history['val_loss'])  # –ë–µ—Ä–µ–º –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º —à—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏\n",
    "        num_params = model.count_params()\n",
    "        complexity_penalty = np.log(num_params) / 10.0  # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å\n",
    "        \n",
    "        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_score = val_loss + complexity_penalty\n",
    "        \n",
    "        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏\n",
    "        tf.keras.backend.clear_session()\n",
    "        del model\n",
    "        \n",
    "        return fitness_score, val_loss, num_params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {e}\")\n",
    "        return float('inf'), float('inf'), 0\n",
    "\n",
    "# –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º\n",
    "class GeneticNNOptimizer:\n",
    "    def __init__(self, input_shape, X_train, y_train, X_val, y_val, \n",
    "                 population_size=20, num_generations=10, \n",
    "                 mutation_rate=0.2, crossover_rate=0.7):\n",
    "        self.input_shape = input_shape\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.population_size = population_size\n",
    "        self.num_generations = num_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.best_architecture = None\n",
    "        self.best_fitness = float('inf')\n",
    "        self.history = []\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            architecture = generate_random_architecture()\n",
    "            population.append(architecture)\n",
    "        return population\n",
    "    \n",
    "    def evaluate_population(self, population):\n",
    "        fitness_scores = []\n",
    "        for architecture in population:\n",
    "            fitness, val_loss, num_params = evaluate_architecture(\n",
    "                architecture, \n",
    "                self.X_train, self.y_train, \n",
    "                self.X_val, self.y_val, \n",
    "                self.input_shape\n",
    "            )\n",
    "            fitness_scores.append((fitness, architecture, val_loss, num_params))\n",
    "        \n",
    "        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏—Å–ø–æ—Å–æ–±–ª–µ–Ω–Ω–æ—Å—Ç–∏ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_scores.sort(key=lambda x: x[0])\n",
    "        return fitness_scores\n",
    "    \n",
    "    def selection(self, fitness_scores):\n",
    "        # –û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –æ—Å–æ–±–µ–π (—ç–ª–∏—Ç–∏–∑–º) + —Ç—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä\n",
    "        elite_count = max(1, int(self.population_size * 0.1))  # 10% —ç–ª–∏—Ç–∏–∑–º–∞\n",
    "        selected = [score[1] for score in fitness_scores[:elite_count]]\n",
    "        \n",
    "        # –¢—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø–æ–∑–∏—Ü–∏–π\n",
    "        while len(selected) < self.population_size:\n",
    "            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ 3 –æ—Å–æ–±–∏ –¥–ª—è —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "            tournament = random.sample(fitness_scores, k=3)\n",
    "            tournament.sort(key=lambda x: x[0])\n",
    "            selected.append(tournament[0][1])  # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –∏–∑ —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def crossover(self, parent1, parent2):\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1.copy(), parent2.copy()\n",
    "        \n",
    "        # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π (–≤—ã—Ö–æ–¥–Ω–æ–π) –ø–µ—Ä–µ–¥ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ–º\n",
    "        p1 = parent1[:-1].copy()\n",
    "        p2 = parent2[:-1].copy()\n",
    "        \n",
    "        # –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ\n",
    "        if len(p1) > 1 and len(p2) > 1:\n",
    "            crossover_point1 = random.randint(1, len(p1) - 1)\n",
    "            crossover_point2 = random.randint(1, len(p2) - 1)\n",
    "            \n",
    "            child1 = p1[:crossover_point1] + p2[crossover_point2:]\n",
    "            child2 = p2[:crossover_point2] + p1[crossover_point1:]\n",
    "        else:\n",
    "            child1, child2 = p1.copy(), p2.copy()\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        output_layer = {\n",
    "            'layer': 'dense',\n",
    "            'units': 1,\n",
    "            'activation': 'linear'\n",
    "        }\n",
    "        \n",
    "        child1.append(output_layer)\n",
    "        child2.append(output_layer)\n",
    "        \n",
    "        return child1, child2\n",
    "    \n",
    "    def mutate(self, architecture):\n",
    "        if random.random() > self.mutation_rate:\n",
    "            return architecture\n",
    "        \n",
    "        # –ö–ª–æ–Ω–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –±–µ–∑ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "        arch_copy = architecture[:-1].copy()\n",
    "        output_layer = architecture[-1].copy()\n",
    "        \n",
    "        mutation_type = random.choice(['add', 'remove', 'modify'])\n",
    "        \n",
    "        if mutation_type == 'add' and len(arch_copy) < 10:\n",
    "            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            insert_position = random.randint(0, len(arch_copy))\n",
    "            if insert_position == 0:\n",
    "                new_layer = create_random_layer()\n",
    "            else:\n",
    "                new_layer = create_random_layer(arch_copy[insert_position-1])\n",
    "            arch_copy.insert(insert_position, new_layer)\n",
    "            \n",
    "        elif mutation_type == 'remove' and len(arch_copy) > 1:\n",
    "            # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            remove_position = random.randint(0, len(arch_copy) - 1)\n",
    "            arch_copy.pop(remove_position)\n",
    "            \n",
    "        elif mutation_type == 'modify' and len(arch_copy) > 0:\n",
    "            # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            modify_position = random.randint(0, len(arch_copy) - 1)\n",
    "            layer = arch_copy[modify_position]\n",
    "            \n",
    "            if layer['layer'] == 'dense':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Dense —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "                \n",
    "            elif layer['layer'] == 'Conv1D':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Conv1D —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "                \n",
    "            elif layer['layer'] in ['RNN', 'GRU']:\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–ª–æ–∏\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['return_sequences'] = random.choice([True, False])\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        arch_copy.append(output_layer)\n",
    "        return arch_copy\n",
    "    \n",
    "    def evolve(self):\n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "        population = self.initialize_population()\n",
    "        \n",
    "        for generation in range(self.num_generations):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # –û—Ü–µ–Ω–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "            fitness_scores = self.evaluate_population(population)\n",
    "            generation_best_fitness = fitness_scores[0][0]\n",
    "            generation_best_architecture = fitness_scores[0][1]\n",
    "            generation_best_val_loss = fitness_scores[0][2]\n",
    "            generation_best_params = fitness_scores[0][3]\n",
    "            \n",
    "            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "            if generation_best_fitness < self.best_fitness:\n",
    "                self.best_fitness = generation_best_fitness\n",
    "                self.best_architecture = generation_best_architecture\n",
    "            \n",
    "            # –ó–∞–ø–∏—Å—å –∏—Å—Ç–æ—Ä–∏–∏\n",
    "            self.history.append({\n",
    "                'generation': generation,\n",
    "                'best_fitness': generation_best_fitness,\n",
    "                'best_val_loss': generation_best_val_loss,\n",
    "                'best_params': generation_best_params\n",
    "            })\n",
    "            \n",
    "            # –í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n",
    "            end_time = time.time()\n",
    "            print(f\"–ü–æ–∫–æ–ª–µ–Ω–∏–µ {generation + 1}/{self.num_generations} - –õ—É—á—à–∞—è –æ—à–∏–±–∫–∞: {generation_best_val_loss:.6f}, \"\n",
    "                  f\"–§–∏—Ç–Ω–µ—Å: {generation_best_fitness:.6f}, –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {generation_best_params}, \"\n",
    "                  f\"–í—Ä–µ–º—è: {end_time - start_time:.2f} —Å–µ–∫.\")\n",
    "            \n",
    "            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ü–∏–∫–ª–∞\n",
    "            if generation == self.num_generations - 1:\n",
    "                break\n",
    "            \n",
    "            # –û—Ç–±–æ—Ä\n",
    "            selected = self.selection(fitness_scores)\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è\n",
    "            new_population = []\n",
    "            \n",
    "            # –≠–ª–∏—Ç–∏–∑–º - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –æ—Å–æ–±–∏\n",
    "            new_population.append(generation_best_architecture)\n",
    "            \n",
    "            # –°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –∏ –º—É—Ç–∞—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–π\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(selected, k=2)\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                \n",
    "                child1 = self.mutate(child1)\n",
    "                child2 = self.mutate(child2)\n",
    "                \n",
    "                new_population.append(child1)\n",
    "                if len(new_population) < self.population_size:\n",
    "                    new_population.append(child2)\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "        final_fitness_scores = self.evaluate_population(population)\n",
    "        final_best = final_fitness_scores[0]\n",
    "        \n",
    "        if final_best[0] < self.best_fitness:\n",
    "            self.best_fitness = final_best[0]\n",
    "            self.best_architecture = final_best[1]\n",
    "            \n",
    "    def plot_evolution(self):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ —ç–≤–æ–ª—é—Ü–∏–∏\"\"\"\n",
    "        generations = [h['generation'] for h in self.history]\n",
    "        best_fitness = [h['best_fitness'] for h in self.history]\n",
    "        val_losses = [h['best_val_loss'] for h in self.history]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(generations, best_fitness, 'b-', marker='o')\n",
    "        plt.title('–≠–≤–æ–ª—é—Ü–∏—è —Ñ–∏—Ç–Ω–µ—Å-—Ñ—É–Ω–∫—Ü–∏–∏')\n",
    "        plt.xlabel('–ü–æ–∫–æ–ª–µ–Ω–∏–µ')\n",
    "        plt.ylabel('–§–∏—Ç–Ω–µ—Å (–Ω–∏–∂–µ = –ª—É—á—à–µ)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(generations, val_losses, 'r-', marker='o')\n",
    "        plt.title('–≠–≤–æ–ª—é—Ü–∏—è –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏')\n",
    "        plt.xlabel('–ü–æ–∫–æ–ª–µ–Ω–∏–µ')\n",
    "        plt.ylabel('–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (MSE)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('evolution_progress.png')\n",
    "        plt.show()\n",
    "    \n",
    "    def train_best_model(self, X_test=None, y_test=None, epochs=100, batch_size=32):\n",
    "        \"\"\"–û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return None\n",
    "            \n",
    "        print(\"–û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...\")\n",
    "        best_model = architecture_to_model(self.best_architecture, self.input_shape)\n",
    "        \n",
    "        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "        best_model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae', 'mse']\n",
    "        )\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "        best_model.summary()\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        history = best_model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(self.X_val, self.y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], 'b-')\n",
    "        plt.plot(history.history['val_loss'], 'r-')\n",
    "        plt.title('–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å')\n",
    "        plt.xlabel('–≠–ø–æ—Ö–∞')\n",
    "        plt.ylabel('–ü–æ—Ç–µ—Ä–∏ (MSE)')\n",
    "        plt.legend(['–û–±—É—á–µ–Ω–∏–µ', '–í–∞–ª–∏–¥–∞—Ü–∏—è'])\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['mae'], 'b-')\n",
    "        plt.plot(history.history['val_mae'], 'r-')\n",
    "        plt.title('–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')\n",
    "        plt.xlabel('–≠–ø–æ—Ö–∞')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend(['–û–±—É—á–µ–Ω–∏–µ', '–í–∞–ª–∏–¥–∞—Ü–∏—è'])\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã\n",
    "        if X_test is not None and y_test is not None:\n",
    "            test_results = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "            print(f\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "            print(f\"MSE: {test_results[1]:.6f}\")\n",
    "            print(f\"MAE: {test_results[0]:.6f}\")\n",
    "            \n",
    "            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            \n",
    "            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(y_test[:100], 'b-', label='–†–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
    "            plt.plot(y_pred[:100], 'r-', label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')\n",
    "            plt.title('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ vs —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
    "            plt.xlabel('–û–±—Ä–∞–∑–µ—Ü')\n",
    "            plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig('predictions.png')\n",
    "            plt.show()\n",
    "        \n",
    "        return best_model\n",
    "    \n",
    "    def save_best_architecture(self, filename='best_architecture.json'):\n",
    "        \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ —Ñ–∞–π–ª\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return\n",
    "            \n",
    "        import json\n",
    "        \n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç\n",
    "        architecture_dict = {\n",
    "            'fitness': self.best_fitness,\n",
    "            'architecture': self.best_architecture\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(architecture_dict, f, indent=4)\n",
    "            \n",
    "        print(f\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filename}\")\n",
    "    \n",
    "    def visualize_architecture(self):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–∏–¥–µ\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return\n",
    "            \n",
    "        print(\"–õ—É—á—à–∞—è –Ω–∞–π–¥–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:\")\n",
    "        print(f\"–§–∏—Ç–Ω–µ—Å: {self.best_fitness:.6f}\")\n",
    "        print(\"–°—Ç—Ä—É–∫—Ç—É—Ä–∞:\")\n",
    "        \n",
    "        for i, layer in enumerate(self.best_architecture):\n",
    "            layer_type = layer['layer']\n",
    "            \n",
    "            if layer_type == 'dense':\n",
    "                print(f\"  {i+1}. Dense: {layer.get('units')} units, activation={layer.get('activation')}\")\n",
    "                if layer.get('batch_normalization', False):\n",
    "                    print(f\"     + BatchNormalization\")\n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                print(f\"  {i+1}. Conv1D: filters={layer.get('filters')}, kernel_size={layer.get('kernel_size')}, \"\n",
    "                      f\"stride={layer.get('strides')}, activation={layer.get('activation')}\")\n",
    "                if layer.get('max_pooling'):\n",
    "                    print(f\"     + MaxPooling1D({layer.get('max_pooling')})\")\n",
    "                if layer.get('batch_normalization', False):\n",
    "                    print(f\"     + BatchNormalization\")\n",
    "                    \n",
    "            elif layer_type == 'RNN':\n",
    "                print(f\"  {i+1}. SimpleRNN: {layer.get('units')} units, activation={layer.get('activation')}, \"\n",
    "                      f\"return_sequences={layer.get('return_sequences')}\")\n",
    "                if layer.get('bidirectional', False):\n",
    "                    print(f\"     + Bidirectional\")\n",
    "                if layer.get('dropout', 0) > 0 or layer.get('recurrent_dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')}), RecurrentDropout({layer.get('recurrent_dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                print(f\"  {i+1}. GRU: {layer.get('units')} units, activation={layer.get('activation')}, \"\n",
    "                      f\"return_sequences={layer.get('return_sequences')}\")\n",
    "                if layer.get('bidirectional', False):\n",
    "                    print(f\"     + Bidirectional\")\n",
    "                if layer.get('dropout', 0) > 0 or layer.get('recurrent_dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')}), RecurrentDropout({layer.get('recurrent_dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                print(f\"  {i+1}. Flatten\")\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                print(f\"  {i+1}. GlobalAveragePooling1D\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3da7f-3f12-4ae1-a625-19650884a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalAveragePooling1D, Flatten, GRU, SimpleRNN, BatchNormalization, Activation, Dropout, Bidirectional\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# --- –û—Å–Ω–æ–≤–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã —Å–ª–æ—ë–≤ ---\n",
    "def random_dense_layer(units_choices=None):\n",
    "    units_choices = units_choices or [32, 64, 128, 256]\n",
    "    layer = {'layer': 'Dense',\n",
    "             'units': random.choice(units_choices),\n",
    "             'activation': random.choice(['relu', 'sigmoid', 'tanh', 'linear']),\n",
    "             'kernel_regularizer': random.choice(['L1', 'L2', 'L1L2', None])}\n",
    "    if layer['kernel_regularizer']:\n",
    "        layer['coef_regularizer'] = random.choice([0.0001, 0.001, 0.01, 0.1])\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    return layer\n",
    "\n",
    "\n",
    "def random_conv1d_block():\n",
    "    return {'layer': 'Conv1D',\n",
    "            'filters': random.choice([32, 64, 128, 256]),\n",
    "            'kernel_size': random.choice([3, 5, 7]),\n",
    "            'strides': random.choice([1, 2]),\n",
    "            'padding': random.choice(['valid', 'same']),\n",
    "            'activation': random.choice(['relu', 'tanh', 'sigmoid', 'elu']),\n",
    "            'batch_norm': random.choice([True, False]),\n",
    "            'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "            'pooling': random.choice([None, 'max2', 'max3'])}\n",
    "\n",
    "\n",
    "def random_rnn_block(rnn_type='GRU'):\n",
    "    return {'layer': rnn_type,\n",
    "            'units': random.choice([32, 64, 128]),\n",
    "            'activation': random.choice(['tanh', 'relu']),\n",
    "            'return_sequences': random.choice([True, False]),\n",
    "            'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "            'recurrent_dropout': random.choice([0.0, 0.1])}\n",
    "\n",
    "\n",
    "def flatten_block():\n",
    "    return {'layer': 'Flatten'}\n",
    "\n",
    "\n",
    "def global_pool_block():\n",
    "    return {'layer': 'GlobalAvgPool1D'}\n",
    "\n",
    "# --- –§—É–Ω–∫—Ü–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è Keras-–º–æ–¥–µ–ª–∏ –∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---\n",
    "def build_model_from_architecture(arch, input_shape):\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = inp\n",
    "    for l in arch:\n",
    "        t = l['layer']\n",
    "        if t == 'Conv1D':\n",
    "            x = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'], strides=l['strides'],\n",
    "                       padding=l['padding'], activation=None)(x)\n",
    "            if l['batch_norm']: x = BatchNormalization()(x)\n",
    "            x = Activation(l['activation'])(x)\n",
    "            if l['dropout'] > 0: x = Dropout(l['dropout'])(x)\n",
    "            if l['pooling'] == 'max2': x = GlobalAveragePooling1D()(x)\n",
    "            elif l['pooling'] == 'max3': x = GlobalAveragePooling1D()(x)\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            layer_cls = GRU if t == 'GRU' else SimpleRNN\n",
    "            cell = layer_cls(l['units'], activation=l['activation'], return_sequences=l['return_sequences'],\n",
    "                             dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])\n",
    "            x = cell(x)\n",
    "        elif t == 'Flatten':\n",
    "            x = Flatten()(x)\n",
    "        elif t == 'GlobalAvgPool1D':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif t == 'Dense':\n",
    "            reg = None\n",
    "            if l.get('kernel_regularizer') == 'L1': reg = l1(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L2': reg = l2(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L1L2': reg = l1_l2(l['coef_regularizer'])\n",
    "            x = Dense(l['units'], activation=l['activation'], kernel_regularizer=reg)(x)\n",
    "            if l.get('dropout', 0) > 0: x = Dropout(l['dropout'])(x)\n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "# --- –§—É–Ω–∫—Ü–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏ (–¥–ª—è run_ga) ---\n",
    "# –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞—Ä–∞–Ω–µ–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: skeleton_conv_dense, skeleton_rnn, block_randomized, dag_parallel, micro_arch\n",
    "\n",
    "def estimate_params(layers):\n",
    "    total = 0\n",
    "    prev_units = None\n",
    "    for l in layers:\n",
    "        t = l.get('layer')\n",
    "        if t == 'Dense':\n",
    "            u = l['units']\n",
    "            total += (prev_units or u) * u + u\n",
    "            prev_units = u\n",
    "        elif t == 'Conv1D':\n",
    "            f, k = l['filters'], l['kernel_size']\n",
    "            total += (prev_units or f) * k + f\n",
    "            prev_units = f\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            u = l['units']\n",
    "            total += u * (prev_units or u) * 3 + u * 3\n",
    "            prev_units = u\n",
    "    return total\n",
    "\n",
    "# –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—Å—Ç–∞—é—Ç—Å—è —Ç–µ –∂–µ, –Ω–æ –≤—ã–Ω–µ—Å–µ–Ω—ã –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã —Ñ–∞–π–ª–∞\n",
    "\n",
    "# Skeleton: Conv blocks + pooling + Dense blocks\n",
    "# (–ò—Å–ø–æ–ª—å–∑—É–µ—Ç random_conv1d_block –∏ random_dense_layer)\n",
    "\n",
    "def skeleton_conv_dense(min_conv=1, max_conv=3, min_dense=1, max_dense=2):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_conv, max_conv)):\n",
    "        layers.append(random_conv1d_block())\n",
    "    layers.append(global_pool_block())\n",
    "    for _ in range(random.randint(min_dense, max_dense)):\n",
    "        layers.append(random_dense_layer())\n",
    "    return layers\n",
    "\n",
    "# Skeleton: RNN/GRU\n",
    "\n",
    "def skeleton_rnn(min_rnn=1, max_rnn=2, rnn_type='GRU'):\n",
    "    layers = []\n",
    "    p = random.randint(min_rnn, max_rnn)\n",
    "    for i in range(p):\n",
    "        block = random_rnn_block(rnn_type)\n",
    "        block['return_sequences'] = (i < p-1)\n",
    "        layers.append(block)\n",
    "    layers.append(random_dense_layer(units_choices=[64, 128]))\n",
    "    return layers\n",
    "\n",
    "# Random blocks\n",
    "\n",
    "def block_randomized(min_blocks=2, max_blocks=5):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_blocks, max_blocks)):\n",
    "        choice = random.choice(['conv', 'rnn', 'dense', 'pool'])\n",
    "        if choice == 'conv': layers.append(random_conv1d_block())\n",
    "        elif choice == 'rnn': layers.append(random_rnn_block(random.choice(['GRU','RNN'])))\n",
    "        elif choice == 'dense': layers.append(random_dense_layer())\n",
    "        else: layers.append(random.choice([flatten_block(), global_pool_block()]))\n",
    "    return layers\n",
    "\n",
    "# DAG parallel\n",
    "\n",
    "def dag_parallel(min_depth=1, max_depth=3):\n",
    "    a = [random_conv1d_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    a.append(global_pool_block())\n",
    "    b = [random_rnn_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    # –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ DAG –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å\n",
    "    return {'parallel': {'conv_branch': a, 'rnn_branch': b}}\n",
    "\n",
    "# Micro architectures\n",
    "\n",
    "def micro_arch(min_layers=2, max_layers=3):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_layers, max_layers)):\n",
    "        layers.append(random.choice([random_conv1d_block(), random_rnn_block(), random_dense_layer()]))\n",
    "    return layers\n",
    "\n",
    "# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "\n",
    "def generate_population(pop_size=20,\n",
    "                         strategies=None,\n",
    "                         max_params=None):\n",
    "    strategies = strategies or [skeleton_conv_dense, skeleton_rnn, block_randomized, dag_parallel, micro_arch]\n",
    "    population = []\n",
    "    while len(population) < pop_size:\n",
    "        strat = random.choice(strategies)\n",
    "        arch = strat() if strat != dag_parallel else dag_parallel()\n",
    "        # –µ—Å–ª–∏ DAG, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–∞–ø—Ä—è–º—É—é\n",
    "        if isinstance(arch, dict):\n",
    "            population.append(arch)\n",
    "            continue\n",
    "        # –ª–∏–Ω–µ–π–Ω–∞—è —Ü–µ–ø–æ—á–∫–∞: –¥–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥\n",
    "        arch.append({'layer': 'Dense', 'units': 1, 'activation': 'linear'})\n",
    "        if max_params and estimate_params(arch) > max_params:\n",
    "            continue\n",
    "        population.append(arch)\n",
    "    return population\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º ---\n",
    "def evaluate_fitness(arch, train_data, val_data, metric='mse', epochs=5, verbose=0):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏–º –º–æ–¥–µ–ª—å, –∫–æ–º–ø–∏–ª–∏—Ä—É–µ–º –∏ –æ–±—É—á–∞–µ–º, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç—Ä–∏–∫: -val_metric\n",
    "    train_data, val_data: –∫–æ—Ä—Ç–µ–∂–∏ (X, y)\n",
    "    metric: —Å—Ç—Ä–æ–∫–∞ –º–µ—Ç—Ä–∏–∫–∏ Keras\n",
    "    \"\"\"\n",
    "    X_train, y_train = train_data\n",
    "    X_val, y_val = val_data\n",
    "    model = build_model_from_architecture(arch, X_train.shape[1:])\n",
    "    model.compile(optimizer='adam', loss=metric, metrics=[metric])\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                        epochs=epochs, verbose=verbose)\n",
    "    val_res = history.history['val_' + metric][-1]\n",
    "    # fitness: —á–µ–º –≤—ã—à–µ, —Ç–µ–º –ª—É—á—à–µ ‚Üí –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "    return -val_res\n",
    "\n",
    "\n",
    "def select_parents(population, fitnesses, k=3):\n",
    "    parents = []\n",
    "    for _ in range(2):\n",
    "        tour = random.sample(list(zip(population, fitnesses)), k)\n",
    "        parents.append(max(tour, key=lambda x: x[1])[0])\n",
    "    return parents\n",
    "\n",
    "\n",
    "def crossover(parent_a, parent_b):\n",
    "    # –æ–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö\n",
    "    cut = random.randint(1, min(len(parent_a), len(parent_b)) - 1)\n",
    "    return parent_a[:cut] + parent_b[cut:]\n",
    "\n",
    "\n",
    "def mutate(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, generators=None):\n",
    "    \"\"\"\n",
    "    base_mut: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–¥–º–µ–Ω—ã —Å–ª–æ—è\n",
    "    param_mut: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "    struct_mut: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—Å—Ç–∞–≤–∫–∏/—É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ—è\n",
    "    \"\"\"\n",
    "    generators = generators or [random_dense_layer, random_conv1d_block, random_rnn_block]\n",
    "    new_arch = []\n",
    "    for layer in arch:\n",
    "        r = random.random()\n",
    "        if r < base_mut:\n",
    "            # –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞\n",
    "            new_arch.append(random.choice(generators)())\n",
    "        elif r < base_mut + param_mut:\n",
    "            # –º—É—Ç–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "            l = layer.copy()\n",
    "            if 'units' in l:\n",
    "                l['units'] = max(1, int(l['units'] * random.uniform(0.5, 1.5)))\n",
    "            if 'dropout' in l:\n",
    "                l['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "            new_arch.append(l)\n",
    "        else:\n",
    "            new_arch.append(layer)\n",
    "    # —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º—É—Ç–∞—Ü–∏–∏\n",
    "    if random.random() < struct_mut:\n",
    "        # –≤—Å—Ç–∞–≤–∫–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "        pos = random.randint(0, len(new_arch))\n",
    "        new_arch.insert(pos, random.choice(generators)())\n",
    "    if random.random() < struct_mut and len(new_arch) > 1:\n",
    "        # —É–¥–∞–ª–µ–Ω–∏–µ\n",
    "        pos = random.randrange(len(new_arch))\n",
    "        new_arch.pop(pos)\n",
    "    return new_arch\n",
    "\n",
    "\n",
    "def run_ga(train_data, val_data,\n",
    "           pop_size=20, generations=10,\n",
    "           max_params=None,\n",
    "           elitism=2,\n",
    "           metric='mse', epochs=5):\n",
    "    # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–∞—è\n",
    "    population = generate_population(pop_size=pop_size, max_params=max_params)\n",
    "    fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "    for gen in range(generations):\n",
    "        print(f\"Gen {gen+1}/{generations}\")\n",
    "        # —ç–ª–∏—Ç–∏–∑–º\n",
    "        elite_idx = sorted(range(len(population)), key=lambda i: fitnesses[i], reverse=True)[:elitism]\n",
    "        new_pop = [population[i] for i in elite_idx]\n",
    "        # —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã—Ö\n",
    "        while len(new_pop) < pop_size:\n",
    "            p1, p2 = select_parents(population, fitnesses)\n",
    "            child = crossover(p1, p2)\n",
    "            child = mutate(child)\n",
    "            new_pop.append(child)\n",
    "        population = new_pop\n",
    "        fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "    best = max(zip(population, fitnesses), key=lambda x: x[1])\n",
    "    return best[0], best[1]\n",
    "\n",
    "# TODO: –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ, —á—Ç–æ train_data –∏ val_data –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –∫–∞–∫ (X, y) –∏ metric —Å—Ç—Ä–æ–∫–∞ Keras. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706b68a-d5da-459d-af1d-21ee25008a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv1D, GlobalAveragePooling1D, Flatten,\n",
    "    GRU, SimpleRNN, BatchNormalization, Activation, Dropout\n",
    ")\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –±–ª–æ–∫–æ–≤ —Å–ª–æ—ë–≤ ---\n",
    "\n",
    "def random_dense_layer(units_choices=None):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞—ë—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "      units_choices: —Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —á–∏—Å–µ–ª –Ω–µ–π—Ä–æ–Ω–æ–≤.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–∞–º–∏:\n",
    "      layer, units, activation, kernel_regularizer, coef_regularizer (–æ–ø—Ü.), dropout\n",
    "    \"\"\"\n",
    "    units_choices = units_choices or [32, 64, 128, 256]\n",
    "    layer = {\n",
    "        'layer': 'Dense',\n",
    "        'units': random.choice(units_choices),\n",
    "        'activation': random.choice(['relu', 'sigmoid', 'tanh', 'linear']),\n",
    "        'kernel_regularizer': random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    }\n",
    "    # –ï—Å–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –≤—ã–±—Ä–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç\n",
    "    if layer['kernel_regularizer']:\n",
    "        layer['coef_regularizer'] = random.choice([0.0001, 0.001, 0.01, 0.1])\n",
    "    # Dropout –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    return layer\n",
    "\n",
    "\n",
    "def random_conv1d_block():\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –æ–¥–Ω–æ-–º–µ—Ä–Ω–æ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ –±–ª–æ–∫–∞.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Å–ª–æ–≤–∞—Ä–µ:\n",
    "      layer, filters, kernel_size, strides, padding, activation,\n",
    "      batch_norm, dropout, pooling.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': 'Conv1D',\n",
    "        'filters': random.choice([32, 64, 128, 256]),\n",
    "        'kernel_size': random.choice([3, 5, 7]),\n",
    "        'strides': random.choice([1, 2]),\n",
    "        'padding': random.choice(['valid', 'same']),\n",
    "        'activation': random.choice(['relu', 'tanh', 'sigmoid', 'elu']),\n",
    "        'batch_norm': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'pooling': random.choice([None, 'max2', 'max3'])\n",
    "    }\n",
    "\n",
    "\n",
    "def random_rnn_block(rnn_type='GRU'):\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–≥–æ –±–ª–æ–∫–∞ GRU –∏–ª–∏ RNN.\n",
    "    –ü–æ–ª—è:\n",
    "      layer, units, activation, return_sequences,\n",
    "      dropout, recurrent_dropout\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': rnn_type,\n",
    "        'units': random.choice([32, 64, 128]),\n",
    "        'activation': random.choice(['tanh', 'relu']),\n",
    "        'return_sequences': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'recurrent_dropout': random.choice([0.0, 0.1])\n",
    "    }\n",
    "\n",
    "\n",
    "def flatten_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è Flatten.\"\"\"\n",
    "    return {'layer': 'Flatten'}\n",
    "\n",
    "\n",
    "def global_pool_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è GlobalAveragePooling1D.\"\"\"\n",
    "    return {'layer': 'GlobalAvgPool1D'}\n",
    "\n",
    "\n",
    "# --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Keras-–º–æ–¥–µ–ª–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---\n",
    "\n",
    "def build_model_from_architecture(arch, input_shape):\n",
    "    \"\"\"\n",
    "    –ö–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç Keras Model –ø–æ —Å–ø–∏—Å–∫—É –æ–ø–∏—Å–∞–Ω–∏–π —Å–ª–æ—ë–≤ arch.\n",
    "    –ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç arch:\n",
    "      - dict —Å –∫–ª—é—á–æ–º 'layer' –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = inp\n",
    "    for l in arch:\n",
    "        t = l['layer']\n",
    "        # --- –°–≤—ë—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫ ---\n",
    "        if t == 'Conv1D':\n",
    "            x = Conv1D(\n",
    "                filters=l['filters'],\n",
    "                kernel_size=l['kernel_size'],\n",
    "                strides=l['strides'],\n",
    "                padding=l['padding'],\n",
    "                activation=None\n",
    "            )(x)\n",
    "            # BatchNorm –ø–æ—Å–ª–µ —Å–≤—ë—Ä—Ç–∫–∏\n",
    "            if l['batch_norm']:\n",
    "                x = BatchNormalization()(x)\n",
    "            x = Activation(l['activation'])(x)\n",
    "            if l['dropout'] > 0:\n",
    "                x = Dropout(l['dropout'])(x)\n",
    "            # Pooling: –∏—Å—Ç–∏–Ω–Ω–æ –¥–ª—è 'max2' –∏–ª–∏ 'max3'\n",
    "            if l['pooling'] in ('max2', 'max3'):\n",
    "                x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "        # --- –†–µ–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –±–ª–æ–∫ (GRU –∏–ª–∏ SimpleRNN) ---\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            layer_cls = GRU if t == 'GRU' else SimpleRNN\n",
    "            cell = layer_cls(\n",
    "                units=l['units'],\n",
    "                activation=l['activation'],\n",
    "                return_sequences=l['return_sequences'],\n",
    "                dropout=l['dropout'],\n",
    "                recurrent_dropout=l['recurrent_dropout']\n",
    "            )\n",
    "            x = cell(x)\n",
    "\n",
    "        # --- –£–ø–ª–æ—â–µ–Ω–∏–µ –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø—É–ª–ª–∏–Ω–≥ ---\n",
    "        elif t == 'Flatten':\n",
    "            x = Flatten()(x)\n",
    "        elif t == 'GlobalAvgPool1D':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "        # --- –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π ---\n",
    "        elif t == 'Dense':\n",
    "            # –í—ã–±–æ—Ä —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä–∞\n",
    "            reg = None\n",
    "            if l.get('kernel_regularizer') == 'L1':\n",
    "                reg = l1(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L2':\n",
    "                reg = l2(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L1L2':\n",
    "                reg = l1_l2(l['coef_regularizer'])\n",
    "\n",
    "            x = Dense(\n",
    "                units=l['units'],\n",
    "                activation=l['activation'],\n",
    "                kernel_regularizer=reg\n",
    "            )(x)\n",
    "            if l.get('dropout', 0) > 0:\n",
    "                x = Dropout(l['dropout'])(x)\n",
    "\n",
    "        # –ò–Ω–∞—á–µ: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø\n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "# --- –û—Ü–µ–Ω–∫–∞ —á–∏—Å–ª–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ (–≥—Ä—É–±–∞—è) ---\n",
    "\n",
    "def estimate_params(layers):\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ—Ç —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Å–ø–∏—Å–∫—É —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    prev_units = None\n",
    "    for l in layers:\n",
    "        t = l.get('layer')\n",
    "        if t == 'Dense':\n",
    "            u = l['units']\n",
    "            total += (prev_units or u) * u + u\n",
    "            prev_units = u\n",
    "        elif t == 'Conv1D':\n",
    "            f, k = l['filters'], l['kernel_size']\n",
    "            total += (prev_units or f) * k + f\n",
    "            prev_units = f\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            u = l['units']\n",
    "            # —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä—ë—Ö –≤—Ö–æ–¥–Ω—ã—Ö –≤–µ—Å–æ–≤ + bias\n",
    "            total += u * (prev_units or u) * 3 + u * 3\n",
    "            prev_units = u\n",
    "    return total\n",
    "\n",
    "\n",
    "# --- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏ ---\n",
    "# –°–ª—É—á–∞–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω—ã–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏\n",
    "\n",
    "# 1) Conv‚ÜíPool‚ÜíDense skeleton\n",
    "\n",
    "def skeleton_conv_dense(min_conv=1, max_conv=3, min_dense=1, max_dense=2):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_conv, max_conv)):\n",
    "        layers.append(random_conv1d_block())\n",
    "    layers.append(global_pool_block())\n",
    "    for _ in range(random.randint(min_dense, max_dense)):\n",
    "        layers.append(random_dense_layer())\n",
    "    return layers\n",
    "\n",
    "# 2) –ß–∏—Å—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π skeleton\n",
    "\n",
    "def skeleton_rnn(min_rnn=1, max_rnn=2, rnn_type='GRU'):\n",
    "    layers = []\n",
    "    p = random.randint(min_rnn, max_rnn)\n",
    "    for i in range(p):\n",
    "        block = random_rnn_block(rnn_type)\n",
    "        block['return_sequences'] = (i < p - 1)\n",
    "        layers.append(block)\n",
    "    layers.append(random_dense_layer(units_choices=[64, 128]))\n",
    "    return layers\n",
    "\n",
    "# 3) –°–ª—É—á–∞–π–Ω—ã–µ –±–ª–æ–∫–∏\n",
    "\n",
    "def block_randomized(min_blocks=2, max_blocks=5):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_blocks, max_blocks)):\n",
    "        choice = random.choice(['conv', 'rnn', 'dense', 'pool'])\n",
    "        if choice == 'conv':\n",
    "            layers.append(random_conv1d_block())\n",
    "        elif choice == 'rnn':\n",
    "            layers.append(random_rnn_block(random.choice(['GRU', 'RNN'])))\n",
    "        elif choice == 'dense':\n",
    "            layers.append(random_dense_layer())\n",
    "        else:\n",
    "            layers.append(random.choice([flatten_block(), global_pool_block()]))\n",
    "    return layers\n",
    "\n",
    "# 4) –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG: Conv-–≤–µ—Ç–∫–∞ –∏ RNN-–≤–µ—Ç–∫–∞\n",
    "\n",
    "def dag_parallel(min_depth=1, max_depth=3):\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–≤—É—Ö –≤–µ—Ç–æ–∫\n",
    "    a = [random_conv1d_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    a.append(global_pool_block())\n",
    "    b = [random_rnn_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º DAG –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏\n",
    "    return {'parallel': {'conv_branch': a, 'rnn_branch': b}}\n",
    "\n",
    "# 5) –ú–∏–Ω–∏-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞\n",
    "\n",
    "def micro_arch(min_layers=2, max_layers=3):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_layers, max_layers)):\n",
    "        layers.append(random.choice([\n",
    "            random_conv1d_block(), random_rnn_block(), random_dense_layer()\n",
    "        ]))\n",
    "    return layers\n",
    "\n",
    "# –°–±–æ—Ä–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏ —Å —É—á—ë—Ç–æ–º max_params\n",
    "\n",
    "def generate_population(pop_size=20, strategies=None, max_params=None):\n",
    "    \"\"\"\n",
    "    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ø—É–ª—è—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\n",
    "    pop_size: —Ä–∞–∑–º–µ—Ä.\n",
    "    strategies: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤.\n",
    "    max_params: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "    \"\"\"\n",
    "    strategies = strategies or [\n",
    "        skeleton_conv_dense,\n",
    "        skeleton_rnn,\n",
    "        block_randomized,\n",
    "        dag_parallel,\n",
    "        micro_arch\n",
    "    ]\n",
    "    population = []\n",
    "    while len(population) < pop_size:\n",
    "        strat = random.choice(strategies)\n",
    "        arch = strat()  # –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å dict (DAG) –∏–ª–∏ list\n",
    "        if isinstance(arch, dict):\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º DAG –∫–∞–∫ –µ—Å—Ç—å\n",
    "            population.append(arch)\n",
    "            continue\n",
    "        # –õ–∏–Ω–µ–π–Ω—ã–µ —Ü–µ–ø–æ—á–∫–∏: –¥–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "        arch.append({'layer': 'Dense', 'units': 1, 'activation': 'linear'})\n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ max_params\n",
    "        if max_params and estimate_params(arch) > max_params:\n",
    "            continue\n",
    "        population.append(arch)\n",
    "    return population\n",
    "\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º ---\n",
    "\n",
    "def evaluate_fitness(arch, train_data, val_data, metric='mse', epochs=5, verbose=0):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç –∏ –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏—Ç–Ω–µ—Å = - (–∑–Ω–∞—á–µ–Ω–∏–µ val_metric).\n",
    "    train_data, val_data: –∫–æ—Ä—Ç–µ–∂–∏ (X, y).\n",
    "    metric: —Å—Ç—Ä–æ–∫–∞ Keras ('mse', 'mae' –∏ —Ç.–¥.).\n",
    "    \"\"\"\n",
    "    X_train, y_train = train_data\n",
    "    X_val, y_val = val_data\n",
    "    model = build_model_from_architecture(arch, X_train.shape[1:])\n",
    "    model.compile(optimizer='adam', loss=metric, metrics=[metric])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏\n",
    "    val_res = history.history['val_' + metric][-1]\n",
    "    return -val_res\n",
    "\n",
    "\n",
    "def select_parents(population, fitnesses, k=3):\n",
    "    \"\"\"\n",
    "    –¢—É—Ä–Ω–∏—Ä–Ω–∞—è —Å–µ–ª–µ–∫—Ü–∏—è: –≤—ã–±–∏—Ä–∞–µ–º k —Å–ª—É—á–∞–π–Ω—ã—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 2 —Ä–æ–¥–∏—Ç–µ–ª—è.\n",
    "    \"\"\"\n",
    "    parents = []\n",
    "    for _ in range(2):\n",
    "        contenders = random.sample(list(zip(population, fitnesses)), k)\n",
    "        parents.append(max(contenders, key=lambda x: x[1])[0])\n",
    "    return parents\n",
    "\n",
    "\n",
    "def crossover(parent_a, parent_b):\n",
    "    \"\"\"\n",
    "    –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –≥–µ–Ω–æ—Ç–∏–ø–æ–≤ (—Å–ø–∏—Å–∫–æ–≤ —Å–ª–æ—ë–≤).\n",
    "    \"\"\"\n",
    "    cut = random.randint(1, min(len(parent_a), len(parent_b)) - 1)\n",
    "    return parent_a[:cut] + parent_b[cut:]\n",
    "\n",
    "\n",
    "def mutate(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, generators=None):\n",
    "    \"\"\"\n",
    "    –ú—É—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏:\n",
    "      base_mut: –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Å–ª–æ—è;\n",
    "      param_mut: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤;\n",
    "      struct_mut: –≤—Å—Ç–∞–≤–∫–∞/—É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è.\n",
    "    generators: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    generators = generators or [random_dense_layer, random_conv1d_block, random_rnn_block]\n",
    "    new_arch = []\n",
    "    # –®–∞–≥ –ø–æ –∫–∞–∂–¥–æ–º—É —Å–ª–æ—é: –∑–∞–º–µ–Ω–∞ –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –º—É—Ç–∞—Ü–∏—è\n",
    "    for layer in arch:\n",
    "        r = random.random()\n",
    "        if r < base_mut:\n",
    "            # –ó–∞–º–µ–Ω—è–µ–º —Å–ª–æ–π –ø–æ–ª–Ω–æ—Å—Ç—å—é\n",
    "            new_arch.append(random.choice(generators)())\n",
    "        elif r < base_mut + param_mut:\n",
    "            # –ú—É—Ç–∏—Ä—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "            l = layer.copy()\n",
    "            if 'units' in l:\n",
    "                l['units'] = max(1, int(l['units'] * random.uniform(0.5, 1.5)))\n",
    "            if 'dropout' in l:\n",
    "                l['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "            new_arch.append(l)\n",
    "        else:\n",
    "            # –û—Å—Ç–∞–≤–ª—è–µ–º —Å–ª–æ–π –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "            new_arch.append(layer)\n",
    "    # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º—É—Ç–∞—Ü–∏–∏: –≤—Å—Ç–∞–≤–∫–∞ –∏/–∏–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è\n",
    "    if random.random() < struct_mut:\n",
    "        pos = random.randint(0, len(new_arch))\n",
    "        new_arch.insert(pos, random.choice(generators)())\n",
    "    if random.random() < struct_mut and len(new_arch) > 1:\n",
    "        pos = random.randrange(len(new_arch))\n",
    "        new_arch.pop(pos)\n",
    "    return new_arch\n",
    "\n",
    "\n",
    "def run_ga(\n",
    "    train_data, val_data,\n",
    "    pop_size=20,\n",
    "    generations=10,\n",
    "    max_params=None,\n",
    "    elitism=2,\n",
    "    metric='mse',\n",
    "    epochs=5\n",
    "):\n",
    "    \"\"\"\n",
    "    –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:\n",
    "      - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "      - –û—Ü–µ–Ω–∫–∞ —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "      - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç–ª–∏—Ç–∏–∑–º–∞, —Å–µ–ª–µ–∫—Ü–∏–∏, –∫—Ä–æ—Å—Å–æ–≤–µ—Ä–∞ –∏ –º—É—Ç–∞—Ü–∏–∏\n",
    "      - –í–æ–∑–≤—Ä–∞—Ç –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –µ—ë —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "    \"\"\"\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    population = generate_population(pop_size=pop_size, max_params=max_params)\n",
    "    fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    for gen in range(generations):\n",
    "        print(f\"Gen {gen+1}/{generations}\")\n",
    "        # --- –≠–ª–∏—Ç–∏–∑–º: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-N –ª—É—á—à–∏—Ö ---\n",
    "        elite_idx = sorted(range(len(population)), key=lambda i: fitnesses[i], reverse=True)[:elitism]\n",
    "        new_population = [population[i] for i in elite_idx]\n",
    "\n",
    "        # --- –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –Ω–æ–≤—ã—Ö –æ—Å–æ–±–µ–π ---\n",
    "        while len(new_population) < pop_size:\n",
    "            p1, p2 = select_parents(population, fitnesses)\n",
    "            child = crossover(p1, p2)\n",
    "            child = mutate(child)\n",
    "            new_population.append(child)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É\n",
    "    best_arch, best_fit = max(zip(population, fitnesses), key=lambda x: x[1])\n",
    "    return best_arch, best_fit\n",
    "\n",
    "# TODO: —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ train_data –∏ val_data ‚Äî –∫–æ—Ä—Ç–µ–∂–∏ (X, y), metric ‚Äî –≤–∞–ª–∏–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0219e05d-5158-4d53-bb7d-ef7b27d059f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 438\u001b[39m\n\u001b[32m    435\u001b[39m val_data = (X[split:], y[split:])\n\u001b[32m    437\u001b[39m \u001b[38;5;66;03m# –ó–∞–ø—É—Å–∫–∞–µ–º GA\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m best_arch, best_fit = \u001b[43mrun_ga\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_params\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43melitism\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmse\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m    444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest fitness:\u001b[39m\u001b[33m\"\u001b[39m, best_fit)\n\u001b[32m    447\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest architecture:\u001b[39m\u001b[33m\"\u001b[39m, best_arch)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 374\u001b[39m, in \u001b[36mrun_ga\u001b[39m\u001b[34m(train_data, val_data, pop_size, generations, max_params, elitism, metric, epochs)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\u001b[39;00m\n\u001b[32m    373\u001b[39m population = generate_population(pop_size=pop_size, max_params=max_params)\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m fitnesses = [\u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(generations):\n\u001b[32m    377\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerations\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 286\u001b[39m, in \u001b[36mevaluate_fitness\u001b[39m\u001b[34m(arch, train_data, val_data, metric, epochs, verbose)\u001b[39m\n\u001b[32m    284\u001b[39m X_train, y_train = train_data\n\u001b[32m    285\u001b[39m X_val, y_val = val_data\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m model = \u001b[43mbuild_model_from_architecture\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=metric, metrics=[metric])\n\u001b[32m    288\u001b[39m history = model.fit(\n\u001b[32m    289\u001b[39m     X_train, y_train,\n\u001b[32m    290\u001b[39m     validation_data=(X_val, y_val),\n\u001b[32m    291\u001b[39m     epochs=epochs,\n\u001b[32m    292\u001b[39m     verbose=verbose\n\u001b[32m    293\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mbuild_model_from_architecture\u001b[39m\u001b[34m(arch, input_shape)\u001b[39m\n\u001b[32m     91\u001b[39m x = inp\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m arch:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     t = \u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlayer\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m# --- –°–≤—ë—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫ ---\u001b[39;00m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m t == \u001b[33m'\u001b[39m\u001b[33mConv1D\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv1D, GlobalAveragePooling1D, Flatten,\n",
    "    GRU, SimpleRNN, BatchNormalization, Activation, Dropout\n",
    ")\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –±–ª–æ–∫–æ–≤ —Å–ª–æ—ë–≤ ---\n",
    "\n",
    "def random_dense_layer(units_choices=None):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞—ë—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "      units_choices: —Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —á–∏—Å–µ–ª –Ω–µ–π—Ä–æ–Ω–æ–≤.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–∞–º–∏:\n",
    "      layer, units, activation, kernel_regularizer, coef_regularizer (–æ–ø—Ü.), dropout\n",
    "    \"\"\"\n",
    "    units_choices = units_choices or [32, 64, 128, 256]\n",
    "    layer = {\n",
    "        'layer': 'Dense',\n",
    "        'units': random.choice(units_choices),\n",
    "        'activation': random.choice(['relu', 'sigmoid', 'tanh', 'linear']),\n",
    "        'kernel_regularizer': random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    }\n",
    "    # –ï—Å–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –≤—ã–±—Ä–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç\n",
    "    if layer['kernel_regularizer']:\n",
    "        layer['coef_regularizer'] = random.choice([0.0001, 0.001, 0.01, 0.1])\n",
    "    # Dropout –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    return layer\n",
    "\n",
    "\n",
    "def random_conv1d_block():\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –æ–¥–Ω–æ-–º–µ—Ä–Ω–æ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ –±–ª–æ–∫–∞.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Å–ª–æ–≤–∞—Ä–µ:\n",
    "      layer, filters, kernel_size, strides, padding, activation,\n",
    "      batch_norm, dropout, pooling.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': 'Conv1D',\n",
    "        'filters': random.choice([32, 64, 128, 256]),\n",
    "        'kernel_size': random.choice([3, 5, 7]),\n",
    "        'strides': random.choice([1, 2]),\n",
    "        'padding': random.choice(['valid', 'same']),\n",
    "        'activation': random.choice(['relu', 'tanh', 'sigmoid', 'elu']),\n",
    "        'batch_norm': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'pooling': random.choice([None, 'max2', 'max3'])\n",
    "    }\n",
    "\n",
    "\n",
    "def random_rnn_block(rnn_type='GRU'):\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–≥–æ –±–ª–æ–∫–∞ GRU –∏–ª–∏ RNN.\n",
    "    –ü–æ–ª—è:\n",
    "      layer, units, activation, return_sequences,\n",
    "      dropout, recurrent_dropout\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': rnn_type,\n",
    "        'units': random.choice([32, 64, 128]),\n",
    "        'activation': random.choice(['tanh', 'relu']),\n",
    "        'return_sequences': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'recurrent_dropout': random.choice([0.0, 0.1])\n",
    "    }\n",
    "\n",
    "\n",
    "def flatten_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è Flatten.\"\"\"\n",
    "    return {'layer': 'Flatten'}\n",
    "\n",
    "\n",
    "def global_pool_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è GlobalAveragePooling1D.\"\"\"\n",
    "    return {'layer': 'GlobalAvgPool1D'}\n",
    "\n",
    "\n",
    "# --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Keras-–º–æ–¥–µ–ª–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---\n",
    "\n",
    "def build_model_from_architecture(arch, input_shape):\n",
    "    \"\"\"\n",
    "    –ö–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç Keras Model –ø–æ —Å–ø–∏—Å–∫—É –æ–ø–∏—Å–∞–Ω–∏–π —Å–ª–æ—ë–≤ arch.\n",
    "    –ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç arch:\n",
    "      - dict —Å –∫–ª—é—á–æ–º 'layer' –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = inp\n",
    "    for l in arch:\n",
    "        t = l['layer']\n",
    "        # --- –°–≤—ë—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫ ---\n",
    "        if t == 'Conv1D':\n",
    "            x = Conv1D(\n",
    "                filters=l['filters'],\n",
    "                kernel_size=l['kernel_size'],\n",
    "                strides=l['strides'],\n",
    "                padding=l['padding'],\n",
    "                activation=None\n",
    "            )(x)\n",
    "            # BatchNorm –ø–æ—Å–ª–µ —Å–≤—ë—Ä—Ç–∫–∏\n",
    "            if l['batch_norm']:\n",
    "                x = BatchNormalization()(x)\n",
    "            x = Activation(l['activation'])(x)\n",
    "            if l['dropout'] > 0:\n",
    "                x = Dropout(l['dropout'])(x)\n",
    "            # Pooling: –∏—Å—Ç–∏–Ω–Ω–æ –¥–ª—è 'max2' –∏–ª–∏ 'max3'\n",
    "            if l['pooling'] in ('max2', 'max3'):\n",
    "                x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "        # --- –†–µ–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –±–ª–æ–∫ (GRU –∏–ª–∏ SimpleRNN) ---\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            layer_cls = GRU if t == 'GRU' else SimpleRNN\n",
    "            cell = layer_cls(\n",
    "                units=l['units'],\n",
    "                activation=l['activation'],\n",
    "                return_sequences=l['return_sequences'],\n",
    "                dropout=l['dropout'],\n",
    "                recurrent_dropout=l['recurrent_dropout']\n",
    "            )\n",
    "            x = cell(x)\n",
    "\n",
    "        # --- –£–ø–ª–æ—â–µ–Ω–∏–µ –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø—É–ª–ª–∏–Ω–≥ ---\n",
    "        elif t == 'Flatten':\n",
    "            x = Flatten()(x)\n",
    "        elif t == 'GlobalAvgPool1D':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "        # --- –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π ---\n",
    "        elif t == 'Dense':\n",
    "            # –í—ã–±–æ—Ä —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä–∞\n",
    "            reg = None\n",
    "            if l.get('kernel_regularizer') == 'L1':\n",
    "                reg = l1(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L2':\n",
    "                reg = l2(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L1L2':\n",
    "                reg = l1_l2(l['coef_regularizer'])\n",
    "\n",
    "            x = Dense(\n",
    "                units=l['units'],\n",
    "                activation=l['activation'],\n",
    "                kernel_regularizer=reg\n",
    "            )(x)\n",
    "            if l.get('dropout', 0) > 0:\n",
    "                x = Dropout(l['dropout'])(x)\n",
    "\n",
    "        # –ò–Ω–∞—á–µ: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø\n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "# --- –û—Ü–µ–Ω–∫–∞ —á–∏—Å–ª–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ (–≥—Ä—É–±–∞—è) ---\n",
    "\n",
    "def estimate_params(layers):\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ—Ç —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Å–ø–∏—Å–∫—É —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    prev_units = None\n",
    "    for l in layers:\n",
    "        t = l.get('layer')\n",
    "        if t == 'Dense':\n",
    "            u = l['units']\n",
    "            total += (prev_units or u) * u + u\n",
    "            prev_units = u\n",
    "        elif t == 'Conv1D':\n",
    "            f, k = l['filters'], l['kernel_size']\n",
    "            total += (prev_units or f) * k + f\n",
    "            prev_units = f\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            u = l['units']\n",
    "            # —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä—ë—Ö –≤—Ö–æ–¥–Ω—ã—Ö –≤–µ—Å–æ–≤ + bias\n",
    "            total += u * (prev_units or u) * 3 + u * 3\n",
    "            prev_units = u\n",
    "    return total\n",
    "\n",
    "\n",
    "# --- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏ ---\n",
    "# –°–ª—É—á–∞–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω—ã–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏\n",
    "\n",
    "# 1) Conv‚ÜíPool‚ÜíDense skeleton\n",
    "\n",
    "def skeleton_conv_dense(min_conv=1, max_conv=3, min_dense=1, max_dense=2):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_conv, max_conv)):\n",
    "        layers.append(random_conv1d_block())\n",
    "    layers.append(global_pool_block())\n",
    "    for _ in range(random.randint(min_dense, max_dense)):\n",
    "        layers.append(random_dense_layer())\n",
    "    return layers\n",
    "\n",
    "# 2) –ß–∏—Å—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π skeleton\n",
    "\n",
    "def skeleton_rnn(min_rnn=1, max_rnn=2, rnn_type='GRU'):\n",
    "    layers = []\n",
    "    p = random.randint(min_rnn, max_rnn)\n",
    "    for i in range(p):\n",
    "        block = random_rnn_block(rnn_type)\n",
    "        block['return_sequences'] = (i < p - 1)\n",
    "        layers.append(block)\n",
    "    layers.append(random_dense_layer(units_choices=[64, 128]))\n",
    "    return layers\n",
    "\n",
    "# 3) –°–ª—É—á–∞–π–Ω—ã–µ –±–ª–æ–∫–∏\n",
    "\n",
    "def block_randomized(min_blocks=2, max_blocks=5):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_blocks, max_blocks)):\n",
    "        choice = random.choice(['conv', 'rnn', 'dense', 'pool'])\n",
    "        if choice == 'conv':\n",
    "            layers.append(random_conv1d_block())\n",
    "        elif choice == 'rnn':\n",
    "            layers.append(random_rnn_block(random.choice(['GRU', 'RNN'])))\n",
    "        elif choice == 'dense':\n",
    "            layers.append(random_dense_layer())\n",
    "        else:\n",
    "            layers.append(random.choice([flatten_block(), global_pool_block()]))\n",
    "    return layers\n",
    "\n",
    "# 4) –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG: Conv-–≤–µ—Ç–∫–∞ –∏ RNN-–≤–µ—Ç–∫–∞\n",
    "\n",
    "def dag_parallel(min_depth=1, max_depth=3):\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–≤—É—Ö –≤–µ—Ç–æ–∫\n",
    "    a = [random_conv1d_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    a.append(global_pool_block())\n",
    "    b = [random_rnn_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º DAG –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏\n",
    "    return {'parallel': {'conv_branch': a, 'rnn_branch': b}}\n",
    "\n",
    "# 5) –ú–∏–Ω–∏-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞\n",
    "\n",
    "def micro_arch(min_layers=2, max_layers=3):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_layers, max_layers)):\n",
    "        layers.append(random.choice([\n",
    "            random_conv1d_block(), random_rnn_block(), random_dense_layer()\n",
    "        ]))\n",
    "    return layers\n",
    "\n",
    "# –°–±–æ—Ä–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏ —Å —É—á—ë—Ç–æ–º max_params\n",
    "\n",
    "def generate_population(pop_size=20, strategies=None, max_params=None):\n",
    "    \"\"\"\n",
    "    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ø—É–ª—è—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\n",
    "    pop_size: —Ä–∞–∑–º–µ—Ä.\n",
    "    strategies: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤.\n",
    "    max_params: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "    \"\"\"\n",
    "    strategies = strategies or [\n",
    "        skeleton_conv_dense,\n",
    "        skeleton_rnn,\n",
    "        block_randomized,\n",
    "        dag_parallel,\n",
    "        micro_arch\n",
    "    ]\n",
    "    population = []\n",
    "    while len(population) < pop_size:\n",
    "        strat = random.choice(strategies)\n",
    "        arch = strat()  # –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å dict (DAG) –∏–ª–∏ list\n",
    "        if isinstance(arch, dict):\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º DAG –∫–∞–∫ –µ—Å—Ç—å\n",
    "            population.append(arch)\n",
    "            continue\n",
    "        # –õ–∏–Ω–µ–π–Ω—ã–µ —Ü–µ–ø–æ—á–∫–∏: –¥–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "        arch.append({'layer': 'Dense', 'units': 1, 'activation': 'linear'})\n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ max_params\n",
    "        if max_params and estimate_params(arch) > max_params:\n",
    "            continue\n",
    "        population.append(arch)\n",
    "    return population\n",
    "\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º ---\n",
    "\n",
    "def evaluate_fitness(arch, train_data, val_data, metric='mse', epochs=5, verbose=0):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç –∏ –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏—Ç–Ω–µ—Å = - (–∑–Ω–∞—á–µ–Ω–∏–µ val_metric).\n",
    "    train_data, val_data: –∫–æ—Ä—Ç–µ–∂–∏ (X, y).\n",
    "    metric: —Å—Ç—Ä–æ–∫–∞ Keras ('mse', 'mae' –∏ —Ç.–¥.).\n",
    "    \"\"\"\n",
    "    X_train, y_train = train_data\n",
    "    X_val, y_val = val_data\n",
    "    model = build_model_from_architecture(arch, X_train.shape[1:])\n",
    "    model.compile(optimizer='adam', loss=metric, metrics=[metric])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏\n",
    "    val_res = history.history['val_' + metric][-1]\n",
    "    return -val_res\n",
    "\n",
    "\n",
    "def select_parents(population, fitnesses, k=3):\n",
    "    \"\"\"\n",
    "    –¢—É—Ä–Ω–∏—Ä–Ω–∞—è —Å–µ–ª–µ–∫—Ü–∏—è: –≤—ã–±–∏—Ä–∞–µ–º k —Å–ª—É—á–∞–π–Ω—ã—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 2 —Ä–æ–¥–∏—Ç–µ–ª—è.\n",
    "    \"\"\"\n",
    "    parents = []\n",
    "    for _ in range(2):\n",
    "        contenders = random.sample(list(zip(population, fitnesses)), k)\n",
    "        parents.append(max(contenders, key=lambda x: x[1])[0])\n",
    "    return parents\n",
    "\n",
    "\n",
    "def crossover(parent_a, parent_b):\n",
    "    \"\"\"\n",
    "    –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –≥–µ–Ω–æ—Ç–∏–ø–æ–≤ (—Å–ø–∏—Å–∫–æ–≤ —Å–ª–æ—ë–≤).\n",
    "    \"\"\"\n",
    "    cut = random.randint(1, min(len(parent_a), len(parent_b)) - 1)\n",
    "    return parent_a[:cut] + parent_b[cut:]\n",
    "\n",
    "\n",
    "def mutate(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, generators=None):\n",
    "    \"\"\"\n",
    "    –ú—É—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏:\n",
    "      base_mut: –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Å–ª–æ—è;\n",
    "      param_mut: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤;\n",
    "      struct_mut: –≤—Å—Ç–∞–≤–∫–∞/—É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è.\n",
    "    generators: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    generators = generators or [random_dense_layer, random_conv1d_block, random_rnn_block]\n",
    "    new_arch = []\n",
    "    # –®–∞–≥ –ø–æ –∫–∞–∂–¥–æ–º—É —Å–ª–æ—é: –∑–∞–º–µ–Ω–∞ –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –º—É—Ç–∞—Ü–∏—è\n",
    "    for layer in arch:\n",
    "        r = random.random()\n",
    "        if r < base_mut:\n",
    "            # –ó–∞–º–µ–Ω—è–µ–º —Å–ª–æ–π –ø–æ–ª–Ω–æ—Å—Ç—å—é\n",
    "            new_arch.append(random.choice(generators)())\n",
    "        elif r < base_mut + param_mut:\n",
    "            # –ú—É—Ç–∏—Ä—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "            l = layer.copy()\n",
    "            if 'units' in l:\n",
    "                l['units'] = max(1, int(l['units'] * random.uniform(0.5, 1.5)))\n",
    "            if 'dropout' in l:\n",
    "                l['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "            new_arch.append(l)\n",
    "        else:\n",
    "            # –û—Å—Ç–∞–≤–ª—è–µ–º —Å–ª–æ–π –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "            new_arch.append(layer)\n",
    "    # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º—É—Ç–∞—Ü–∏–∏: –≤—Å—Ç–∞–≤–∫–∞ –∏/–∏–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è\n",
    "    if random.random() < struct_mut:\n",
    "        pos = random.randint(0, len(new_arch))\n",
    "        new_arch.insert(pos, random.choice(generators)())\n",
    "    if random.random() < struct_mut and len(new_arch) > 1:\n",
    "        pos = random.randrange(len(new_arch))\n",
    "        new_arch.pop(pos)\n",
    "    return new_arch\n",
    "\n",
    "\n",
    "def run_ga(\n",
    "    train_data, val_data,\n",
    "    pop_size=20,\n",
    "    generations=10,\n",
    "    max_params=None,\n",
    "    elitism=2,\n",
    "    metric='mse',\n",
    "    epochs=5\n",
    "):\n",
    "    \"\"\"\n",
    "    –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:\n",
    "      - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "      - –û—Ü–µ–Ω–∫–∞ —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "      - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç–ª–∏—Ç–∏–∑–º–∞, —Å–µ–ª–µ–∫—Ü–∏–∏, –∫—Ä–æ—Å—Å–æ–≤–µ—Ä–∞ –∏ –º—É—Ç–∞—Ü–∏–∏\n",
    "      - –í–æ–∑–≤—Ä–∞—Ç –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –µ—ë —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "    \"\"\"\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    population = generate_population(pop_size=pop_size, max_params=max_params)\n",
    "    fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    for gen in range(generations):\n",
    "        print(f\"Gen {gen+1}/{generations}\")\n",
    "        # --- –≠–ª–∏—Ç–∏–∑–º: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-N –ª—É—á—à–∏—Ö ---\n",
    "        elite_idx = sorted(range(len(population)), key=lambda i: fitnesses[i], reverse=True)[:elitism]\n",
    "        new_population = [population[i] for i in elite_idx]\n",
    "\n",
    "        # --- –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –Ω–æ–≤—ã—Ö –æ—Å–æ–±–µ–π ---\n",
    "        while len(new_population) < pop_size:\n",
    "            p1, p2 = select_parents(population, fitnesses)\n",
    "            child = crossover(p1, p2)\n",
    "            child = mutate(child)\n",
    "            new_population.append(child)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É\n",
    "    best_arch, best_fit = max(zip(population, fitnesses), key=lambda x: x[1])\n",
    "    return best_arch, best_fit\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö Mackey-Glass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä—è–¥–∞\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def generate_mackey_glass(beta=0.2, gamma=0.1, n=10, tau=17,\n",
    "                              dt=0.1, total_time=1000, burn_in_time=100):\n",
    "        total_steps = int((total_time + burn_in_time) / dt)\n",
    "        burn_in_steps = int(burn_in_time / dt)\n",
    "        tau_steps = int(tau / dt)\n",
    "        # –†–∞–≤–Ω–æ–≤–µ—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        x0 = ((beta / gamma) - 1)**(1/n)\n",
    "        x = np.zeros(total_steps)\n",
    "        x[:tau_steps] = x0 + 0.01 * np.random.randn(tau_steps)\n",
    "        # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        for t in range(tau_steps, total_steps):\n",
    "            dx = dt * (beta * x[t - tau_steps] / (1 + x[t - tau_steps]**n)\n",
    "                       - gamma * x[t - 1])\n",
    "            x[t] = x[t - 1] + dx\n",
    "        # –û—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º burn-in\n",
    "        x = x[burn_in_steps:]\n",
    "        t_axis = np.linspace(0, total_time, len(x))\n",
    "        return t_axis, x\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ–∫–Ω–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    t, series = generate_mackey_glass()\n",
    "    window_size = 50\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window_size):\n",
    "        X.append(series[i:i+window_size])\n",
    "        y.append(series[i+window_size])\n",
    "    X = np.array(X)[..., np.newaxis]  # (N, window, 1)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # –î–µ–ª–∏–º –Ω–∞ train/val\n",
    "    split = int(0.8 * len(X))\n",
    "    train_data = (X[:split], y[:split])\n",
    "    val_data = (X[split:], y[split:])\n",
    "\n",
    "    # –ó–∞–ø—É—Å–∫–∞–µ–º GA\n",
    "    best_arch, best_fit = run_ga(\n",
    "        train_data, val_data,\n",
    "        pop_size=10, generations=5,\n",
    "        max_params=50000,\n",
    "        elitism=2,\n",
    "        metric='mse', epochs=3\n",
    "    )\n",
    "\n",
    "    print(\"Best fitness:\", best_fit)\n",
    "    print(\"Best architecture:\", best_arch)\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Å—Ç–∏ —Ä—è–¥–∞\n",
    "    plt.plot(t[window_size:window_size+200], series[window_size:window_size+200], label='True')\n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "    model = build_model_from_architecture(best_arch, train_data[0].shape[1:])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    preds = model.predict(train_data[0][:200])\n",
    "    plt.plot(t[window_size:window_size+200], preds.flatten(), label='Pred')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4763dbb6-f2f8-4508-84ab-05606ec19d60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"gru_3\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 440\u001b[39m\n\u001b[32m    437\u001b[39m val_data = (X[split:], y[split:])\n\u001b[32m    439\u001b[39m \u001b[38;5;66;03m# –ó–∞–ø—É—Å–∫–∞–µ–º GA\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m best_arch, best_fit = \u001b[43mrun_ga\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_params\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43melitism\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmse\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m    446\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest fitness:\u001b[39m\u001b[33m\"\u001b[39m, best_fit)\n\u001b[32m    449\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest architecture:\u001b[39m\u001b[33m\"\u001b[39m, best_arch)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 376\u001b[39m, in \u001b[36mrun_ga\u001b[39m\u001b[34m(train_data, val_data, pop_size, generations, max_params, elitism, metric, epochs)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\u001b[39;00m\n\u001b[32m    375\u001b[39m population = generate_population(pop_size=pop_size, max_params=max_params)\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m fitnesses = [\u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(generations):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerations\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 288\u001b[39m, in \u001b[36mevaluate_fitness\u001b[39m\u001b[34m(arch, train_data, val_data, metric, epochs, verbose)\u001b[39m\n\u001b[32m    286\u001b[39m X_train, y_train = train_data\n\u001b[32m    287\u001b[39m X_val, y_val = val_data\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m model = \u001b[43mbuild_model_from_architecture\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=metric, metrics=[metric])\n\u001b[32m    290\u001b[39m history = model.fit(\n\u001b[32m    291\u001b[39m     X_train, y_train,\n\u001b[32m    292\u001b[39m     validation_data=(X_val, y_val),\n\u001b[32m    293\u001b[39m     epochs=epochs,\n\u001b[32m    294\u001b[39m     verbose=verbose\n\u001b[32m    295\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 116\u001b[39m, in \u001b[36mbuild_model_from_architecture\u001b[39m\u001b[34m(arch, input_shape)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m l[\u001b[33m'\u001b[39m\u001b[33mlayer\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mGRU\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mRNN\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    115\u001b[39m     layer_cls = GRU \u001b[38;5;28;01mif\u001b[39;00m l[\u001b[33m'\u001b[39m\u001b[33mlayer\u001b[39m\u001b[33m'\u001b[39m]==\u001b[33m'\u001b[39m\u001b[33mGRU\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m SimpleRNN\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     x2 = \u001b[43mlayer_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munits\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mactivation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreturn_sequences\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdropout\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrecurrent_dropout\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m l[\u001b[33m'\u001b[39m\u001b[33mlayer\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mGlobalAvgPool1D\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    120\u001b[39m     x2 = GlobalAveragePooling1D()(x2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/keras/src/layers/input_spec.py:186\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m spec.allow_last_axis_squeeze:\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ndim != spec.ndim:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    187\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of layer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    188\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis incompatible with the layer: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    191\u001b[39m         )\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.max_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim > spec.max_ndim:\n",
      "\u001b[31mValueError\u001b[39m: Input 0 of layer \"gru_3\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 128)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv1D, GlobalAveragePooling1D, Flatten,\n",
    "    GRU, SimpleRNN, BatchNormalization, Activation, Dropout\n",
    ")\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –±–ª–æ–∫–æ–≤ —Å–ª–æ—ë–≤ ---\n",
    "\n",
    "def random_dense_layer(units_choices=None):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞—ë—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "      units_choices: —Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —á–∏—Å–µ–ª –Ω–µ–π—Ä–æ–Ω–æ–≤.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–∞–º–∏:\n",
    "      layer, units, activation, kernel_regularizer, coef_regularizer (–æ–ø—Ü.), dropout\n",
    "    \"\"\"\n",
    "    units_choices = units_choices or [32, 64, 128, 256]\n",
    "    layer = {\n",
    "        'layer': 'Dense',\n",
    "        'units': random.choice(units_choices),\n",
    "        'activation': random.choice(['relu', 'sigmoid', 'tanh', 'linear']),\n",
    "        'kernel_regularizer': random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    }\n",
    "    # –ï—Å–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –≤—ã–±—Ä–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç\n",
    "    if layer['kernel_regularizer']:\n",
    "        layer['coef_regularizer'] = random.choice([0.0001, 0.001, 0.01, 0.1])\n",
    "    # Dropout –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    return layer\n",
    "\n",
    "\n",
    "def random_conv1d_block():\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –æ–¥–Ω–æ-–º–µ—Ä–Ω–æ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ –±–ª–æ–∫–∞.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Å–ª–æ–≤–∞—Ä–µ:\n",
    "      layer, filters, kernel_size, strides, padding, activation,\n",
    "      batch_norm, dropout, pooling.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': 'Conv1D',\n",
    "        'filters': random.choice([32, 64, 128, 256]),\n",
    "        'kernel_size': random.choice([3, 5, 7]),\n",
    "        'strides': random.choice([1, 2]),\n",
    "        'padding': random.choice(['valid', 'same']),\n",
    "        'activation': random.choice(['relu', 'tanh', 'sigmoid', 'elu']),\n",
    "        'batch_norm': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'pooling': random.choice([None, 'max2', 'max3'])\n",
    "    }\n",
    "\n",
    "\n",
    "def random_rnn_block(rnn_type='GRU'):\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–≥–æ –±–ª–æ–∫–∞ GRU –∏–ª–∏ RNN.\n",
    "    –ü–æ–ª—è:\n",
    "      layer, units, activation, return_sequences,\n",
    "      dropout, recurrent_dropout\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': rnn_type,\n",
    "        'units': random.choice([32, 64, 128]),\n",
    "        'activation': random.choice(['tanh', 'relu']),\n",
    "        'return_sequences': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'recurrent_dropout': random.choice([0.0, 0.1])\n",
    "    }\n",
    "\n",
    "\n",
    "def flatten_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è Flatten.\"\"\"\n",
    "    return {'layer': 'Flatten'}\n",
    "\n",
    "\n",
    "def global_pool_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è GlobalAveragePooling1D.\"\"\"\n",
    "    return {'layer': 'GlobalAvgPool1D'}\n",
    "\n",
    "\n",
    "# --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Keras-–º–æ–¥–µ–ª–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---\n",
    "\n",
    "def build_model_from_architecture(arch, input_shape):\n",
    "    \"\"\"\n",
    "    –ö–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç Keras Model –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:\n",
    "      - –õ–∏–Ω–µ–π–Ω—ã–µ —Å–ø–∏—Å–∫–∏ —Å–ª–æ—ë–≤ (list of dict)\n",
    "      - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG —Å –∫–ª—é—á–æ–º 'parallel'\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ DAG-–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        from tensorflow.keras.layers import Concatenate\n",
    "        # –í–µ—Ç–∫–∏\n",
    "        conv_branch = arch['parallel']['conv_branch']\n",
    "        rnn_branch = arch['parallel']['rnn_branch']\n",
    "        # –ü—Ä–æ—Ö–æ–¥ –ø–æ Conv –≤–µ—Ç–∫–µ\n",
    "        x1 = inp\n",
    "        for l in conv_branch:\n",
    "            if l['layer'] == 'Conv1D':\n",
    "                x1 = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'],\n",
    "                            strides=l['strides'], padding=l['padding'], activation=None)(x1)\n",
    "                if l['batch_norm']: x1 = BatchNormalization()(x1)\n",
    "                x1 = Activation(l['activation'])(x1)\n",
    "                if l['dropout'] > 0: x1 = Dropout(l['dropout'])(x1)\n",
    "            elif l['layer'] == 'GlobalAvgPool1D':\n",
    "                x1 = GlobalAveragePooling1D()(x1)\n",
    "            elif l['layer'] == 'Flatten':\n",
    "                x1 = Flatten()(x1)\n",
    "        # –ü—Ä–æ—Ö–æ–¥ –ø–æ RNN –≤–µ—Ç–∫–µ\n",
    "        x2 = inp\n",
    "        for l in rnn_branch:\n",
    "            if l['layer'] in ('GRU','RNN'):\n",
    "                layer_cls = GRU if l['layer']=='GRU' else SimpleRNN\n",
    "                x2 = layer_cls(units=l['units'], activation=l['activation'],\n",
    "                                return_sequences=l['return_sequences'],\n",
    "                                dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])(x2)\n",
    "            elif l['layer'] == 'GlobalAvgPool1D':\n",
    "                x2 = GlobalAveragePooling1D()(x2)\n",
    "            elif l['layer'] == 'Flatten':\n",
    "                x2 = Flatten()(x2)\n",
    "        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Ç–æ–∫ –∏ –≤—ã—Ö–æ–¥\n",
    "        merged = Concatenate()([x1, x2])\n",
    "        out = Dense(1, activation='linear')(merged)\n",
    "        return Model(inputs=inp, outputs=out)\n",
    "    # –û–±—ã—á–Ω–∞—è –ª–∏–Ω–µ–π–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (list)\n",
    "    x = inp\n",
    "    for l in arch:\n",
    "        t = l['layer']\n",
    "        if t == 'Conv1D':\n",
    "            x = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'], strides=l['strides'],\n",
    "                       padding=l['padding'], activation=None)(x)\n",
    "            if l['batch_norm']: x = BatchNormalization()(x)\n",
    "            x = Activation(l['activation'])(x)\n",
    "            if l['dropout'] > 0: x = Dropout(l['dropout'])(x)\n",
    "            if l['pooling'] in ('max2', 'max3'): x = GlobalAveragePooling1D()(x)\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            layer_cls = GRU if t == 'GRU' else SimpleRNN\n",
    "            x = layer_cls(l['units'], activation=l['activation'], return_sequences=l['return_sequences'],\n",
    "                         dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])(x)\n",
    "        elif t == 'Flatten':\n",
    "            x = Flatten()(x)\n",
    "        elif t == 'GlobalAvgPool1D':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif t == 'Dense':\n",
    "            reg = None\n",
    "            if l.get('kernel_regularizer') == 'L1': reg = l1(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L2': reg = l2(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L1L2': reg = l1_l2(l['coef_regularizer'])\n",
    "            x = Dense(l['units'], activation=l['activation'], kernel_regularizer=reg)(x)\n",
    "            if l.get('dropout',0) > 0: x = Dropout(l['dropout'])(x)\n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "# --- –û—Ü–µ–Ω–∫–∞ —á–∏—Å–ª–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ (–≥—Ä—É–±–∞—è) ---\n",
    "\n",
    "def estimate_params(layers):\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ—Ç —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Å–ø–∏—Å–∫—É —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    prev_units = None\n",
    "    for l in layers:\n",
    "        t = l.get('layer')\n",
    "        if t == 'Dense':\n",
    "            u = l['units']\n",
    "            total += (prev_units or u) * u + u\n",
    "            prev_units = u\n",
    "        elif t == 'Conv1D':\n",
    "            f, k = l['filters'], l['kernel_size']\n",
    "            total += (prev_units or f) * k + f\n",
    "            prev_units = f\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            u = l['units']\n",
    "            # —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä—ë—Ö –≤—Ö–æ–¥–Ω—ã—Ö –≤–µ—Å–æ–≤ + bias\n",
    "            total += u * (prev_units or u) * 3 + u * 3\n",
    "            prev_units = u\n",
    "    return total\n",
    "\n",
    "\n",
    "# --- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏ ---\n",
    "# –°–ª—É—á–∞–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω—ã–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏\n",
    "\n",
    "# 1) Conv‚ÜíPool‚ÜíDense skeleton\n",
    "\n",
    "def skeleton_conv_dense(min_conv=1, max_conv=3, min_dense=1, max_dense=2):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_conv, max_conv)):\n",
    "        layers.append(random_conv1d_block())\n",
    "    layers.append(global_pool_block())\n",
    "    for _ in range(random.randint(min_dense, max_dense)):\n",
    "        layers.append(random_dense_layer())\n",
    "    return layers\n",
    "\n",
    "# 2) –ß–∏—Å—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π skeleton\n",
    "\n",
    "def skeleton_rnn(min_rnn=1, max_rnn=2, rnn_type='GRU'):\n",
    "    layers = []\n",
    "    p = random.randint(min_rnn, max_rnn)\n",
    "    for i in range(p):\n",
    "        block = random_rnn_block(rnn_type)\n",
    "        block['return_sequences'] = (i < p - 1)\n",
    "        layers.append(block)\n",
    "    layers.append(random_dense_layer(units_choices=[64, 128]))\n",
    "    return layers\n",
    "\n",
    "# 3) –°–ª—É—á–∞–π–Ω—ã–µ –±–ª–æ–∫–∏\n",
    "\n",
    "def block_randomized(min_blocks=2, max_blocks=5):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_blocks, max_blocks)):\n",
    "        choice = random.choice(['conv', 'rnn', 'dense', 'pool'])\n",
    "        if choice == 'conv':\n",
    "            layers.append(random_conv1d_block())\n",
    "        elif choice == 'rnn':\n",
    "            layers.append(random_rnn_block(random.choice(['GRU', 'RNN'])))\n",
    "        elif choice == 'dense':\n",
    "            layers.append(random_dense_layer())\n",
    "        else:\n",
    "            layers.append(random.choice([flatten_block(), global_pool_block()]))\n",
    "    return layers\n",
    "\n",
    "# 4) –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG: Conv-–≤–µ—Ç–∫–∞ –∏ RNN-–≤–µ—Ç–∫–∞\n",
    "\n",
    "def dag_parallel(min_depth=1, max_depth=3):\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–≤—É—Ö –≤–µ—Ç–æ–∫\n",
    "    a = [random_conv1d_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    a.append(global_pool_block())\n",
    "    b = [random_rnn_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º DAG –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏\n",
    "    return {'parallel': {'conv_branch': a, 'rnn_branch': b}}\n",
    "\n",
    "# 5) –ú–∏–Ω–∏-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞\n",
    "\n",
    "def micro_arch(min_layers=2, max_layers=3):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_layers, max_layers)):\n",
    "        layers.append(random.choice([\n",
    "            random_conv1d_block(), random_rnn_block(), random_dense_layer()\n",
    "        ]))\n",
    "    return layers\n",
    "\n",
    "# –°–±–æ—Ä–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏ —Å —É—á—ë—Ç–æ–º max_params\n",
    "\n",
    "def generate_population(pop_size=20, strategies=None, max_params=None):\n",
    "    \"\"\"\n",
    "    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ø—É–ª—è—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\n",
    "    pop_size: —Ä–∞–∑–º–µ—Ä.\n",
    "    strategies: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤.\n",
    "    max_params: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "    \"\"\"\n",
    "    strategies = strategies or [\n",
    "        skeleton_conv_dense,\n",
    "        skeleton_rnn,\n",
    "        block_randomized,\n",
    "        dag_parallel,\n",
    "        micro_arch\n",
    "    ]\n",
    "    population = []\n",
    "    while len(population) < pop_size:\n",
    "        strat = random.choice(strategies)\n",
    "        arch = strat()  # –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å dict (DAG) –∏–ª–∏ list\n",
    "        if isinstance(arch, dict):\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º DAG –∫–∞–∫ –µ—Å—Ç—å\n",
    "            population.append(arch)\n",
    "            continue\n",
    "        # –õ–∏–Ω–µ–π–Ω—ã–µ —Ü–µ–ø–æ—á–∫–∏: –¥–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "        arch.append({'layer': 'Dense', 'units': 1, 'activation': 'linear'})\n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ max_params\n",
    "        if max_params and estimate_params(arch) > max_params:\n",
    "            continue\n",
    "        population.append(arch)\n",
    "    return population\n",
    "\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º ---\n",
    "\n",
    "def evaluate_fitness(arch, train_data, val_data, metric='mse', epochs=5, verbose=0):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç –∏ –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏—Ç–Ω–µ—Å = - (–∑–Ω–∞—á–µ–Ω–∏–µ val_metric).\n",
    "    train_data, val_data: –∫–æ—Ä—Ç–µ–∂–∏ (X, y).\n",
    "    metric: —Å—Ç—Ä–æ–∫–∞ Keras ('mse', 'mae' –∏ —Ç.–¥.).\n",
    "    \"\"\"\n",
    "    X_train, y_train = train_data\n",
    "    X_val, y_val = val_data\n",
    "    model = build_model_from_architecture(arch, X_train.shape[1:])\n",
    "    model.compile(optimizer='adam', loss=metric, metrics=[metric])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏\n",
    "    val_res = history.history['val_' + metric][-1]\n",
    "    return -val_res\n",
    "\n",
    "\n",
    "def select_parents(population, fitnesses, k=3):\n",
    "    \"\"\"\n",
    "    –¢—É—Ä–Ω–∏—Ä–Ω–∞—è —Å–µ–ª–µ–∫—Ü–∏—è: –≤—ã–±–∏—Ä–∞–µ–º k —Å–ª—É—á–∞–π–Ω—ã—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 2 —Ä–æ–¥–∏—Ç–µ–ª—è.\n",
    "    \"\"\"\n",
    "    parents = []\n",
    "    for _ in range(2):\n",
    "        contenders = random.sample(list(zip(population, fitnesses)), k)\n",
    "        parents.append(max(contenders, key=lambda x: x[1])[0])\n",
    "    return parents\n",
    "\n",
    "\n",
    "def crossover(parent_a, parent_b):\n",
    "    \"\"\"\n",
    "    –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –≥–µ–Ω–æ—Ç–∏–ø–æ–≤ (—Å–ø–∏—Å–∫–æ–≤ —Å–ª–æ—ë–≤).\n",
    "    \"\"\"\n",
    "    cut = random.randint(1, min(len(parent_a), len(parent_b)) - 1)\n",
    "    return parent_a[:cut] + parent_b[cut:]\n",
    "\n",
    "\n",
    "def mutate(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, generators=None):\n",
    "    \"\"\"\n",
    "    –ú—É—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏:\n",
    "      base_mut: –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Å–ª–æ—è;\n",
    "      param_mut: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤;\n",
    "      struct_mut: –≤—Å—Ç–∞–≤–∫–∞/—É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è.\n",
    "    generators: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    generators = generators or [random_dense_layer, random_conv1d_block, random_rnn_block]\n",
    "    new_arch = []\n",
    "    # –®–∞–≥ –ø–æ –∫–∞–∂–¥–æ–º—É —Å–ª–æ—é: –∑–∞–º–µ–Ω–∞ –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –º—É—Ç–∞—Ü–∏—è\n",
    "    for layer in arch:\n",
    "        r = random.random()\n",
    "        if r < base_mut:\n",
    "            # –ó–∞–º–µ–Ω—è–µ–º —Å–ª–æ–π –ø–æ–ª–Ω–æ—Å—Ç—å—é\n",
    "            new_arch.append(random.choice(generators)())\n",
    "        elif r < base_mut + param_mut:\n",
    "            # –ú—É—Ç–∏—Ä—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "            l = layer.copy()\n",
    "            if 'units' in l:\n",
    "                l['units'] = max(1, int(l['units'] * random.uniform(0.5, 1.5)))\n",
    "            if 'dropout' in l:\n",
    "                l['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "            new_arch.append(l)\n",
    "        else:\n",
    "            # –û—Å—Ç–∞–≤–ª—è–µ–º —Å–ª–æ–π –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "            new_arch.append(layer)\n",
    "    # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º—É—Ç–∞—Ü–∏–∏: –≤—Å—Ç–∞–≤–∫–∞ –∏/–∏–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è\n",
    "    if random.random() < struct_mut:\n",
    "        pos = random.randint(0, len(new_arch))\n",
    "        new_arch.insert(pos, random.choice(generators)())\n",
    "    if random.random() < struct_mut and len(new_arch) > 1:\n",
    "        pos = random.randrange(len(new_arch))\n",
    "        new_arch.pop(pos)\n",
    "    return new_arch\n",
    "\n",
    "\n",
    "def run_ga(\n",
    "    train_data, val_data,\n",
    "    pop_size=20,\n",
    "    generations=10,\n",
    "    max_params=None,\n",
    "    elitism=2,\n",
    "    metric='mse',\n",
    "    epochs=5\n",
    "):\n",
    "    \"\"\"\n",
    "    –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:\n",
    "      - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "      - –û—Ü–µ–Ω–∫–∞ —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "      - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç–ª–∏—Ç–∏–∑–º–∞, —Å–µ–ª–µ–∫—Ü–∏–∏, –∫—Ä–æ—Å—Å–æ–≤–µ—Ä–∞ –∏ –º—É—Ç–∞—Ü–∏–∏\n",
    "      - –í–æ–∑–≤—Ä–∞—Ç –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –µ—ë —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "    \"\"\"\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    population = generate_population(pop_size=pop_size, max_params=max_params)\n",
    "    fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    for gen in range(generations):\n",
    "        print(f\"Gen {gen+1}/{generations}\")\n",
    "        # --- –≠–ª–∏—Ç–∏–∑–º: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-N –ª—É—á—à–∏—Ö ---\n",
    "        elite_idx = sorted(range(len(population)), key=lambda i: fitnesses[i], reverse=True)[:elitism]\n",
    "        new_population = [population[i] for i in elite_idx]\n",
    "\n",
    "        # --- –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –Ω–æ–≤—ã—Ö –æ—Å–æ–±–µ–π ---\n",
    "        while len(new_population) < pop_size:\n",
    "            p1, p2 = select_parents(population, fitnesses)\n",
    "            child = crossover(p1, p2)\n",
    "            child = mutate(child)\n",
    "            new_population.append(child)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É\n",
    "    best_arch, best_fit = max(zip(population, fitnesses), key=lambda x: x[1])\n",
    "    return best_arch, best_fit\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö Mackey-Glass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä—è–¥–∞\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def generate_mackey_glass(beta=0.2, gamma=0.1, n=10, tau=17,\n",
    "                              dt=0.1, total_time=1000, burn_in_time=100):\n",
    "        total_steps = int((total_time + burn_in_time) / dt)\n",
    "        burn_in_steps = int(burn_in_time / dt)\n",
    "        tau_steps = int(tau / dt)\n",
    "        # –†–∞–≤–Ω–æ–≤–µ—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        x0 = ((beta / gamma) - 1)**(1/n)\n",
    "        x = np.zeros(total_steps)\n",
    "        x[:tau_steps] = x0 + 0.01 * np.random.randn(tau_steps)\n",
    "        # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        for t in range(tau_steps, total_steps):\n",
    "            dx = dt * (beta * x[t - tau_steps] / (1 + x[t - tau_steps]**n)\n",
    "                       - gamma * x[t - 1])\n",
    "            x[t] = x[t - 1] + dx\n",
    "        # –û—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º burn-in\n",
    "        x = x[burn_in_steps:]\n",
    "        t_axis = np.linspace(0, total_time, len(x))\n",
    "        return t_axis, x\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ–∫–Ω–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    t, series = generate_mackey_glass()\n",
    "    window_size = 50\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window_size):\n",
    "        X.append(series[i:i+window_size])\n",
    "        y.append(series[i+window_size])\n",
    "    X = np.array(X)[..., np.newaxis]  # (N, window, 1)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # –î–µ–ª–∏–º –Ω–∞ train/val\n",
    "    split = int(0.8 * len(X))\n",
    "    train_data = (X[:split], y[:split])\n",
    "    val_data = (X[split:], y[split:])\n",
    "\n",
    "    # –ó–∞–ø—É—Å–∫–∞–µ–º GA\n",
    "    best_arch, best_fit = run_ga(\n",
    "        train_data, val_data,\n",
    "        pop_size=10, generations=5,\n",
    "        max_params=50000,\n",
    "        elitism=2,\n",
    "        metric='mse', epochs=3\n",
    "    )\n",
    "\n",
    "    print(\"Best fitness:\", best_fit)\n",
    "    print(\"Best architecture:\", best_arch)\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Å—Ç–∏ —Ä—è–¥–∞\n",
    "    plt.plot(t[window_size:window_size+200], series[window_size:window_size+200], label='True')\n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "    model = build_model_from_architecture(best_arch, train_data[0].shape[1:])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    preds = model.predict(train_data[0][:200])\n",
    "    plt.plot(t[window_size:window_size+200], preds.flatten(), label='Pred')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c22ccd62-6434-4ce3-8219-41ce6ebade19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv1d_5\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 453\u001b[39m\n\u001b[32m    450\u001b[39m val_data = (X[split:], y[split:])\n\u001b[32m    452\u001b[39m \u001b[38;5;66;03m# –ó–∞–ø—É—Å–∫–∞–µ–º GA\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m best_arch, best_fit = \u001b[43mrun_ga\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_params\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43melitism\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmse\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m    459\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest fitness:\u001b[39m\u001b[33m\"\u001b[39m, best_fit)\n\u001b[32m    462\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest architecture:\u001b[39m\u001b[33m\"\u001b[39m, best_arch)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 389\u001b[39m, in \u001b[36mrun_ga\u001b[39m\u001b[34m(train_data, val_data, pop_size, generations, max_params, elitism, metric, epochs)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;66;03m# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\u001b[39;00m\n\u001b[32m    388\u001b[39m population = generate_population(pop_size=pop_size, max_params=max_params)\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m fitnesses = [\u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(generations):\n\u001b[32m    392\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerations\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 301\u001b[39m, in \u001b[36mevaluate_fitness\u001b[39m\u001b[34m(arch, train_data, val_data, metric, epochs, verbose)\u001b[39m\n\u001b[32m    299\u001b[39m X_train, y_train = train_data\n\u001b[32m    300\u001b[39m X_val, y_val = val_data\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m model = \u001b[43mbuild_model_from_architecture\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=metric, metrics=[metric])\n\u001b[32m    303\u001b[39m history = model.fit(\n\u001b[32m    304\u001b[39m     X_train, y_train,\n\u001b[32m    305\u001b[39m     validation_data=(X_val, y_val),\n\u001b[32m    306\u001b[39m     epochs=epochs,\n\u001b[32m    307\u001b[39m     verbose=verbose\n\u001b[32m    308\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 132\u001b[39m, in \u001b[36mbuild_model_from_architecture\u001b[39m\u001b[34m(arch, input_shape)\u001b[39m\n\u001b[32m    130\u001b[39m t = l[\u001b[33m'\u001b[39m\u001b[33mlayer\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t == \u001b[33m'\u001b[39m\u001b[33mConv1D\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     x = \u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfilters\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkernel_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstrides\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m               \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpadding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m l[\u001b[33m'\u001b[39m\u001b[33mbatch_norm\u001b[39m\u001b[33m'\u001b[39m]: x = BatchNormalization()(x)\n\u001b[32m    135\u001b[39m     x = Activation(l[\u001b[33m'\u001b[39m\u001b[33mactivation\u001b[39m\u001b[33m'\u001b[39m])(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/keras/src/layers/input_spec.py:202\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.min_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim < spec.min_ndim:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    203\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of layer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    204\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis incompatible with the layer: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec.min_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         )\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Input 0 of layer \"conv1d_5\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 32)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv1D, GlobalAveragePooling1D, Flatten,\n",
    "    GRU, SimpleRNN, BatchNormalization, Activation, Dropout\n",
    ")\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –±–ª–æ–∫–æ–≤ —Å–ª–æ—ë–≤ ---\n",
    "\n",
    "def random_dense_layer(units_choices=None):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞—ë—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "      units_choices: —Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —á–∏—Å–µ–ª –Ω–µ–π—Ä–æ–Ω–æ–≤.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–∞–º–∏:\n",
    "      layer, units, activation, kernel_regularizer, coef_regularizer (–æ–ø—Ü.), dropout\n",
    "    \"\"\"\n",
    "    units_choices = units_choices or [32, 64, 128, 256]\n",
    "    layer = {\n",
    "        'layer': 'Dense',\n",
    "        'units': random.choice(units_choices),\n",
    "        'activation': random.choice(['relu', 'sigmoid', 'tanh', 'linear']),\n",
    "        'kernel_regularizer': random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    }\n",
    "    # –ï—Å–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –≤—ã–±—Ä–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç\n",
    "    if layer['kernel_regularizer']:\n",
    "        layer['coef_regularizer'] = random.choice([0.0001, 0.001, 0.01, 0.1])\n",
    "    # Dropout –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    return layer\n",
    "\n",
    "\n",
    "def random_conv1d_block():\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –æ–¥–Ω–æ-–º–µ—Ä–Ω–æ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ –±–ª–æ–∫–∞.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Å–ª–æ–≤–∞—Ä–µ:\n",
    "      layer, filters, kernel_size, strides, padding, activation,\n",
    "      batch_norm, dropout, pooling.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': 'Conv1D',\n",
    "        'filters': random.choice([32, 64, 128, 256]),\n",
    "        'kernel_size': random.choice([3, 5, 7]),\n",
    "        'strides': random.choice([1, 2]),\n",
    "        'padding': random.choice(['valid', 'same']),\n",
    "        'activation': random.choice(['relu', 'tanh', 'sigmoid', 'elu']),\n",
    "        'batch_norm': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'pooling': random.choice([None, 'max2', 'max3'])\n",
    "    }\n",
    "\n",
    "\n",
    "def random_rnn_block(rnn_type='GRU'):\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–≥–æ –±–ª–æ–∫–∞ GRU –∏–ª–∏ RNN.\n",
    "    –ü–æ–ª—è:\n",
    "      layer, units, activation, return_sequences,\n",
    "      dropout, recurrent_dropout\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': rnn_type,\n",
    "        'units': random.choice([32, 64, 128]),\n",
    "        'activation': random.choice(['tanh', 'relu']),\n",
    "        'return_sequences': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'recurrent_dropout': random.choice([0.0, 0.1])\n",
    "    }\n",
    "\n",
    "\n",
    "def flatten_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è Flatten.\"\"\"\n",
    "    return {'layer': 'Flatten'}\n",
    "\n",
    "\n",
    "def global_pool_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è GlobalAveragePooling1D.\"\"\"\n",
    "    return {'layer': 'GlobalAvgPool1D'}\n",
    "\n",
    "\n",
    "# --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Keras-–º–æ–¥–µ–ª–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---\n",
    "\n",
    "def build_model_from_architecture(arch, input_shape):\n",
    "    \"\"\"\n",
    "    –ö–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç Keras Model –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:\n",
    "      - –õ–∏–Ω–µ–π–Ω—ã–µ —Å–ø–∏—Å–∫–∏ —Å–ª–æ—ë–≤ (list of dict)\n",
    "      - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG —Å –∫–ª—é—á–æ–º 'parallel'\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ DAG-–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        from tensorflow.keras.layers import Concatenate\n",
    "        # –í–µ—Ç–∫–∏\n",
    "        conv_branch = arch['parallel']['conv_branch']\n",
    "        rnn_branch = arch['parallel']['rnn_branch']\n",
    "        # –ü—Ä–æ—Ö–æ–¥ –ø–æ Conv –≤–µ—Ç–∫–µ\n",
    "        x1 = inp\n",
    "        for l in conv_branch:\n",
    "            if l['layer'] == 'Conv1D':\n",
    "                x1 = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'],\n",
    "                            strides=l['strides'], padding=l['padding'], activation=None)(x1)\n",
    "                if l['batch_norm']: x1 = BatchNormalization()(x1)\n",
    "                x1 = Activation(l['activation'])(x1)\n",
    "                if l['dropout'] > 0: x1 = Dropout(l['dropout'])(x1)\n",
    "            elif l['layer'] == 'GlobalAvgPool1D':\n",
    "                x1 = GlobalAveragePooling1D()(x1)\n",
    "            elif l['layer'] == 'Flatten':\n",
    "                x1 = Flatten()(x1)\n",
    "        # –ü—Ä–æ—Ö–æ–¥ –ø–æ RNN –≤–µ—Ç–∫–µ\n",
    "        x2 = inp\n",
    "        for l in rnn_branch:\n",
    "            if l['layer'] in ('GRU','RNN'):\n",
    "                layer_cls = GRU if l['layer']=='GRU' else SimpleRNN\n",
    "                x2 = layer_cls(units=l['units'], activation=l['activation'],\n",
    "                                return_sequences=l['return_sequences'],\n",
    "                                dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])(x2)\n",
    "            elif l['layer'] == 'GlobalAvgPool1D':\n",
    "                x2 = GlobalAveragePooling1D()(x2)\n",
    "            elif l['layer'] == 'Flatten':\n",
    "                x2 = Flatten()(x2)\n",
    "        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Ç–æ–∫ –∏ –≤—ã—Ö–æ–¥\n",
    "        merged = Concatenate()([x1, x2])\n",
    "        out = Dense(1, activation='linear')(merged)\n",
    "        return Model(inputs=inp, outputs=out)\n",
    "    # –û–±—ã—á–Ω–∞—è –ª–∏–Ω–µ–π–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (list)\n",
    "    x = inp\n",
    "    for l in arch:\n",
    "        t = l['layer']\n",
    "        if t == 'Conv1D':\n",
    "            x = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'], strides=l['strides'],\n",
    "                       padding=l['padding'], activation=None)(x)\n",
    "            if l['batch_norm']: x = BatchNormalization()(x)\n",
    "            x = Activation(l['activation'])(x)\n",
    "            if l['dropout'] > 0: x = Dropout(l['dropout'])(x)\n",
    "            if l['pooling'] in ('max2', 'max3'): x = GlobalAveragePooling1D()(x)\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            layer_cls = GRU if t == 'GRU' else SimpleRNN\n",
    "            x = layer_cls(l['units'], activation=l['activation'], return_sequences=l['return_sequences'],\n",
    "                         dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])(x)\n",
    "        elif t == 'Flatten':\n",
    "            x = Flatten()(x)\n",
    "        elif t == 'GlobalAvgPool1D':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif t == 'Dense':\n",
    "            reg = None\n",
    "            if l.get('kernel_regularizer') == 'L1': reg = l1(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L2': reg = l2(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L1L2': reg = l1_l2(l['coef_regularizer'])\n",
    "            x = Dense(l['units'], activation=l['activation'], kernel_regularizer=reg)(x)\n",
    "            if l.get('dropout',0) > 0: x = Dropout(l['dropout'])(x)\n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "# --- –û—Ü–µ–Ω–∫–∞ —á–∏—Å–ª–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ (–≥—Ä—É–±–∞—è) ---\n",
    "\n",
    "def estimate_params(layers):\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ—Ç —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Å–ø–∏—Å–∫—É —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    prev_units = None\n",
    "    for l in layers:\n",
    "        t = l.get('layer')\n",
    "        if t == 'Dense':\n",
    "            u = l['units']\n",
    "            total += (prev_units or u) * u + u\n",
    "            prev_units = u\n",
    "        elif t == 'Conv1D':\n",
    "            f, k = l['filters'], l['kernel_size']\n",
    "            total += (prev_units or f) * k + f\n",
    "            prev_units = f\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            u = l['units']\n",
    "            # —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä—ë—Ö –≤—Ö–æ–¥–Ω—ã—Ö –≤–µ—Å–æ–≤ + bias\n",
    "            total += u * (prev_units or u) * 3 + u * 3\n",
    "            prev_units = u\n",
    "    return total\n",
    "\n",
    "\n",
    "# --- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏ ---\n",
    "# –°–ª—É—á–∞–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω—ã–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏\n",
    "\n",
    "# 1) Conv‚ÜíPool‚ÜíDense skeleton\n",
    "\n",
    "def skeleton_conv_dense(min_conv=1, max_conv=3, min_dense=1, max_dense=2):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_conv, max_conv)):\n",
    "        layers.append(random_conv1d_block())\n",
    "    layers.append(global_pool_block())\n",
    "    for _ in range(random.randint(min_dense, max_dense)):\n",
    "        layers.append(random_dense_layer())\n",
    "    return layers\n",
    "\n",
    "# 2) –ß–∏—Å—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π skeleton\n",
    "\n",
    "def skeleton_rnn(min_rnn=1, max_rnn=2, rnn_type='GRU'):\n",
    "    layers = []\n",
    "    p = random.randint(min_rnn, max_rnn)\n",
    "    for i in range(p):\n",
    "        block = random_rnn_block(rnn_type)\n",
    "        block['return_sequences'] = (i < p - 1)\n",
    "        layers.append(block)\n",
    "    layers.append(random_dense_layer(units_choices=[64, 128]))\n",
    "    return layers\n",
    "\n",
    "# 3) –°–ª—É—á–∞–π–Ω—ã–µ –±–ª–æ–∫–∏\n",
    "\n",
    "def block_randomized(min_blocks=2, max_blocks=5):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_blocks, max_blocks)):\n",
    "        choice = random.choice(['conv', 'rnn', 'dense', 'pool'])\n",
    "        if choice == 'conv':\n",
    "            layers.append(random_conv1d_block())\n",
    "        elif choice == 'rnn':\n",
    "            layers.append(random_rnn_block(random.choice(['GRU', 'RNN'])))\n",
    "        elif choice == 'dense':\n",
    "            layers.append(random_dense_layer())\n",
    "        else:\n",
    "            layers.append(random.choice([flatten_block(), global_pool_block()]))\n",
    "    return layers\n",
    "\n",
    "# 4) –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG: Conv-–≤–µ—Ç–∫–∞ –∏ RNN-–≤–µ—Ç–∫–∞\n",
    "\n",
    "def dag_parallel(min_depth=1, max_depth=3):\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏:\n",
    "      - conv_branch: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å Conv1D + global pool\n",
    "      - rnn_branch: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å RNN/GRU —Å return_sequences=True —É –≤—Å–µ—Ö, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–æ–º 'parallel'.\n",
    "    \"\"\"\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º —Å–≤—ë—Ä—Ç–æ—á–Ω—É—é –≤–µ—Ç–∫—É\n",
    "    a = [random_conv1d_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    a.append(global_pool_block())\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º RNN –≤–µ—Ç–∫—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º return_sequences\n",
    "    depth = random.randint(min_depth, max_depth)\n",
    "    b = []\n",
    "    for i in range(depth):\n",
    "        block = random_rnn_block(random.choice(['GRU', 'RNN']))\n",
    "        # –≤—Å–µ, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ, –¥–æ–ª–∂–Ω—ã –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "        block['return_sequences'] = (i < depth - 1)\n",
    "        b.append(block)\n",
    "    # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º DAG –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏\n",
    "    return {'parallel': {'conv_branch': a, 'rnn_branch': b}}\n",
    "\n",
    "# 5) –ú–∏–Ω–∏-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞\n",
    "\n",
    "def micro_arch(min_layers=2, max_layers=3):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_layers, max_layers)):\n",
    "        layers.append(random.choice([\n",
    "            random_conv1d_block(), random_rnn_block(), random_dense_layer()\n",
    "        ]))\n",
    "    return layers\n",
    "\n",
    "# –°–±–æ—Ä–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏ —Å —É—á—ë—Ç–æ–º max_params\n",
    "\n",
    "def generate_population(pop_size=20, strategies=None, max_params=None):\n",
    "    \"\"\"\n",
    "    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ø—É–ª—è—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\n",
    "    pop_size: —Ä–∞–∑–º–µ—Ä.\n",
    "    strategies: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤.\n",
    "    max_params: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "    \"\"\"\n",
    "    strategies = strategies or [\n",
    "        skeleton_conv_dense,\n",
    "        skeleton_rnn,\n",
    "        block_randomized,\n",
    "        dag_parallel,\n",
    "        micro_arch\n",
    "    ]\n",
    "    population = []\n",
    "    while len(population) < pop_size:\n",
    "        strat = random.choice(strategies)\n",
    "        arch = strat()  # –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å dict (DAG) –∏–ª–∏ list\n",
    "        if isinstance(arch, dict):\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º DAG –∫–∞–∫ –µ—Å—Ç—å\n",
    "            population.append(arch)\n",
    "            continue\n",
    "        # –õ–∏–Ω–µ–π–Ω—ã–µ —Ü–µ–ø–æ—á–∫–∏: –¥–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "        arch.append({'layer': 'Dense', 'units': 1, 'activation': 'linear'})\n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ max_params\n",
    "        if max_params and estimate_params(arch) > max_params:\n",
    "            continue\n",
    "        population.append(arch)\n",
    "    return population\n",
    "\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º ---\n",
    "\n",
    "def evaluate_fitness(arch, train_data, val_data, metric='mse', epochs=5, verbose=0):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç –∏ –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏—Ç–Ω–µ—Å = - (–∑–Ω–∞—á–µ–Ω–∏–µ val_metric).\n",
    "    train_data, val_data: –∫–æ—Ä—Ç–µ–∂–∏ (X, y).\n",
    "    metric: —Å—Ç—Ä–æ–∫–∞ Keras ('mse', 'mae' –∏ —Ç.–¥.).\n",
    "    \"\"\"\n",
    "    X_train, y_train = train_data\n",
    "    X_val, y_val = val_data\n",
    "    model = build_model_from_architecture(arch, X_train.shape[1:])\n",
    "    model.compile(optimizer='adam', loss=metric, metrics=[metric])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏\n",
    "    val_res = history.history['val_' + metric][-1]\n",
    "    return -val_res\n",
    "\n",
    "\n",
    "def select_parents(population, fitnesses, k=3):\n",
    "    \"\"\"\n",
    "    –¢—É—Ä–Ω–∏—Ä–Ω–∞—è —Å–µ–ª–µ–∫—Ü–∏—è: –≤—ã–±–∏—Ä–∞–µ–º k —Å–ª—É—á–∞–π–Ω—ã—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 2 —Ä–æ–¥–∏—Ç–µ–ª—è.\n",
    "    \"\"\"\n",
    "    parents = []\n",
    "    for _ in range(2):\n",
    "        contenders = random.sample(list(zip(population, fitnesses)), k)\n",
    "        parents.append(max(contenders, key=lambda x: x[1])[0])\n",
    "    return parents\n",
    "\n",
    "\n",
    "def crossover(parent_a, parent_b):\n",
    "    \"\"\"\n",
    "    –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –≥–µ–Ω–æ—Ç–∏–ø–æ–≤ (—Å–ø–∏—Å–∫–æ–≤ —Å–ª–æ—ë–≤).\n",
    "    \"\"\"\n",
    "    cut = random.randint(1, min(len(parent_a), len(parent_b)) - 1)\n",
    "    return parent_a[:cut] + parent_b[cut:]\n",
    "\n",
    "\n",
    "def mutate(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, generators=None):\n",
    "    \"\"\"\n",
    "    –ú—É—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏:\n",
    "      base_mut: –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Å–ª–æ—è;\n",
    "      param_mut: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤;\n",
    "      struct_mut: –≤—Å—Ç–∞–≤–∫–∞/—É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è.\n",
    "    generators: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    generators = generators or [random_dense_layer, random_conv1d_block, random_rnn_block]\n",
    "    new_arch = []\n",
    "    # –®–∞–≥ –ø–æ –∫–∞–∂–¥–æ–º—É —Å–ª–æ—é: –∑–∞–º–µ–Ω–∞ –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –º—É—Ç–∞—Ü–∏—è\n",
    "    for layer in arch:\n",
    "        r = random.random()\n",
    "        if r < base_mut:\n",
    "            # –ó–∞–º–µ–Ω—è–µ–º —Å–ª–æ–π –ø–æ–ª–Ω–æ—Å—Ç—å—é\n",
    "            new_arch.append(random.choice(generators)())\n",
    "        elif r < base_mut + param_mut:\n",
    "            # –ú—É—Ç–∏—Ä—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "            l = layer.copy()\n",
    "            if 'units' in l:\n",
    "                l['units'] = max(1, int(l['units'] * random.uniform(0.5, 1.5)))\n",
    "            if 'dropout' in l:\n",
    "                l['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "            new_arch.append(l)\n",
    "        else:\n",
    "            # –û—Å—Ç–∞–≤–ª—è–µ–º —Å–ª–æ–π –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "            new_arch.append(layer)\n",
    "    # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º—É—Ç–∞—Ü–∏–∏: –≤—Å—Ç–∞–≤–∫–∞ –∏/–∏–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è\n",
    "    if random.random() < struct_mut:\n",
    "        pos = random.randint(0, len(new_arch))\n",
    "        new_arch.insert(pos, random.choice(generators)())\n",
    "    if random.random() < struct_mut and len(new_arch) > 1:\n",
    "        pos = random.randrange(len(new_arch))\n",
    "        new_arch.pop(pos)\n",
    "    return new_arch\n",
    "\n",
    "\n",
    "def run_ga(\n",
    "    train_data, val_data,\n",
    "    pop_size=20,\n",
    "    generations=10,\n",
    "    max_params=None,\n",
    "    elitism=2,\n",
    "    metric='mse',\n",
    "    epochs=5\n",
    "):\n",
    "    \"\"\"\n",
    "    –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:\n",
    "      - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "      - –û—Ü–µ–Ω–∫–∞ —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "      - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç–ª–∏—Ç–∏–∑–º–∞, —Å–µ–ª–µ–∫—Ü–∏–∏, –∫—Ä–æ—Å—Å–æ–≤–µ—Ä–∞ –∏ –º—É—Ç–∞—Ü–∏–∏\n",
    "      - –í–æ–∑–≤—Ä–∞—Ç –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –µ—ë —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "    \"\"\"\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    population = generate_population(pop_size=pop_size, max_params=max_params)\n",
    "    fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    for gen in range(generations):\n",
    "        print(f\"Gen {gen+1}/{generations}\")\n",
    "        # --- –≠–ª–∏—Ç–∏–∑–º: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-N –ª—É—á—à–∏—Ö ---\n",
    "        elite_idx = sorted(range(len(population)), key=lambda i: fitnesses[i], reverse=True)[:elitism]\n",
    "        new_population = [population[i] for i in elite_idx]\n",
    "\n",
    "        # --- –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –Ω–æ–≤—ã—Ö –æ—Å–æ–±–µ–π ---\n",
    "        while len(new_population) < pop_size:\n",
    "            p1, p2 = select_parents(population, fitnesses)\n",
    "            child = crossover(p1, p2)\n",
    "            child = mutate(child)\n",
    "            new_population.append(child)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É\n",
    "    best_arch, best_fit = max(zip(population, fitnesses), key=lambda x: x[1])\n",
    "    return best_arch, best_fit\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö Mackey-Glass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä—è–¥–∞\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def generate_mackey_glass(beta=0.2, gamma=0.1, n=10, tau=17,\n",
    "                              dt=0.1, total_time=1000, burn_in_time=100):\n",
    "        total_steps = int((total_time + burn_in_time) / dt)\n",
    "        burn_in_steps = int(burn_in_time / dt)\n",
    "        tau_steps = int(tau / dt)\n",
    "        # –†–∞–≤–Ω–æ–≤–µ—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        x0 = ((beta / gamma) - 1)**(1/n)\n",
    "        x = np.zeros(total_steps)\n",
    "        x[:tau_steps] = x0 + 0.01 * np.random.randn(tau_steps)\n",
    "        # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        for t in range(tau_steps, total_steps):\n",
    "            dx = dt * (beta * x[t - tau_steps] / (1 + x[t - tau_steps]**n)\n",
    "                       - gamma * x[t - 1])\n",
    "            x[t] = x[t - 1] + dx\n",
    "        # –û—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º burn-in\n",
    "        x = x[burn_in_steps:]\n",
    "        t_axis = np.linspace(0, total_time, len(x))\n",
    "        return t_axis, x\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ–∫–Ω–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    t, series = generate_mackey_glass()\n",
    "    window_size = 50\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window_size):\n",
    "        X.append(series[i:i+window_size])\n",
    "        y.append(series[i+window_size])\n",
    "    X = np.array(X)[..., np.newaxis]  # (N, window, 1)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # –î–µ–ª–∏–º –Ω–∞ train/val\n",
    "    split = int(0.8 * len(X))\n",
    "    train_data = (X[:split], y[:split])\n",
    "    val_data = (X[split:], y[split:])\n",
    "\n",
    "    # –ó–∞–ø—É—Å–∫–∞–µ–º GA\n",
    "    best_arch, best_fit = run_ga(\n",
    "        train_data, val_data,\n",
    "        pop_size=10, generations=5,\n",
    "        max_params=50000,\n",
    "        elitism=2,\n",
    "        metric='mse', epochs=3\n",
    "    )\n",
    "\n",
    "    print(\"Best fitness:\", best_fit)\n",
    "    print(\"Best architecture:\", best_arch)\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Å—Ç–∏ —Ä—è–¥–∞\n",
    "    plt.plot(t[window_size:window_size+200], series[window_size:window_size+200], label='True')\n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "    model = build_model_from_architecture(best_arch, train_data[0].shape[1:])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    preds = model.predict(train_data[0][:200])\n",
    "    plt.plot(t[window_size:window_size+200], preds.flatten(), label='Pred')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e0cc50d-debd-415b-877a-1d2d12498420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746978663.253542    2904 service.cc:152] XLA service 0x77b08800ad10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746978663.253743    2904 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 Ti, Compute Capability 7.5\n",
      "2025-05-11 18:51:03.333665: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1746978663.575883    2904 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1746978666.171619    2904 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"global_average_pooling1d_6\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 462\u001b[39m\n\u001b[32m    459\u001b[39m val_data = (X[split:], y[split:])\n\u001b[32m    461\u001b[39m \u001b[38;5;66;03m# –ó–∞–ø—É—Å–∫–∞–µ–º GA\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m best_arch, best_fit = \u001b[43mrun_ga\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_params\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43melitism\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmse\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m    468\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest fitness:\u001b[39m\u001b[33m\"\u001b[39m, best_fit)\n\u001b[32m    471\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest architecture:\u001b[39m\u001b[33m\"\u001b[39m, best_arch)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 398\u001b[39m, in \u001b[36mrun_ga\u001b[39m\u001b[34m(train_data, val_data, pop_size, generations, max_params, elitism, metric, epochs)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\u001b[39;00m\n\u001b[32m    397\u001b[39m population = generate_population(pop_size=pop_size, max_params=max_params)\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m fitnesses = [\u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(generations):\n\u001b[32m    401\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerations\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 310\u001b[39m, in \u001b[36mevaluate_fitness\u001b[39m\u001b[34m(arch, train_data, val_data, metric, epochs, verbose)\u001b[39m\n\u001b[32m    308\u001b[39m X_train, y_train = train_data\n\u001b[32m    309\u001b[39m X_val, y_val = val_data\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m model = \u001b[43mbuild_model_from_architecture\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=metric, metrics=[metric])\n\u001b[32m    312\u001b[39m history = model.fit(\n\u001b[32m    313\u001b[39m     X_train, y_train,\n\u001b[32m    314\u001b[39m     validation_data=(X_val, y_val),\n\u001b[32m    315\u001b[39m     epochs=epochs,\n\u001b[32m    316\u001b[39m     verbose=verbose\n\u001b[32m    317\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 145\u001b[39m, in \u001b[36mbuild_model_from_architecture\u001b[39m\u001b[34m(arch, input_shape)\u001b[39m\n\u001b[32m    143\u001b[39m     x = Flatten()(x)\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m t == \u001b[33m'\u001b[39m\u001b[33mGlobalAvgPool1D\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     x = \u001b[43mGlobalAveragePooling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m t == \u001b[33m'\u001b[39m\u001b[33mDense\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    147\u001b[39m     reg = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/keras/src/layers/input_spec.py:186\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m spec.allow_last_axis_squeeze:\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ndim != spec.ndim:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    187\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of layer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    188\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis incompatible with the layer: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    191\u001b[39m         )\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.max_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim > spec.max_ndim:\n",
      "\u001b[31mValueError\u001b[39m: Input 0 of layer \"global_average_pooling1d_6\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv1D, GlobalAveragePooling1D, Flatten,\n",
    "    GRU, SimpleRNN, BatchNormalization, Activation, Dropout\n",
    ")\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –±–ª–æ–∫–æ–≤ —Å–ª–æ—ë–≤ ---\n",
    "\n",
    "def random_dense_layer(units_choices=None):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞—ë—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "      units_choices: —Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —á–∏—Å–µ–ª –Ω–µ–π—Ä–æ–Ω–æ–≤.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–∞–º–∏:\n",
    "      layer, units, activation, kernel_regularizer, coef_regularizer (–æ–ø—Ü.), dropout\n",
    "    \"\"\"\n",
    "    units_choices = units_choices or [32, 64, 128, 256]\n",
    "    layer = {\n",
    "        'layer': 'Dense',\n",
    "        'units': random.choice(units_choices),\n",
    "        'activation': random.choice(['relu', 'sigmoid', 'tanh', 'linear']),\n",
    "        'kernel_regularizer': random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    }\n",
    "    # –ï—Å–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –≤—ã–±—Ä–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç\n",
    "    if layer['kernel_regularizer']:\n",
    "        layer['coef_regularizer'] = random.choice([0.0001, 0.001, 0.01, 0.1])\n",
    "    # Dropout –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    return layer\n",
    "\n",
    "\n",
    "def random_conv1d_block():\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –æ–¥–Ω–æ-–º–µ—Ä–Ω–æ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ –±–ª–æ–∫–∞.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Å–ª–æ–≤–∞—Ä–µ:\n",
    "      layer, filters, kernel_size, strides, padding, activation,\n",
    "      batch_norm, dropout, pooling.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': 'Conv1D',\n",
    "        'filters': random.choice([32, 64, 128, 256]),\n",
    "        'kernel_size': random.choice([3, 5, 7]),\n",
    "        'strides': random.choice([1, 2]),\n",
    "        'padding': random.choice(['valid', 'same']),\n",
    "        'activation': random.choice(['relu', 'tanh', 'sigmoid', 'elu']),\n",
    "        'batch_norm': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'pooling': random.choice([None, 'max2', 'max3'])\n",
    "    }\n",
    "\n",
    "\n",
    "def random_rnn_block(rnn_type='GRU'):\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–≥–æ –±–ª–æ–∫–∞ GRU –∏–ª–∏ RNN.\n",
    "    –ü–æ–ª—è:\n",
    "      layer, units, activation, return_sequences,\n",
    "      dropout, recurrent_dropout\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': rnn_type,\n",
    "        'units': random.choice([32, 64, 128]),\n",
    "        'activation': random.choice(['tanh', 'relu']),\n",
    "        'return_sequences': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'recurrent_dropout': random.choice([0.0, 0.1])\n",
    "    }\n",
    "\n",
    "\n",
    "def flatten_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è Flatten.\"\"\"\n",
    "    return {'layer': 'Flatten'}\n",
    "\n",
    "\n",
    "def global_pool_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è GlobalAveragePooling1D.\"\"\"\n",
    "    return {'layer': 'GlobalAvgPool1D'}\n",
    "\n",
    "\n",
    "# --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Keras-–º–æ–¥–µ–ª–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---\n",
    "\n",
    "def build_model_from_architecture(arch, input_shape):\n",
    "    \"\"\"\n",
    "    –ö–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç Keras Model –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:\n",
    "      - –õ–∏–Ω–µ–π–Ω—ã–µ —Å–ø–∏—Å–∫–∏ —Å–ª–æ—ë–≤ (list of dict)\n",
    "      - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG —Å –∫–ª—é—á–æ–º 'parallel'\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ DAG-–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        from tensorflow.keras.layers import Concatenate\n",
    "        # –í–µ—Ç–∫–∏\n",
    "        conv_branch = arch['parallel']['conv_branch']\n",
    "        rnn_branch = arch['parallel']['rnn_branch']\n",
    "        # –ü—Ä–æ—Ö–æ–¥ –ø–æ Conv –≤–µ—Ç–∫–µ\n",
    "        x1 = inp\n",
    "        for l in conv_branch:\n",
    "            if l['layer'] == 'Conv1D':\n",
    "                x1 = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'],\n",
    "                            strides=l['strides'], padding=l['padding'], activation=None)(x1)\n",
    "                if l['batch_norm']: x1 = BatchNormalization()(x1)\n",
    "                x1 = Activation(l['activation'])(x1)\n",
    "                if l['dropout'] > 0: x1 = Dropout(l['dropout'])(x1)\n",
    "            elif l['layer'] == 'GlobalAvgPool1D':\n",
    "                x1 = GlobalAveragePooling1D()(x1)\n",
    "            elif l['layer'] == 'Flatten':\n",
    "                x1 = Flatten()(x1)\n",
    "        # –ü—Ä–æ—Ö–æ–¥ –ø–æ RNN –≤–µ—Ç–∫–µ\n",
    "        x2 = inp\n",
    "        for l in rnn_branch:\n",
    "            if l['layer'] in ('GRU','RNN'):\n",
    "                layer_cls = GRU if l['layer']=='GRU' else SimpleRNN\n",
    "                x2 = layer_cls(units=l['units'], activation=l['activation'],\n",
    "                                return_sequences=l['return_sequences'],\n",
    "                                dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])(x2)\n",
    "            elif l['layer'] == 'GlobalAvgPool1D':\n",
    "                x2 = GlobalAveragePooling1D()(x2)\n",
    "            elif l['layer'] == 'Flatten':\n",
    "                x2 = Flatten()(x2)\n",
    "        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Ç–æ–∫ –∏ –≤—ã—Ö–æ–¥\n",
    "        merged = Concatenate()([x1, x2])\n",
    "        out = Dense(1, activation='linear')(merged)\n",
    "        return Model(inputs=inp, outputs=out)\n",
    "    # –û–±—ã—á–Ω–∞—è –ª–∏–Ω–µ–π–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (list)\n",
    "    x = inp\n",
    "    for l in arch:\n",
    "        t = l['layer']\n",
    "        if t == 'Conv1D':\n",
    "            x = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'], strides=l['strides'],\n",
    "                       padding=l['padding'], activation=None)(x)\n",
    "            if l['batch_norm']: x = BatchNormalization()(x)\n",
    "            x = Activation(l['activation'])(x)\n",
    "            if l['dropout'] > 0: x = Dropout(l['dropout'])(x)\n",
    "            if l['pooling'] in ('max2', 'max3'): x = GlobalAveragePooling1D()(x)\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            layer_cls = GRU if t == 'GRU' else SimpleRNN\n",
    "            x = layer_cls(l['units'], activation=l['activation'], return_sequences=l['return_sequences'],\n",
    "                         dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])(x)\n",
    "        elif t == 'Flatten':\n",
    "            x = Flatten()(x)\n",
    "        elif t == 'GlobalAvgPool1D':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        elif t == 'Dense':\n",
    "            reg = None\n",
    "            if l.get('kernel_regularizer') == 'L1': reg = l1(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L2': reg = l2(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L1L2': reg = l1_l2(l['coef_regularizer'])\n",
    "            x = Dense(l['units'], activation=l['activation'], kernel_regularizer=reg)(x)\n",
    "            if l.get('dropout',0) > 0: x = Dropout(l['dropout'])(x)\n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "# --- –û—Ü–µ–Ω–∫–∞ —á–∏—Å–ª–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ (–≥—Ä—É–±–∞—è) ---\n",
    "\n",
    "def estimate_params(layers):\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ—Ç —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Å–ø–∏—Å–∫—É —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    prev_units = None\n",
    "    for l in layers:\n",
    "        t = l.get('layer')\n",
    "        if t == 'Dense':\n",
    "            u = l['units']\n",
    "            total += (prev_units or u) * u + u\n",
    "            prev_units = u\n",
    "        elif t == 'Conv1D':\n",
    "            f, k = l['filters'], l['kernel_size']\n",
    "            total += (prev_units or f) * k + f\n",
    "            prev_units = f\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            u = l['units']\n",
    "            # —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä—ë—Ö –≤—Ö–æ–¥–Ω—ã—Ö –≤–µ—Å–æ–≤ + bias\n",
    "            total += u * (prev_units or u) * 3 + u * 3\n",
    "            prev_units = u\n",
    "    return total\n",
    "\n",
    "\n",
    "# --- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏ ---\n",
    "# –°–ª—É—á–∞–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω—ã–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏\n",
    "\n",
    "# 1) Conv‚ÜíPool‚ÜíDense skeleton\n",
    "\n",
    "def skeleton_conv_dense(min_conv=1, max_conv=3, min_dense=1, max_dense=2):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_conv, max_conv)):\n",
    "        layers.append(random_conv1d_block())\n",
    "    layers.append(global_pool_block())\n",
    "    for _ in range(random.randint(min_dense, max_dense)):\n",
    "        layers.append(random_dense_layer())\n",
    "    return layers\n",
    "\n",
    "# 2) –ß–∏—Å—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π skeleton\n",
    "\n",
    "def skeleton_rnn(min_rnn=1, max_rnn=2, rnn_type='GRU'):\n",
    "    layers = []\n",
    "    p = random.randint(min_rnn, max_rnn)\n",
    "    for i in range(p):\n",
    "        block = random_rnn_block(rnn_type)\n",
    "        block['return_sequences'] = (i < p - 1)\n",
    "        layers.append(block)\n",
    "    layers.append(random_dense_layer(units_choices=[64, 128]))\n",
    "    return layers\n",
    "\n",
    "# 3) –°–ª—É—á–∞–π–Ω—ã–µ –±–ª–æ–∫–∏\n",
    "\n",
    "def block_randomized(min_blocks=2, max_blocks=5):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_blocks, max_blocks)):\n",
    "        choice = random.choice(['conv', 'rnn', 'dense', 'pool'])\n",
    "        if choice == 'conv':\n",
    "            layers.append(random_conv1d_block())\n",
    "        elif choice == 'rnn':\n",
    "            layers.append(random_rnn_block(random.choice(['GRU', 'RNN'])))\n",
    "        elif choice == 'dense':\n",
    "            layers.append(random_dense_layer())\n",
    "        else:\n",
    "            layers.append(random.choice([flatten_block(), global_pool_block()]))\n",
    "    return layers\n",
    "\n",
    "# 4) –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG: Conv-–≤–µ—Ç–∫–∞ –∏ RNN-–≤–µ—Ç–∫–∞\n",
    "\n",
    "def dag_parallel(min_depth=1, max_depth=3):\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏:\n",
    "      - conv_branch: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å Conv1D + global pool\n",
    "      - rnn_branch: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å RNN/GRU —Å return_sequences=True —É –≤—Å–µ—Ö, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–æ–º 'parallel'.\n",
    "    \"\"\"\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º —Å–≤—ë—Ä—Ç–æ—á–Ω—É—é –≤–µ—Ç–∫—É\n",
    "    a = [random_conv1d_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    a.append(global_pool_block())\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º RNN –≤–µ—Ç–∫—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º return_sequences\n",
    "    depth = random.randint(min_depth, max_depth)\n",
    "    b = []\n",
    "    for i in range(depth):\n",
    "        block = random_rnn_block(random.choice(['GRU', 'RNN']))\n",
    "        # –≤—Å–µ, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ, –¥–æ–ª–∂–Ω—ã –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "        block['return_sequences'] = (i < depth - 1)\n",
    "        b.append(block)\n",
    "    # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º DAG –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏\n",
    "    return {'parallel': {'conv_branch': a, 'rnn_branch': b}}\n",
    "\n",
    "# 5) –ú–∏–Ω–∏-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞\n",
    "\n",
    "def micro_arch(min_layers=2, max_layers=3):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_layers, max_layers)):\n",
    "        layers.append(random.choice([\n",
    "            random_conv1d_block(), random_rnn_block(), random_dense_layer()\n",
    "        ]))\n",
    "    return layers\n",
    "\n",
    "# –°–±–æ—Ä–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏ —Å —É—á—ë—Ç–æ–º max_params\n",
    "\n",
    "def generate_population(pop_size=20, strategies=None, max_params=None):\n",
    "    \"\"\"\n",
    "    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ø—É–ª—è—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\n",
    "    pop_size: —Ä–∞–∑–º–µ—Ä.\n",
    "    strategies: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤.\n",
    "    max_params: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "    \"\"\"\n",
    "    strategies = strategies or [\n",
    "        skeleton_conv_dense,\n",
    "        skeleton_rnn,\n",
    "        block_randomized,\n",
    "        dag_parallel,\n",
    "        micro_arch\n",
    "    ]\n",
    "    population = []\n",
    "    while len(population) < pop_size:\n",
    "        strat = random.choice(strategies)\n",
    "        arch = strat()  # –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å dict (DAG) –∏–ª–∏ list\n",
    "        if isinstance(arch, dict):\n",
    "            population.append(arch)\n",
    "            continue\n",
    "        # –õ–∏–Ω–µ–π–Ω–∞—è —Ü–µ–ø–æ—á–∫–∞: —É–¥–∞–ª—è–µ–º Conv/RNN –ø–æ—Å–ª–µ —É–ø–ª–æ—â–µ–Ω–∏—è\n",
    "        clean_arch = []\n",
    "        collapsed = False\n",
    "        for l in arch:\n",
    "            if collapsed and l['layer'] in ('Conv1D', 'GRU', 'RNN'):\n",
    "                # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Å–ª–æ–π\n",
    "                continue\n",
    "            clean_arch.append(l)\n",
    "            if l['layer'] in ('Flatten', 'GlobalAvgPool1D'):\n",
    "                collapsed = True\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "        clean_arch.append({'layer': 'Dense', 'units': 1, 'activation': 'linear'})\n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ max_params\n",
    "        if max_params and estimate_params(clean_arch) > max_params:\n",
    "            continue\n",
    "        population.append(clean_arch)\n",
    "    return population\n",
    "\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º ---\n",
    "\n",
    "def evaluate_fitness(arch, train_data, val_data, metric='mse', epochs=5, verbose=0):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç –∏ –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏—Ç–Ω–µ—Å = - (–∑–Ω–∞—á–µ–Ω–∏–µ val_metric).\n",
    "    train_data, val_data: –∫–æ—Ä—Ç–µ–∂–∏ (X, y).\n",
    "    metric: —Å—Ç—Ä–æ–∫–∞ Keras ('mse', 'mae' –∏ —Ç.–¥.).\n",
    "    \"\"\"\n",
    "    X_train, y_train = train_data\n",
    "    X_val, y_val = val_data\n",
    "    model = build_model_from_architecture(arch, X_train.shape[1:])\n",
    "    model.compile(optimizer='adam', loss=metric, metrics=[metric])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏\n",
    "    val_res = history.history['val_' + metric][-1]\n",
    "    return -val_res\n",
    "\n",
    "\n",
    "def select_parents(population, fitnesses, k=3):\n",
    "    \"\"\"\n",
    "    –¢—É—Ä–Ω–∏—Ä–Ω–∞—è —Å–µ–ª–µ–∫—Ü–∏—è: –≤—ã–±–∏—Ä–∞–µ–º k —Å–ª—É—á–∞–π–Ω—ã—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 2 —Ä–æ–¥–∏—Ç–µ–ª—è.\n",
    "    \"\"\"\n",
    "    parents = []\n",
    "    for _ in range(2):\n",
    "        contenders = random.sample(list(zip(population, fitnesses)), k)\n",
    "        parents.append(max(contenders, key=lambda x: x[1])[0])\n",
    "    return parents\n",
    "\n",
    "\n",
    "def crossover(parent_a, parent_b):\n",
    "    \"\"\"\n",
    "    –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –≥–µ–Ω–æ—Ç–∏–ø–æ–≤ (—Å–ø–∏—Å–∫–æ–≤ —Å–ª–æ—ë–≤).\n",
    "    \"\"\"\n",
    "    cut = random.randint(1, min(len(parent_a), len(parent_b)) - 1)\n",
    "    return parent_a[:cut] + parent_b[cut:]\n",
    "\n",
    "\n",
    "def mutate(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, generators=None):\n",
    "    \"\"\"\n",
    "    –ú—É—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏:\n",
    "      base_mut: –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Å–ª–æ—è;\n",
    "      param_mut: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤;\n",
    "      struct_mut: –≤—Å—Ç–∞–≤–∫–∞/—É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è.\n",
    "    generators: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    generators = generators or [random_dense_layer, random_conv1d_block, random_rnn_block]\n",
    "    new_arch = []\n",
    "    # –®–∞–≥ –ø–æ –∫–∞–∂–¥–æ–º—É —Å–ª–æ—é: –∑–∞–º–µ–Ω–∞ –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –º—É—Ç–∞—Ü–∏—è\n",
    "    for layer in arch:\n",
    "        r = random.random()\n",
    "        if r < base_mut:\n",
    "            # –ó–∞–º–µ–Ω—è–µ–º —Å–ª–æ–π –ø–æ–ª–Ω–æ—Å—Ç—å—é\n",
    "            new_arch.append(random.choice(generators)())\n",
    "        elif r < base_mut + param_mut:\n",
    "            # –ú—É—Ç–∏—Ä—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "            l = layer.copy()\n",
    "            if 'units' in l:\n",
    "                l['units'] = max(1, int(l['units'] * random.uniform(0.5, 1.5)))\n",
    "            if 'dropout' in l:\n",
    "                l['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "            new_arch.append(l)\n",
    "        else:\n",
    "            # –û—Å—Ç–∞–≤–ª—è–µ–º —Å–ª–æ–π –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "            new_arch.append(layer)\n",
    "    # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º—É—Ç–∞—Ü–∏–∏: –≤—Å—Ç–∞–≤–∫–∞ –∏/–∏–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è\n",
    "    if random.random() < struct_mut:\n",
    "        pos = random.randint(0, len(new_arch))\n",
    "        new_arch.insert(pos, random.choice(generators)())\n",
    "    if random.random() < struct_mut and len(new_arch) > 1:\n",
    "        pos = random.randrange(len(new_arch))\n",
    "        new_arch.pop(pos)\n",
    "    return new_arch\n",
    "\n",
    "\n",
    "def run_ga(\n",
    "    train_data, val_data,\n",
    "    pop_size=20,\n",
    "    generations=10,\n",
    "    max_params=None,\n",
    "    elitism=2,\n",
    "    metric='mse',\n",
    "    epochs=5\n",
    "):\n",
    "    \"\"\"\n",
    "    –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:\n",
    "      - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "      - –û—Ü–µ–Ω–∫–∞ —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "      - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç–ª–∏—Ç–∏–∑–º–∞, —Å–µ–ª–µ–∫—Ü–∏–∏, –∫—Ä–æ—Å—Å–æ–≤–µ—Ä–∞ –∏ –º—É—Ç–∞—Ü–∏–∏\n",
    "      - –í–æ–∑–≤—Ä–∞—Ç –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –µ—ë —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "    \"\"\"\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    population = generate_population(pop_size=pop_size, max_params=max_params)\n",
    "    fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    for gen in range(generations):\n",
    "        print(f\"Gen {gen+1}/{generations}\")\n",
    "        # --- –≠–ª–∏—Ç–∏–∑–º: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-N –ª—É—á—à–∏—Ö ---\n",
    "        elite_idx = sorted(range(len(population)), key=lambda i: fitnesses[i], reverse=True)[:elitism]\n",
    "        new_population = [population[i] for i in elite_idx]\n",
    "\n",
    "        # --- –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –Ω–æ–≤—ã—Ö –æ—Å–æ–±–µ–π ---\n",
    "        while len(new_population) < pop_size:\n",
    "            p1, p2 = select_parents(population, fitnesses)\n",
    "            child = crossover(p1, p2)\n",
    "            child = mutate(child)\n",
    "            new_population.append(child)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É\n",
    "    best_arch, best_fit = max(zip(population, fitnesses), key=lambda x: x[1])\n",
    "    return best_arch, best_fit\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö Mackey-Glass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä—è–¥–∞\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def generate_mackey_glass(beta=0.2, gamma=0.1, n=10, tau=17,\n",
    "                              dt=0.1, total_time=1000, burn_in_time=100):\n",
    "        total_steps = int((total_time + burn_in_time) / dt)\n",
    "        burn_in_steps = int(burn_in_time / dt)\n",
    "        tau_steps = int(tau / dt)\n",
    "        # –†–∞–≤–Ω–æ–≤–µ—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        x0 = ((beta / gamma) - 1)**(1/n)\n",
    "        x = np.zeros(total_steps)\n",
    "        x[:tau_steps] = x0 + 0.01 * np.random.randn(tau_steps)\n",
    "        # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        for t in range(tau_steps, total_steps):\n",
    "            dx = dt * (beta * x[t - tau_steps] / (1 + x[t - tau_steps]**n)\n",
    "                       - gamma * x[t - 1])\n",
    "            x[t] = x[t - 1] + dx\n",
    "        # –û—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º burn-in\n",
    "        x = x[burn_in_steps:]\n",
    "        t_axis = np.linspace(0, total_time, len(x))\n",
    "        return t_axis, x\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ–∫–Ω–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    t, series = generate_mackey_glass()\n",
    "    window_size = 50\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window_size):\n",
    "        X.append(series[i:i+window_size])\n",
    "        y.append(series[i+window_size])\n",
    "    X = np.array(X)[..., np.newaxis]  # (N, window, 1)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # –î–µ–ª–∏–º –Ω–∞ train/val\n",
    "    split = int(0.8 * len(X))\n",
    "    train_data = (X[:split], y[:split])\n",
    "    val_data = (X[split:], y[split:])\n",
    "\n",
    "    # –ó–∞–ø—É—Å–∫–∞–µ–º GA\n",
    "    best_arch, best_fit = run_ga(\n",
    "        train_data, val_data,\n",
    "        pop_size=10, generations=5,\n",
    "        max_params=50000,\n",
    "        elitism=2,\n",
    "        metric='mse', epochs=3\n",
    "    )\n",
    "\n",
    "    print(\"Best fitness:\", best_fit)\n",
    "    print(\"Best architecture:\", best_arch)\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Å—Ç–∏ —Ä—è–¥–∞\n",
    "    plt.plot(t[window_size:window_size+200], series[window_size:window_size+200], label='True')\n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "    model = build_model_from_architecture(best_arch, train_data[0].shape[1:])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    preds = model.predict(train_data[0][:200])\n",
    "    plt.plot(t[window_size:window_size+200], preds.flatten(), label='Pred')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0c26807-37da-4e9e-b9b5-293692e8b4bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 500\u001b[39m\n\u001b[32m    497\u001b[39m val_data = (X[split:], y[split:])\n\u001b[32m    499\u001b[39m \u001b[38;5;66;03m# –ó–∞–ø—É—Å–∫–∞–µ–º GA\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m best_arch, best_fit = \u001b[43mrun_ga\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_params\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43melitism\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmse\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest fitness:\u001b[39m\u001b[33m\"\u001b[39m, best_fit)\n\u001b[32m    509\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest architecture:\u001b[39m\u001b[33m\"\u001b[39m, best_arch)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 434\u001b[39m, in \u001b[36mrun_ga\u001b[39m\u001b[34m(train_data, val_data, pop_size, generations, max_params, elitism, metric, epochs)\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;66;03m# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\u001b[39;00m\n\u001b[32m    433\u001b[39m population = generate_population(pop_size=pop_size, max_params=max_params)\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m fitnesses = [\u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(generations):\n\u001b[32m    437\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerations\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 336\u001b[39m, in \u001b[36mevaluate_fitness\u001b[39m\u001b[34m(arch, train_data, val_data, metric, epochs, verbose)\u001b[39m\n\u001b[32m    334\u001b[39m model = build_model_from_architecture(arch, X_train.shape[\u001b[32m1\u001b[39m:])\n\u001b[32m    335\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=metric, metrics=[metric])\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;66;03m# –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏\u001b[39;00m\n\u001b[32m    343\u001b[39m val_res = history.history[\u001b[33m'\u001b[39m\u001b[33mval_\u001b[39m\u001b[33m'\u001b[39m + metric][-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/diploma/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv1D, GlobalAveragePooling1D, Flatten,\n",
    "    GRU, SimpleRNN, BatchNormalization, Activation, Dropout\n",
    ")\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –±–ª–æ–∫–æ–≤ —Å–ª–æ—ë–≤ ---\n",
    "\n",
    "def random_dense_layer(units_choices=None):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞—ë—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "      units_choices: —Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —á–∏—Å–µ–ª –Ω–µ–π—Ä–æ–Ω–æ–≤.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–∞–º–∏:\n",
    "      layer, units, activation, kernel_regularizer, coef_regularizer (–æ–ø—Ü.), dropout\n",
    "    \"\"\"\n",
    "    units_choices = units_choices or [32, 64, 128, 256]\n",
    "    layer = {\n",
    "        'layer': 'Dense',\n",
    "        'units': random.choice(units_choices),\n",
    "        'activation': random.choice(['relu', 'sigmoid', 'tanh', 'linear']),\n",
    "        'kernel_regularizer': random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    }\n",
    "    # –ï—Å–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –≤—ã–±—Ä–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç\n",
    "    if layer['kernel_regularizer']:\n",
    "        layer['coef_regularizer'] = random.choice([0.0001, 0.001, 0.01, 0.1])\n",
    "    # Dropout –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    return layer\n",
    "\n",
    "\n",
    "def random_conv1d_block():\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –æ–¥–Ω–æ-–º–µ—Ä–Ω–æ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ –±–ª–æ–∫–∞.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Å–ª–æ–≤–∞—Ä–µ:\n",
    "      layer, filters, kernel_size, strides, padding, activation,\n",
    "      batch_norm, dropout, pooling.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': 'Conv1D',\n",
    "        'filters': random.choice([32, 64, 128, 256]),\n",
    "        'kernel_size': random.choice([3, 5, 7]),\n",
    "        'strides': random.choice([1, 2]),\n",
    "        'padding': random.choice(['valid', 'same']),\n",
    "        'activation': random.choice(['relu', 'tanh', 'sigmoid', 'elu']),\n",
    "        'batch_norm': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'pooling': random.choice([None, 'max2', 'max3'])\n",
    "    }\n",
    "\n",
    "\n",
    "def random_rnn_block(rnn_type='GRU'):\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–≥–æ –±–ª–æ–∫–∞ GRU –∏–ª–∏ RNN.\n",
    "    –ü–æ–ª—è:\n",
    "      layer, units, activation, return_sequences,\n",
    "      dropout, recurrent_dropout\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': rnn_type,\n",
    "        'units': random.choice([32, 64, 128]),\n",
    "        'activation': random.choice(['tanh', 'relu']),\n",
    "        'return_sequences': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'recurrent_dropout': random.choice([0.0, 0.1])\n",
    "    }\n",
    "\n",
    "\n",
    "def flatten_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è Flatten.\"\"\"\n",
    "    return {'layer': 'Flatten'}\n",
    "\n",
    "\n",
    "def global_pool_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è GlobalAveragePooling1D.\"\"\"\n",
    "    return {'layer': 'GlobalAvgPool1D'}\n",
    "\n",
    "\n",
    "# --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Keras-–º–æ–¥–µ–ª–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---\n",
    "\n",
    "def build_model_from_architecture(arch, input_shape):\n",
    "    \"\"\"\n",
    "    –ö–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç Keras Model –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:\n",
    "      - –õ–∏–Ω–µ–π–Ω—ã–µ —Å–ø–∏—Å–∫–∏ —Å–ª–æ—ë–≤ (list of dict)\n",
    "      - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG —Å –∫–ª—é—á–æ–º 'parallel'\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ DAG-–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        from tensorflow.keras.layers import Concatenate\n",
    "        # –í–µ—Ç–∫–∏\n",
    "        conv_branch = arch['parallel']['conv_branch']\n",
    "        rnn_branch = arch['parallel']['rnn_branch']\n",
    "        # –ü—Ä–æ—Ö–æ–¥ –ø–æ Conv –≤–µ—Ç–∫–µ\n",
    "        x1 = inp\n",
    "        for l in conv_branch:\n",
    "            if l['layer'] == 'Conv1D':\n",
    "                x1 = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'],\n",
    "                            strides=l['strides'], padding=l['padding'], activation=None)(x1)\n",
    "                if l['batch_norm']: x1 = BatchNormalization()(x1)\n",
    "                x1 = Activation(l['activation'])(x1)\n",
    "                if l['dropout'] > 0: x1 = Dropout(l['dropout'])(x1)\n",
    "            elif l['layer'] == 'GlobalAvgPool1D':\n",
    "                x1 = GlobalAveragePooling1D()(x1)\n",
    "            elif l['layer'] == 'Flatten':\n",
    "                x1 = Flatten()(x1)\n",
    "        # –ü—Ä–æ—Ö–æ–¥ –ø–æ RNN –≤–µ—Ç–∫–µ\n",
    "        x2 = inp\n",
    "        for l in rnn_branch:\n",
    "            if l['layer'] in ('GRU','RNN'):\n",
    "                layer_cls = GRU if l['layer']=='GRU' else SimpleRNN\n",
    "                x2 = layer_cls(units=l['units'], activation=l['activation'],\n",
    "                                return_sequences=l['return_sequences'],\n",
    "                                dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])(x2)\n",
    "            elif l['layer'] == 'GlobalAvgPool1D':\n",
    "                x2 = GlobalAveragePooling1D()(x2)\n",
    "            elif l['layer'] == 'Flatten':\n",
    "                x2 = Flatten()(x2)\n",
    "        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Ç–æ–∫ –∏ –≤—ã—Ö–æ–¥\n",
    "        merged = Concatenate()([x1, x2])\n",
    "        out = Dense(1, activation='linear')(merged)\n",
    "        return Model(inputs=inp, outputs=out)\n",
    "    \n",
    "    # –û–±—ã—á–Ω–∞—è –ª–∏–Ω–µ–π–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (list)\n",
    "    x = inp\n",
    "    input_shape_rank = len(input_shape)\n",
    "    \n",
    "    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–ª–æ—ë–≤\n",
    "    current_rank = input_shape_rank\n",
    "    \n",
    "    for l in arch:\n",
    "        t = l['layer']\n",
    "        \n",
    "        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏, —Ç—Ä–µ–±—É—é—â–∏–µ 3D –≤—Ö–æ–¥–∞, –µ—Å–ª–∏ —Ç–µ–∫—É—â–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 2D\n",
    "        if current_rank < 3 and t in ('Conv1D', 'GRU', 'RNN', 'GlobalAvgPool1D'):\n",
    "            continue\n",
    "            \n",
    "        if t == 'Conv1D':\n",
    "            x = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'], strides=l['strides'],\n",
    "                       padding=l['padding'], activation=None)(x)\n",
    "            if l['batch_norm']: x = BatchNormalization()(x)\n",
    "            x = Activation(l['activation'])(x)\n",
    "            if l['dropout'] > 0: x = Dropout(l['dropout'])(x)\n",
    "            if l['pooling'] in ('max2', 'max3'): \n",
    "                x = GlobalAveragePooling1D()(x)\n",
    "                current_rank = 2  # –ü–æ—Å–ª–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ø—É–ª–∏–Ω–≥–∞ –ø–æ–ª—É—á–∞–µ–º 2D —Ç–µ–Ω–∑–æ—Ä\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            layer_cls = GRU if t == 'GRU' else SimpleRNN\n",
    "            x = layer_cls(l['units'], activation=l['activation'], return_sequences=l['return_sequences'],\n",
    "                         dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])(x)\n",
    "            if not l['return_sequences']:\n",
    "                current_rank = 2  # –ï—Å–ª–∏ return_sequences=False, –ø–æ–ª—É—á–∞–µ–º 2D —Ç–µ–Ω–∑–æ—Ä\n",
    "        elif t == 'Flatten':\n",
    "            x = Flatten()(x)\n",
    "            current_rank = 2  # –ü–æ—Å–ª–µ Flatten –≤—Å–µ–≥–¥–∞ 2D —Ç–µ–Ω–∑–æ—Ä\n",
    "        elif t == 'GlobalAvgPool1D':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "            current_rank = 2  # –ü–æ—Å–ª–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ø—É–ª–∏–Ω–≥–∞ –ø–æ–ª—É—á–∞–µ–º 2D —Ç–µ–Ω–∑–æ—Ä\n",
    "        elif t == 'Dense':\n",
    "            reg = None\n",
    "            if l.get('kernel_regularizer') == 'L1': reg = l1(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L2': reg = l2(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L1L2': reg = l1_l2(l['coef_regularizer'])\n",
    "            x = Dense(l['units'], activation=l['activation'], kernel_regularizer=reg)(x)\n",
    "            if l.get('dropout',0) > 0: x = Dropout(l['dropout'])(x)\n",
    "    \n",
    "    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –Ω–µ Dense, –¥–æ–±–∞–≤–ª—è–µ–º Dense(1) –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    if not (len(arch) > 0 and arch[-1]['layer'] == 'Dense' and arch[-1]['units'] == 1):\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "# --- –û—Ü–µ–Ω–∫–∞ —á–∏—Å–ª–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ (–≥—Ä—É–±–∞—è) ---\n",
    "\n",
    "def estimate_params(layers):\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ—Ç —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Å–ø–∏—Å–∫—É —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    prev_units = None\n",
    "    for l in layers:\n",
    "        t = l.get('layer')\n",
    "        if t == 'Dense':\n",
    "            u = l['units']\n",
    "            total += (prev_units or u) * u + u\n",
    "            prev_units = u\n",
    "        elif t == 'Conv1D':\n",
    "            f, k = l['filters'], l['kernel_size']\n",
    "            total += (prev_units or f) * k + f\n",
    "            prev_units = f\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            u = l['units']\n",
    "            # —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä—ë—Ö –≤—Ö–æ–¥–Ω—ã—Ö –≤–µ—Å–æ–≤ + bias\n",
    "            total += u * (prev_units or u) * 3 + u * 3\n",
    "            prev_units = u\n",
    "    return total\n",
    "\n",
    "\n",
    "# --- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏ ---\n",
    "# –°–ª—É—á–∞–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω—ã–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏\n",
    "\n",
    "# 1) Conv‚ÜíPool‚ÜíDense skeleton\n",
    "\n",
    "def skeleton_conv_dense(min_conv=1, max_conv=3, min_dense=1, max_dense=2):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_conv, max_conv)):\n",
    "        layers.append(random_conv1d_block())\n",
    "    layers.append(global_pool_block())\n",
    "    for _ in range(random.randint(min_dense, max_dense)):\n",
    "        layers.append(random_dense_layer())\n",
    "    return layers\n",
    "\n",
    "# 2) –ß–∏—Å—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π skeleton\n",
    "\n",
    "def skeleton_rnn(min_rnn=1, max_rnn=2, rnn_type='GRU'):\n",
    "    layers = []\n",
    "    p = random.randint(min_rnn, max_rnn)\n",
    "    for i in range(p):\n",
    "        block = random_rnn_block(rnn_type)\n",
    "        block['return_sequences'] = (i < p - 1)\n",
    "        layers.append(block)\n",
    "    layers.append(random_dense_layer(units_choices=[64, 128]))\n",
    "    return layers\n",
    "\n",
    "# 3) –°–ª—É—á–∞–π–Ω—ã–µ –±–ª–æ–∫–∏\n",
    "\n",
    "def block_randomized(min_blocks=2, max_blocks=5):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_blocks, max_blocks)):\n",
    "        choice = random.choice(['conv', 'rnn', 'dense', 'pool'])\n",
    "        if choice == 'conv':\n",
    "            layers.append(random_conv1d_block())\n",
    "        elif choice == 'rnn':\n",
    "            layers.append(random_rnn_block(random.choice(['GRU', 'RNN'])))\n",
    "        elif choice == 'dense':\n",
    "            layers.append(random_dense_layer())\n",
    "        else:\n",
    "            layers.append(random.choice([flatten_block(), global_pool_block()]))\n",
    "    return layers\n",
    "\n",
    "# 4) –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG: Conv-–≤–µ—Ç–∫–∞ –∏ RNN-–≤–µ—Ç–∫–∞\n",
    "\n",
    "def dag_parallel(min_depth=1, max_depth=3):\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏:\n",
    "      - conv_branch: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å Conv1D + global pool\n",
    "      - rnn_branch: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å RNN/GRU —Å return_sequences=True —É –≤—Å–µ—Ö, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–æ–º 'parallel'.\n",
    "    \"\"\"\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º —Å–≤—ë—Ä—Ç–æ—á–Ω—É—é –≤–µ—Ç–∫—É\n",
    "    a = [random_conv1d_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    a.append(global_pool_block())\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º RNN –≤–µ—Ç–∫—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º return_sequences\n",
    "    depth = random.randint(min_depth, max_depth)\n",
    "    b = []\n",
    "    for i in range(depth):\n",
    "        block = random_rnn_block(random.choice(['GRU', 'RNN']))\n",
    "        # –≤—Å–µ, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ, –¥–æ–ª–∂–Ω—ã –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "        block['return_sequences'] = (i < depth - 1)\n",
    "        b.append(block)\n",
    "    # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º DAG –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏\n",
    "    return {'parallel': {'conv_branch': a, 'rnn_branch': b}}\n",
    "\n",
    "# 5) –ú–∏–Ω–∏-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞\n",
    "\n",
    "def micro_arch(min_layers=2, max_layers=3):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_layers, max_layers)):\n",
    "        layers.append(random.choice([\n",
    "            random_conv1d_block(), random_rnn_block(), random_dense_layer()\n",
    "        ]))\n",
    "    return layers\n",
    "\n",
    "# –°–±–æ—Ä–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏ —Å —É—á—ë—Ç–æ–º max_params\n",
    "\n",
    "def generate_population(pop_size=20, strategies=None, max_params=None):\n",
    "    \"\"\"\n",
    "    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ø—É–ª—è—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\n",
    "    pop_size: —Ä–∞–∑–º–µ—Ä.\n",
    "    strategies: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤.\n",
    "    max_params: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "    \"\"\"\n",
    "    strategies = strategies or [\n",
    "        skeleton_conv_dense,\n",
    "        skeleton_rnn,\n",
    "        block_randomized,\n",
    "        dag_parallel,\n",
    "        micro_arch\n",
    "    ]\n",
    "    population = []\n",
    "    while len(population) < pop_size:\n",
    "        strat = random.choice(strategies)\n",
    "        arch = strat()  # –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å dict (DAG) –∏–ª–∏ list\n",
    "        if isinstance(arch, dict):\n",
    "            population.append(arch)\n",
    "            continue\n",
    "        # –õ–∏–Ω–µ–π–Ω–∞—è —Ü–µ–ø–æ—á–∫–∞: —É–¥–∞–ª—è–µ–º Conv/RNN –ø–æ—Å–ª–µ —É–ø–ª–æ—â–µ–Ω–∏—è\n",
    "        clean_arch = []\n",
    "        collapsed = False\n",
    "        for l in arch:\n",
    "            if collapsed and l['layer'] in ('Conv1D', 'GRU', 'RNN'):\n",
    "                # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Å–ª–æ–π\n",
    "                continue\n",
    "            clean_arch.append(l)\n",
    "            if l['layer'] in ('Flatten', 'GlobalAvgPool1D'):\n",
    "                collapsed = True\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "        clean_arch.append({'layer': 'Dense', 'units': 1, 'activation': 'linear'})\n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ max_params\n",
    "        if max_params and estimate_params(clean_arch) > max_params:\n",
    "            continue\n",
    "        population.append(clean_arch)\n",
    "    return population\n",
    "\n",
    "\n",
    "# --- –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º ---\n",
    "\n",
    "def evaluate_fitness(arch, train_data, val_data, metric='mse', epochs=5, verbose=0):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç –∏ –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏—Ç–Ω–µ—Å = - (–∑–Ω–∞—á–µ–Ω–∏–µ val_metric).\n",
    "    train_data, val_data: –∫–æ—Ä—Ç–µ–∂–∏ (X, y).\n",
    "    metric: —Å—Ç—Ä–æ–∫–∞ Keras ('mse', 'mae' –∏ —Ç.–¥.).\n",
    "    \"\"\"\n",
    "    X_train, y_train = train_data\n",
    "    X_val, y_val = val_data\n",
    "    \n",
    "    try:\n",
    "        model = build_model_from_architecture(arch, X_train.shape[1:])\n",
    "        model.compile(optimizer='adam', loss=metric, metrics=[metric])\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏\n",
    "        val_res = history.history['val_' + metric][-1]\n",
    "        return -val_res\n",
    "    except Exception as e:\n",
    "        print(f\"Error in fitness evaluation: {e}\")\n",
    "        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–µ–Ω—å –ø–ª–æ—Ö–æ–π —Ñ–∏—Ç–Ω–µ—Å\n",
    "        return float('-inf')\n",
    "\n",
    "\n",
    "def select_parents(population, fitnesses, k=3):\n",
    "    \"\"\"\n",
    "    –¢—É—Ä–Ω–∏—Ä–Ω–∞—è —Å–µ–ª–µ–∫—Ü–∏—è: –≤—ã–±–∏—Ä–∞–µ–º k —Å–ª—É—á–∞–π–Ω—ã—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 2 —Ä–æ–¥–∏—Ç–µ–ª—è.\n",
    "    \"\"\"\n",
    "    parents = []\n",
    "    for _ in range(2):\n",
    "        contenders = random.sample(list(zip(population, fitnesses)), k)\n",
    "        parents.append(max(contenders, key=lambda x: x[1])[0])\n",
    "    return parents\n",
    "\n",
    "\n",
    "def crossover(parent_a, parent_b):\n",
    "    \"\"\"\n",
    "    –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –≥–µ–Ω–æ—Ç–∏–ø–æ–≤ (—Å–ø–∏—Å–∫–æ–≤ —Å–ª–æ—ë–≤).\n",
    "    \"\"\"\n",
    "    if isinstance(parent_a, dict) or isinstance(parent_b, dict):\n",
    "        # –î–ª—è DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –ø—Ä–æ—Å—Ç–æ –≤—ã–±–∏—Ä–∞–µ–º –æ–¥–Ω–æ–≥–æ –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª–µ–π\n",
    "        return random.choice([parent_a, parent_b])\n",
    "    \n",
    "    cut = random.randint(1, min(len(parent_a), len(parent_b)) - 1)\n",
    "    return parent_a[:cut] + parent_b[cut:]\n",
    "\n",
    "\n",
    "def mutate(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, generators=None):\n",
    "    \"\"\"\n",
    "    –ú—É—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏:\n",
    "      base_mut: –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Å–ª–æ—è;\n",
    "      param_mut: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤;\n",
    "      struct_mut: –≤—Å—Ç–∞–≤–∫–∞/—É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è.\n",
    "    generators: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö —Å–ª–æ—ë–≤.\n",
    "    \"\"\"\n",
    "    # –ï—Å–ª–∏ DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–µ\n",
    "    if isinstance(arch, dict):\n",
    "        return arch\n",
    "        \n",
    "    generators = generators or [random_dense_layer, random_conv1d_block, random_rnn_block]\n",
    "    new_arch = []\n",
    "    # –®–∞–≥ –ø–æ –∫–∞–∂–¥–æ–º—É —Å–ª–æ—é: –∑–∞–º–µ–Ω–∞ –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –º—É—Ç–∞—Ü–∏—è\n",
    "    for layer in arch:\n",
    "        r = random.random()\n",
    "        if r < base_mut:\n",
    "            # –ó–∞–º–µ–Ω—è–µ–º —Å–ª–æ–π –ø–æ–ª–Ω–æ—Å—Ç—å—é\n",
    "            new_arch.append(random.choice(generators)())\n",
    "        elif r < base_mut + param_mut:\n",
    "            # –ú—É—Ç–∏—Ä—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "            l = layer.copy()\n",
    "            if 'units' in l:\n",
    "                l['units'] = max(1, int(l['units'] * random.uniform(0.5, 1.5)))\n",
    "            if 'dropout' in l:\n",
    "                l['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "            new_arch.append(l)\n",
    "        else:\n",
    "            # –û—Å—Ç–∞–≤–ª—è–µ–º —Å–ª–æ–π –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "            new_arch.append(layer)\n",
    "    # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –º—É—Ç–∞—Ü–∏–∏: –≤—Å—Ç–∞–≤–∫–∞ –∏/–∏–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è\n",
    "    if random.random() < struct_mut:\n",
    "        pos = random.randint(0, len(new_arch))\n",
    "        new_arch.insert(pos, random.choice(generators)())\n",
    "    if random.random() < struct_mut and len(new_arch) > 1:\n",
    "        pos = random.randrange(len(new_arch))\n",
    "        new_arch.pop(pos)\n",
    "    return new_arch\n",
    "\n",
    "\n",
    "def run_ga(\n",
    "    train_data, val_data,\n",
    "    pop_size=20,\n",
    "    generations=10,\n",
    "    max_params=None,\n",
    "    elitism=2,\n",
    "    metric='mse',\n",
    "    epochs=5\n",
    "):\n",
    "    \"\"\"\n",
    "    –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:\n",
    "      - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "      - –û—Ü–µ–Ω–∫–∞ —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "      - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç–ª–∏—Ç–∏–∑–º–∞, —Å–µ–ª–µ–∫—Ü–∏–∏, –∫—Ä–æ—Å—Å–æ–≤–µ—Ä–∞ –∏ –º—É—Ç–∞—Ü–∏–∏\n",
    "      - –í–æ–∑–≤—Ä–∞—Ç –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –µ—ë —Ñ–∏—Ç–Ω–µ—Å–∞\n",
    "    \"\"\"\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    population = generate_population(pop_size=pop_size, max_params=max_params)\n",
    "    fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    for gen in range(generations):\n",
    "        print(f\"Gen {gen+1}/{generations}\")\n",
    "        # --- –≠–ª–∏—Ç–∏–∑–º: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-N –ª—É—á—à–∏—Ö ---\n",
    "        elite_idx = sorted(range(len(population)), key=lambda i: fitnesses[i], reverse=True)[:elitism]\n",
    "        new_population = [population[i] for i in elite_idx]\n",
    "\n",
    "        # --- –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –Ω–æ–≤—ã—Ö –æ—Å–æ–±–µ–π ---\n",
    "        while len(new_population) < pop_size:\n",
    "            p1, p2 = select_parents(population, fitnesses)\n",
    "            child = crossover(p1, p2)\n",
    "            child = mutate(child)\n",
    "            new_population.append(child)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = [evaluate_fitness(ind, train_data, val_data, metric, epochs) for ind in population]\n",
    "\n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É\n",
    "    best_idx = max(range(len(population)), key=lambda i: fitnesses[i])\n",
    "    best_arch = population[best_idx]\n",
    "    best_fit = fitnesses[best_idx]\n",
    "    return best_arch, best_fit\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö Mackey-Glass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä—è–¥–∞\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def generate_mackey_glass(beta=0.2, gamma=0.1, n=10, tau=17,\n",
    "                              dt=0.1, total_time=1000, burn_in_time=100):\n",
    "        total_steps = int((total_time + burn_in_time) / dt)\n",
    "        burn_in_steps = int(burn_in_time / dt)\n",
    "        tau_steps = int(tau / dt)\n",
    "        # –†–∞–≤–Ω–æ–≤–µ—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        x0 = ((beta / gamma) - 1)**(1/n)\n",
    "        x = np.zeros(total_steps)\n",
    "        x[:tau_steps] = x0 + 0.01 * np.random.randn(tau_steps)\n",
    "        # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        for t in range(tau_steps, total_steps):\n",
    "            dx = dt * (beta * x[t - tau_steps] / (1 + x[t - tau_steps]**n)\n",
    "                       - gamma * x[t - 1])\n",
    "            x[t] = x[t - 1] + dx\n",
    "        # –û—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º burn-in\n",
    "        x = x[burn_in_steps:]\n",
    "        t_axis = np.linspace(0, total_time, len(x))\n",
    "        return t_axis, x\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ–∫–Ω–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    t, series = generate_mackey_glass()\n",
    "    window_size = 50\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window_size):\n",
    "        X.append(series[i:i+window_size])\n",
    "        y.append(series[i+window_size])\n",
    "    X = np.array(X)[..., np.newaxis]  # (N, window, 1)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # –î–µ–ª–∏–º –Ω–∞ train/val\n",
    "    split = int(0.8 * len(X))\n",
    "    train_data = (X[:split], y[:split])\n",
    "    val_data = (X[split:], y[split:])\n",
    "\n",
    "    # –ó–∞–ø—É—Å–∫–∞–µ–º GA\n",
    "    best_arch, best_fit = run_ga(\n",
    "        train_data, val_data,\n",
    "        pop_size=10, generations=5,\n",
    "        max_params=50000,\n",
    "        elitism=2,\n",
    "        metric='mse', epochs=3\n",
    "    )\n",
    "\n",
    "    print(\"Best fitness:\", best_fit)\n",
    "    print(\"Best architecture:\", best_arch)\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Å—Ç–∏ —Ä—è–¥–∞\n",
    "    plt.plot(t[window_size:window_size+200], series[window_size:window_size+200], label='True')\n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "    model = build_model_from_architecture(best_arch, train_data[0].shape[1:])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    preds = model.predict(train_data[0][:200])\n",
    "\n",
    "    # ‚Ä¶ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∏ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ ‚Ä¶\n",
    "\n",
    "    # 2) –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –≤—Å—ë–º train-–Ω–∞–±–æ—Ä–µ\n",
    "    preds_all = model.predict(train_data[0])     # (N_windows, 1)\n",
    "    preds_all = preds_all.flatten()              # (N_windows,)\n",
    "\n",
    "    # —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –æ—Å—å –≤—Ä–µ–º–µ–Ω–∏\n",
    "    t_pred = t[window_size:]                     # (N_windows,)\n",
    "\n",
    "    plt.plot(t_pred, series[window_size:], label='True')\n",
    "    plt.plot(t_pred, preds_all,    label='Pred')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(t[window_size:window_size+200], preds.flatten(), label='Pred')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654e4a0-a476-4a48-823c-015c103a4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "class HPOptimizer:\n",
    "    \"\"\"–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\"\"\"\n",
    "    \n",
    "    def __init__(self, train_data, val_data, test_data=None):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "        \n",
    "    def optimize_hyperparameters(self, architecture, trials=10, epochs=30, patience=5):\n",
    "        \"\"\"\n",
    "        –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∏–ª—É—á—à—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –º–æ–¥–µ–ª—å.\n",
    "        \"\"\"\n",
    "        best_hp = None\n",
    "        best_val_loss = float('inf')\n",
    "        best_model = None\n",
    "        \n",
    "        X_train, y_train = self.train_data\n",
    "        X_val, y_val = self.val_data\n",
    "        \n",
    "        for trial in range(trials):\n",
    "            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "            hp = self._sample_hyperparameters()\n",
    "            print(f\"–ü—Ä–æ–±—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {hp}\")\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "            model = build_model_from_architecture(architecture, X_train.shape[1:])\n",
    "            \n",
    "            # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "            optimizer = self._get_optimizer(hp['optimizer_name'], hp['learning_rate'])\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=hp['loss'],\n",
    "                metrics=['mse', 'mae']\n",
    "            )\n",
    "            \n",
    "            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–ª–±—ç–∫–∏\n",
    "            callbacks = [\n",
    "                EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=patience,\n",
    "                    restore_best_weights=True\n",
    "                ),\n",
    "                ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.5,\n",
    "                    patience=patience // 2,\n",
    "                    min_lr=1e-6\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=epochs,\n",
    "                batch_size=hp['batch_size'],\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ\n",
    "            val_loss = min(history.history['val_loss'])\n",
    "            \n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_hp = hp\n",
    "                best_model = model\n",
    "            else:\n",
    "                # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å\n",
    "                del model\n",
    "                tf.keras.backend.clear_session()\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "        test_metrics = None\n",
    "        if self.test_data is not None and best_model is not None:\n",
    "            X_test, y_test = self.test_data\n",
    "            test_metrics = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "            print(f\"–¢–µ—Å—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: MSE={test_metrics[1]}, MAE={test_metrics[2]}\")\n",
    "        \n",
    "        return best_hp, best_model, best_val_loss, test_metrics\n",
    "    \n",
    "    def _sample_hyperparameters(self):\n",
    "        \"\"\"–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\"\"\"\n",
    "        return {\n",
    "            'batch_size': random.choice([16, 32, 64, 128]),\n",
    "            'learning_rate': 10 ** random.uniform(-4, -1),  # –æ—Ç 1e-4 –¥–æ 1e-1\n",
    "            'optimizer_name': random.choice(['adam', 'rmsprop', 'sgd']),\n",
    "            'loss': random.choice(['mse', 'mae', 'huber_loss']),\n",
    "        }\n",
    "    \n",
    "    def _get_optimizer(self, name, learning_rate):\n",
    "        \"\"\"–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–æ –∏–º–µ–Ω–∏ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
    "        if name == 'adam':\n",
    "            return Adam(learning_rate=learning_rate)\n",
    "        elif name == 'rmsprop':\n",
    "            return RMSprop(learning_rate=learning_rate)\n",
    "        elif name == 'sgd':\n",
    "            return SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "        else:\n",
    "            return Adam(learning_rate=learning_rate)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "\n",
    "\n",
    "class EnsembleBuilder:\n",
    "    \"\"\"–°—Ç—Ä–æ–∏—Ç –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π\"\"\"\n",
    "    \n",
    "    def __init__(self, train_data, val_data, test_data=None):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def build_ensemble(self, architectures, hp_optimizer=None, ensemble_size=5, \n",
    "                       diversity_weight=0.3, max_trials=10):\n",
    "        \"\"\"\n",
    "        –°–æ–∑–¥–∞–µ—Ç –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        architectures : list\n",
    "            –°–ø–∏—Å–æ–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã–±–∏—Ä–∞—é—Ç—Å—è –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è\n",
    "        hp_optimizer : HPOptimizer, optional\n",
    "            –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "        ensemble_size : int\n",
    "            –†–∞–∑–º–µ—Ä –∞–Ω—Å–∞–º–±–ª—è (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π)\n",
    "        diversity_weight : float\n",
    "            –í–µ—Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –ø—Ä–∏ –æ—Ç–±–æ—Ä–µ –º–æ–¥–µ–ª–µ–π (0-1)\n",
    "        max_trials : int\n",
    "            –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list of models\n",
    "            –°–ø–∏—Å–æ–∫ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è\n",
    "        \"\"\"\n",
    "        if hp_optimizer is None:\n",
    "            hp_optimizer = HPOptimizer(self.train_data, self.val_data, self.test_data)\n",
    "        \n",
    "        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\n",
    "        if len(architectures) < ensemble_size:\n",
    "            print(f\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ {len(architectures)} –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä \" \n",
    "                  f\"–¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è –∏–∑ {ensemble_size} –º–æ–¥–µ–ª–µ–π\")\n",
    "            ensemble_size = min(ensemble_size, len(architectures))\n",
    "            \n",
    "        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "        models = []\n",
    "        performances = []\n",
    "        \n",
    "        for i, arch in enumerate(architectures[:ensemble_size * 2]):  # –ë–µ—Ä–µ–º —Å –∑–∞–ø–∞—Å–æ–º\n",
    "            print(f\"\\n–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ {i+1}/{ensemble_size*2}\")\n",
    "            best_hp, model, val_loss, _ = hp_optimizer.optimize_hyperparameters(\n",
    "                arch, trials=max_trials, epochs=30, patience=5\n",
    "            )\n",
    "            \n",
    "            models.append(model)\n",
    "            performances.append(-val_loss)  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º, —Ç.–∫. –º–µ–Ω—å—à–µ –ª—É—á—à–µ\n",
    "            \n",
    "            # –ï—Å–ª–∏ —É –Ω–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–æ–¥–µ–ª–µ–π, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è\n",
    "            if len(models) >= ensemble_size * 2:\n",
    "                break\n",
    "                \n",
    "        # –û—Ç–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è, —É—á–∏—Ç—ã–≤–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ\n",
    "        selected_models = self._select_diverse_models(\n",
    "            models, performances, ensemble_size, diversity_weight\n",
    "        )\n",
    "        \n",
    "        return selected_models\n",
    "    \n",
    "    def _select_diverse_models(self, models, performances, ensemble_size, diversity_weight):\n",
    "        \"\"\"\n",
    "        –û—Ç–±–∏—Ä–∞–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π –Ω–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è,\n",
    "        —É—á–∏—Ç—ã–≤–∞—è –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Ç–∞–∫ –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.\n",
    "        \"\"\"\n",
    "        X_val, y_val = self.val_data\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ\n",
    "        predictions = [model.predict(X_val, verbose=0).flatten() for model in models]\n",
    "        \n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "        normalized_performances = np.array(performances)\n",
    "        normalized_performances = (normalized_performances - normalized_performances.min()) / \\\n",
    "                                 (normalized_performances.max() - normalized_performances.min() + 1e-10)\n",
    "        \n",
    "        selected_indices = []\n",
    "        remaining_indices = list(range(len(models)))\n",
    "        \n",
    "        # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å (–ª—É—á—à—É—é –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)\n",
    "        best_idx = np.argmax(normalized_performances)\n",
    "        selected_indices.append(best_idx)\n",
    "        remaining_indices.remove(best_idx)\n",
    "        \n",
    "        # –í—ã–±–∏—Ä–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏, —É—á–∏—Ç—ã–≤–∞—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ\n",
    "        for _ in range(ensemble_size - 1):\n",
    "            if not remaining_indices:\n",
    "                break\n",
    "                \n",
    "            best_score = -float('inf')\n",
    "            best_idx = -1\n",
    "            \n",
    "            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∞–Ω—Å–∞–º–±–ª—è\n",
    "            ensemble_pred = np.mean([predictions[i] for i in selected_indices], axis=0)\n",
    "            \n",
    "            for idx in remaining_indices:\n",
    "                # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "                performance_score = normalized_performances[idx]\n",
    "                \n",
    "                # –û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ç–µ–∫—É—â–∏–º –∞–Ω—Å–∞–º–±–ª–µ–º)\n",
    "                model_pred = predictions[idx]\n",
    "                correlation = np.corrcoef(ensemble_pred, model_pred)[0, 1]\n",
    "                diversity_score = 1.0 - abs(correlation)  # –í—ã—Å–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ = –≤—ã—Å–æ–∫–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ\n",
    "                \n",
    "                # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞\n",
    "                combined_score = (1 - diversity_weight) * performance_score + \\\n",
    "                                 diversity_weight * diversity_score\n",
    "                \n",
    "                if combined_score > best_score:\n",
    "                    best_score = combined_score\n",
    "                    best_idx = idx\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º –æ–±—â–∏–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–º\n",
    "            selected_indices.append(best_idx)\n",
    "            remaining_indices.remove(best_idx)\n",
    "        \n",
    "        return [models[i] for i in selected_indices]\n",
    "    \n",
    "    def evaluate_ensemble(self, ensemble_models, method='mean'):\n",
    "        \"\"\"\n",
    "        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–Ω—Å–∞–º–±–ª—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        ensemble_models : list\n",
    "            –°–ø–∏—Å–æ–∫ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "        method : str, optional\n",
    "            –ú–µ—Ç–æ–¥ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π ('mean', 'median', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        \"\"\"\n",
    "        if self.test_data is None:\n",
    "            print(\"–û—à–∏–±–∫–∞: —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã\")\n",
    "            return None\n",
    "            \n",
    "        X_test, y_test = self.test_data\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "        predictions = [model.predict(X_test, verbose=0).flatten() for model in ensemble_models]\n",
    "        \n",
    "        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "        if method == 'mean':\n",
    "            ensemble_pred = np.mean(predictions, axis=0)\n",
    "        elif method == 'median':\n",
    "            ensemble_pred = np.median(predictions, axis=0)\n",
    "        elif method == 'weighted':\n",
    "            # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "            X_val, y_val = self.val_data\n",
    "            val_errors = []\n",
    "            for model in ensemble_models:\n",
    "                val_pred = model.predict(X_val, verbose=0).flatten()\n",
    "                val_mse = np.mean((val_pred - y_val) ** 2)\n",
    "                val_errors.append(val_mse)\n",
    "            \n",
    "            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—à–∏–±–∫–∏ –≤ –≤–µ—Å–∞ (–º–µ–Ω—å—à–µ –æ—à–∏–±–∫–∞ = –±–æ–ª—å—à–µ –≤–µ—Å)\n",
    "            weights = 1.0 / (np.array(val_errors) + 1e-10)\n",
    "            weights /= weights.sum()\n",
    "            \n",
    "            # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ\n",
    "            ensemble_pred = np.sum([weights[i] * predictions[i] for i in range(len(predictions))], axis=0)\n",
    "        else:\n",
    "            raise ValueError(f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {method}\")\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "        mse = np.mean((ensemble_pred - y_test) ** 2)\n",
    "        mae = np.mean(np.abs(ensemble_pred - y_test))\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ R^2\n",
    "        ss_total = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "        ss_res = np.sum((y_test - ensemble_pred) ** 2)\n",
    "        r2 = 1 - (ss_res / (ss_total + 1e-10))\n",
    "        \n",
    "        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏\n",
    "        individual_mse = [np.mean((pred - y_test) ** 2) for pred in predictions]\n",
    "        best_individual_mse = min(individual_mse)\n",
    "        \n",
    "        metrics = {\n",
    "            'ensemble_mse': mse,\n",
    "            'ensemble_mae': mae,\n",
    "            'ensemble_rmse': rmse,\n",
    "            'ensemble_r2': r2,\n",
    "            'best_individual_mse': best_individual_mse,\n",
    "            'improvement_pct': ((best_individual_mse - mse) / best_individual_mse) * 100\n",
    "        }\n",
    "        \n",
    "        print(f\"–ú–µ—Ç—Ä–∏–∫–∏ –∞–Ω—Å–∞–º–±–ª—è (–º–µ—Ç–æ–¥: {method}):\")\n",
    "        print(f\"  MSE: {mse:.6f}\")\n",
    "        print(f\"  MAE: {mae:.6f}\")\n",
    "        print(f\"  RMSE: {rmse:.6f}\")\n",
    "        print(f\"  R¬≤: {r2:.6f}\")\n",
    "        print(f\"  –£–ª—É—á—à–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {metrics['improvement_pct']:.2f}%\")\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b186449d-880c-4f7e-96ff-a6277592e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture_to_mermaid(arch):\n",
    "    \"\"\"\n",
    "    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –≤ Mermaid –¥–∏–∞–≥—Ä–∞–º–º—É –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.\n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ –ª–∏–Ω–µ–π–Ω—ã–µ, —Ç–∞–∫ –∏ DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\n",
    "    \"\"\"\n",
    "    mermaid_code = \"graph TD\\n\"\n",
    "    mermaid_code += \"    subgraph \\\"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏\\\"\\n\"\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —É–∑–µ–ª\n",
    "    mermaid_code += \"    Input[–í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π]\\n\"\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: DAG –∏–ª–∏ –ª–∏–Ω–µ–π–Ω–∞—è\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –≤–µ—Ç–≤—è–º–∏\n",
    "        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º conv_branch\n",
    "        prev_node = \"Input\"\n",
    "        for i, layer in enumerate(arch['parallel']['conv_branch']):\n",
    "            node_name = f\"Conv{i+1}\"\n",
    "            layer_info = _layer_info_to_string(layer)\n",
    "            mermaid_code += f\"    {prev_node} --> {node_name}[{layer_info}]\\n\"\n",
    "            prev_node = node_name\n",
    "        conv_last_node = prev_node\n",
    "        \n",
    "        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º rnn_branch\n",
    "        prev_node = \"Input\"\n",
    "        for i, layer in enumerate(arch['parallel']['rnn_branch']):\n",
    "            node_name = f\"RNN{i+1}\"\n",
    "            layer_info = _layer_info_to_string(layer)\n",
    "            mermaid_code += f\"    {prev_node} --> {node_name}[{layer_info}]\\n\"\n",
    "            prev_node = node_name\n",
    "        rnn_last_node = prev_node\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Ç–≤–µ–π\n",
    "        mermaid_code += f\"    {conv_last_node} --> Merge[Concatenate]\\n\"\n",
    "        mermaid_code += f\"    {rnn_last_node} --> Merge\\n\"\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        mermaid_code += f\"    Merge --> Output[Dense<br/>1 —é–Ω–∏—Ç<br/>linear]\\n\"\n",
    "    else:\n",
    "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏–Ω–µ–π–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "        prev_node = \"Input\"\n",
    "        for i, layer in enumerate(arch):\n",
    "            if layer['layer'] == 'Dense' and layer['units'] == 1 and i == len(arch) - 1:\n",
    "                # –≠—Ç–æ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏ –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ\n",
    "                continue\n",
    "                \n",
    "            node_name = f\"Layer{i+1}\"\n",
    "            layer_info = _layer_info_to_string(layer)\n",
    "            mermaid_code += f\"    {prev_node} --> {node_name}[{layer_info}]\\n\"\n",
    "            prev_node = node_name\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        mermaid_code += f\"    {prev_node} --> Output[Dense<br/>1 —é–Ω–∏—Ç<br/>linear]\\n\"\n",
    "    \n",
    "    mermaid_code += \"    end\"\n",
    "    return mermaid_code\n",
    "\n",
    "def _layer_info_to_string(layer):\n",
    "    \"\"\"–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–ª–æ–µ\"\"\"\n",
    "    layer_type = layer.get('layer', '')\n",
    "    info = f\"{layer_type}\"\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —Ç–∏–ø–∞ —Å–ª–æ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    if layer_type == 'Dense':\n",
    "        info += f\"<br/>{layer['units']} —é–Ω–∏—Ç–æ–≤\"\n",
    "        if 'activation' in layer:\n",
    "            info += f\"<br/>{layer['activation']}\"\n",
    "        if layer.get('dropout', 0) > 0:\n",
    "            info += f\"<br/>dropout={layer['dropout']}\"\n",
    "            \n",
    "    elif layer_type == 'Conv1D':\n",
    "        info += f\"<br/>{layer['filters']} —Ñ–∏–ª—å—Ç—Ä–æ–≤\"\n",
    "        info += f\"<br/>kernel={layer['kernel_size']}\"\n",
    "        if 'activation' in layer:\n",
    "            info += f\"<br/>{layer['activation']}\"\n",
    "        if layer.get('batch_norm', False):\n",
    "            info += f\"<br/>BatchNorm\"\n",
    "        if layer.get('dropout', 0) > 0:\n",
    "            info += f\"<br/>dropout={layer['dropout']}\"\n",
    "            \n",
    "    elif layer_type in ('GRU', 'RNN'):\n",
    "        info += f\"<br/>{layer['units']} —é–Ω–∏—Ç–æ–≤\"\n",
    "        if 'return_sequences' in layer:\n",
    "            info += f\"<br/>return_seq={str(layer['return_sequences'])}\"\n",
    "        if 'activation' in layer:\n",
    "            info += f\"<br/>{layer['activation']}\"\n",
    "        if layer.get('dropout', 0) > 0:\n",
    "            info += f\"<br/>dropout={layer['dropout']}\"\n",
    "            \n",
    "    elif layer_type == 'GlobalAvgPool1D':\n",
    "        info = \"GlobalAvgPooling1D\"\n",
    "        \n",
    "    elif layer_type == 'Flatten':\n",
    "        info = \"Flatten\"\n",
    "        \n",
    "    return info\n",
    "\n",
    "def visualize_best_architectures(best_archs, output_file=None):\n",
    "    \"\"\"\n",
    "    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª—É—á—à–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, –Ω–∞–π–¥–µ–Ω–Ω—ã–µ GA\n",
    "    best_archs: —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, fitness)\n",
    "    output_file: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.display import display, Markdown\n",
    "    \n",
    "    for i, (arch, fitness) in enumerate(best_archs):\n",
    "        print(f\"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ #{i+1}, –§–∏—Ç–Ω–µ—Å: {fitness}\")\n",
    "        mermaid_diagram = architecture_to_mermaid(arch)\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ –≤ Jupyter –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª\n",
    "        if output_file:\n",
    "            with open(f\"{output_file}_{i}.md\", \"w\") as f:\n",
    "                f.write(f\"# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ #{i+1}\\n\\n\")\n",
    "                f.write(f\"–§–∏—Ç–Ω–µ—Å: {fitness}\\n\\n\")\n",
    "                f.write(\"```mermaid\\n\")\n",
    "                f.write(mermaid_diagram)\n",
    "                f.write(\"\\n```\\n\")\n",
    "        else:\n",
    "            # –î–ª—è Jupyter Notebook\n",
    "            try:\n",
    "                display(Markdown(f\"```mermaid\\n{mermaid_diagram}\\n```\"))\n",
    "            except:\n",
    "                print(\"–î–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è mermaid-–¥–∏–∞–≥—Ä–∞–º–º —Ç—Ä–µ–±—É–µ—Ç—Å—è Jupyter Notebook\")\n",
    "                print(mermaid_diagram)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "def example_visualization():\n",
    "    \"\"\"–ü—Ä–∏–º–µ—Ä –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\"\"\"\n",
    "    # –ü—Ä–∏–º–µ—Ä –ª–∏–Ω–µ–π–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "    linear_arch = [\n",
    "        {'layer': 'Conv1D', 'filters': 64, 'kernel_size': 3, 'strides': 1, \n",
    "         'padding': 'same', 'activation': 'relu', 'batch_norm': True, \n",
    "         'dropout': 0.1, 'pooling': None},\n",
    "        {'layer': 'Conv1D', 'filters': 128, 'kernel_size': 5, 'strides': 1, \n",
    "         'padding': 'same', 'activation': 'relu', 'batch_norm': False, \n",
    "         'dropout': 0.2, 'pooling': None},\n",
    "        {'layer': 'GlobalAvgPool1D'},\n",
    "        {'layer': 'Dense', 'units': 64, 'activation': 'relu', 'dropout': 0.2},\n",
    "        {'layer': 'Dense', 'units': 1, 'activation': 'linear'}\n",
    "    ]\n",
    "    \n",
    "    # –ü—Ä–∏–º–µ—Ä DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "    dag_arch = {\n",
    "        'parallel': {\n",
    "            'conv_branch': [\n",
    "                {'layer': 'Conv1D', 'filters': 64, 'kernel_size': 3, 'strides': 1, \n",
    "                 'padding': 'same', 'activation': 'relu', 'batch_norm': True, \n",
    "                 'dropout': 0.1, 'pooling': None},\n",
    "                {'layer': 'GlobalAvgPool1D'}\n",
    "            ],\n",
    "            'rnn_branch': [\n",
    "                {'layer': 'GRU', 'units': 64, 'activation': 'tanh', \n",
    "                 'return_sequences': True, 'dropout': 0.1, 'recurrent_dropout': 0.0},\n",
    "                {'layer': 'GRU', 'units': 32, 'activation': 'tanh', \n",
    "                 'return_sequences': False, 'dropout': 0.2, 'recurrent_dropout': 0.1}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "    best_archs = [(linear_arch, -0.152), (dag_arch, -0.118)]\n",
    "    visualize_best_architectures(best_archs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d398dad-7818-436d-9980-1169d83dc0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d44c5-a294-413e-93a0-457916f07390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "def crossover_dag(parent_a, parent_b):\n",
    "    \"\"\"\n",
    "    –°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–ª—è DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä (—Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –≤–µ—Ç–≤—è–º–∏).\n",
    "    –°—Ç—Ä–∞—Ç–µ–≥–∏—è: —Å–º–µ—à–∏–≤–∞–Ω–∏–µ –≤–µ—Ç–≤–µ–π –º–µ–∂–¥—É —Ä–æ–¥–∏—Ç–µ–ª—è–º–∏.\n",
    "    \"\"\"\n",
    "    # –ï—Å–ª–∏ –æ–±–∞ —Ä–æ–¥–∏—Ç–µ–ª—è - DAG, –≤—ã–ø–æ–ª–Ω—è–µ–º —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ –≤–µ—Ç–≤–µ–π\n",
    "    if isinstance(parent_a, dict) and isinstance(parent_b, dict) and 'parallel' in parent_a and 'parallel' in parent_b:\n",
    "        child = {'parallel': {}}\n",
    "        \n",
    "        # –î–ª—è –∫–∞–∂–¥–æ–π –≤–µ—Ç–≤–∏ –≤—ã–±–∏—Ä–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—è –∏–ª–∏ –≤—ã–ø–æ–ª–Ω—è–µ–º —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–µ–≤\n",
    "        for branch in ['conv_branch', 'rnn_branch']:\n",
    "            if random.random() < 0.5:\n",
    "                # –ë–µ—Ä–µ–º –≤–µ—Ç–≤—å —Ü–µ–ª–∏–∫–æ–º –æ—Ç –æ–¥–Ω–æ–≥–æ –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª–µ–π\n",
    "                source = random.choice([parent_a, parent_b])\n",
    "                child['parallel'][branch] = copy.deepcopy(source['parallel'][branch])\n",
    "            else:\n",
    "                # –°–∫—Ä–µ—â–∏–≤–∞–µ–º —Å–ª–æ–∏ –∏–∑ –æ–±–µ–∏—Ö –≤–µ—Ç–≤–µ–π\n",
    "                branch_a = parent_a['parallel'][branch]\n",
    "                branch_b = parent_b['parallel'][branch]\n",
    "                \n",
    "                # –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ –≤–µ—Ç–≤–∏\n",
    "                cut = random.randint(1, min(len(branch_a), len(branch_b)) - 1)\n",
    "                child['parallel'][branch] = copy.deepcopy(branch_a[:cut] + branch_b[cut:])\n",
    "        \n",
    "        return child\n",
    "        \n",
    "    # –ï—Å–ª–∏ –æ–¥–∏–Ω –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª–µ–π - DAG, –¥—Ä—É–≥–æ–π - –ª–∏–Ω–µ–π–Ω—ã–π —Å–ø–∏—Å–æ–∫, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DAG\n",
    "    elif isinstance(parent_a, dict) and isinstance(parent_a.get('parallel'), dict) and isinstance(parent_b, list):\n",
    "        # –í—ã–±–∏—Ä–∞–µ–º, –∫–∞–∫—É—é –≤–µ—Ç–≤—å –∑–∞–º–µ–Ω–∏—Ç—å –∏–∑ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è\n",
    "        target_branch = random.choice(['conv_branch', 'rnn_branch'])\n",
    "        child = copy.deepcopy(parent_a)\n",
    "        \n",
    "        # –ù–∞—Ö–æ–¥–∏–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Å–ª–æ–∏ –∏–∑ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è\n",
    "        if target_branch == 'conv_branch':\n",
    "            suitable_layers = [l for l in parent_b if l.get('layer') == 'Conv1D']\n",
    "        else:  # rnn_branch\n",
    "            suitable_layers = [l for l in parent_b if l.get('layer') in ('GRU', 'RNN')]\n",
    "        \n",
    "        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Å–ª–æ–∏, –∑–∞–º–µ–Ω—è–µ–º –≤–µ—Ç–≤—å\n",
    "        if suitable_layers:\n",
    "            child['parallel'][target_branch] = copy.deepcopy(suitable_layers)\n",
    "            \n",
    "            # –î–ª—è RNN-–≤–µ—Ç–≤–∏ –Ω—É–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å return_sequences\n",
    "            if target_branch == 'rnn_branch':\n",
    "                for i, layer in enumerate(child['parallel'][target_branch]):\n",
    "                    layer['return_sequences'] = (i < len(child['parallel'][target_branch]) - 1)\n",
    "        \n",
    "        return child\n",
    "        \n",
    "    elif isinstance(parent_b, dict) and isinstance(parent_b.get('parallel'), dict) and isinstance(parent_a, list):\n",
    "        # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É —Å–ª—É—á–∞—é, –Ω–æ —Ä–æ–¥–∏—Ç–µ–ª–∏ –º–µ–Ω—è—é—Ç—Å—è –º–µ—Å—Ç–∞–º–∏\n",
    "        return crossover_dag(parent_b, parent_a)\n",
    "        \n",
    "    # –ï—Å–ª–∏ –æ–±–∞ —Ä–æ–¥–∏—Ç–µ–ª—è - –ª–∏–Ω–µ–π–Ω—ã–µ —Å–ø–∏—Å–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ\n",
    "    else:\n",
    "        return crossover(parent_a, parent_b)\n",
    "\n",
    "def mutate_dag(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, branch_mut=0.1):\n",
    "    \"\"\"\n",
    "    –ú—É—Ç–∞—Ü–∏—è DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –º—É—Ç–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤–µ—Ç–≤–µ–π.\n",
    "    \"\"\"\n",
    "    # –ï—Å–ª–∏ —ç—Ç–æ DAG —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –≤–µ—Ç–≤—è–º–∏\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        result = copy.deepcopy(arch)\n",
    "        \n",
    "        # –ú—É—Ç–∞—Ü–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ –≤–µ—Ç–≤–µ–π: –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞, –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ—Ç–≤–∏ –∏–ª–∏ —Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏—è\n",
    "        if random.random() < branch_mut:\n",
    "            branch_to_mutate = random.choice(['conv_branch', 'rnn_branch'])\n",
    "            mutation_type = random.choice(['replace', 'restructure'])\n",
    "            \n",
    "            if mutation_type == 'replace':\n",
    "                # –ü–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ –≤–µ—Ç–≤–∏ –Ω–æ–≤–æ–π —Å–ª—É—á–∞–π–Ω–æ–π\n",
    "                if branch_to_mutate == 'conv_branch':\n",
    "                    depth = random.randint(1, 3)\n",
    "                    result['parallel'][branch_to_mutate] = [random_conv1d_block() for _ in range(depth)]\n",
    "                    result['parallel'][branch_to_mutate].append(global_pool_block())\n",
    "                else:  # rnn_branch\n",
    "                    depth = random.randint(1, 3)\n",
    "                    result['parallel'][branch_to_mutate] = []\n",
    "                    for i in range(depth):\n",
    "                        block = random_rnn_block(random.choice(['GRU', 'RNN']))\n",
    "                        block['return_sequences'] = (i < depth - 1)\n",
    "                        result['parallel'][branch_to_mutate].append(block)\n",
    "            \n",
    "            elif mutation_type == 'restructure':\n",
    "                # –†–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è\n",
    "                branch = result['parallel'][branch_to_mutate]\n",
    "                \n",
    "                if random.random() < 0.5 and len(branch) > 1:\n",
    "                    # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è (–Ω–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ Pool/Flatten –¥–ª—è conv_branch)\n",
    "                    if branch_to_mutate == 'conv_branch' and branch[-1]['layer'] in ('GlobalAvgPool1D', 'Flatten'):\n",
    "                        pos = random.randint(0, len(branch) - 2)\n",
    "                    else:\n",
    "                        pos = random.randint(0, len(branch) - 1)\n",
    "                    branch.pop(pos)\n",
    "                    \n",
    "                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ return_sequences –¥–ª—è RNN-–≤–µ—Ç–≤–∏\n",
    "                    if branch_to_mutate == 'rnn_branch':\n",
    "                        for i, layer in enumerate(branch):\n",
    "                            if layer['layer'] in ('GRU', 'RNN'):\n",
    "                                layer['return_sequences'] = (i < len(branch) - 1)\n",
    "                else:\n",
    "                    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ—è\n",
    "                    if branch_to_mutate == 'conv_branch':\n",
    "                        # –î–ª—è —Å–≤—ë—Ä—Ç–æ—á–Ω–æ–π –≤–µ—Ç–≤–∏ –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–¥ –ø–æ—Å–ª–µ–¥–Ω–∏–º —Å–ª–æ–µ–º (–µ—Å–ª–∏ —ç—Ç–æ GlobalAvgPool)\n",
    "                        if branch[-1]['layer'] in ('GlobalAvgPool1D', 'Flatten'):\n",
    "                            branch.insert(len(branch) - 1, random_conv1d_block())\n",
    "                        else:\n",
    "                            branch.append(random_conv1d_block())\n",
    "                    else:  # rnn_branch\n",
    "                        # –î–ª—è RNN –≤–µ—Ç–≤–∏ –æ–±–Ω–æ–≤–ª—è–µ–º return_sequences\n",
    "                        new_layer = random_rnn_block(random.choice(['GRU', 'RNN']))\n",
    "                        pos = random.randint(0, len(branch))\n",
    "                        branch.insert(pos, new_layer)\n",
    "                        \n",
    "                        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥–∏ return_sequences\n",
    "                        for i, layer in enumerate(branch):\n",
    "                            if layer['layer'] in ('GRU', 'RNN'):\n",
    "                                layer['return_sequences'] = (i < len(branch) - 1)\n",
    "        \n",
    "        # –ú—É—Ç–∞—Ü–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–µ–≤ –≤ –∫–∞–∂–¥–æ–π –≤–µ—Ç–≤–∏\n",
    "        for branch_name, branch in result['parallel'].items():\n",
    "            for i, layer in enumerate(branch):\n",
    "                r = random.random()\n",
    "                if r < base_mut:\n",
    "                    # –ü–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Å–ª–æ—è\n",
    "                    if branch_name == 'conv_branch' and layer['layer'] == 'Conv1D':\n",
    "                        branch[i] = random_conv1d_block()\n",
    "                    elif branch_name == 'rnn_branch' and layer['layer'] in ('GRU', 'RNN'):\n",
    "                        new_layer = random_rnn_block(random.choice(['GRU', 'RNN']))\n",
    "                        new_layer['return_sequences'] = layer['return_sequences']\n",
    "                        branch[i] = new_layer\n",
    "                elif r < base_mut + param_mut:\n",
    "                    # –ú—É—Ç–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "                    l = copy.deepcopy(layer)\n",
    "                    if 'units' in l:\n",
    "                        l['units'] = max(1, int(l['units'] * random.uniform(0.5, 1.5)))\n",
    "                    if 'filters' in l:\n",
    "                        l['filters'] = max(1, int(l['filters'] * random.uniform(0.5, 1.5)))\n",
    "                    if 'dropout' in l:\n",
    "                        l['dropout'] = min(0.5, max(0.0, l['dropout'] + random.uniform(-0.1, 0.1)))\n",
    "                    branch[i] = l\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # –î–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º—É—Ç–∞—Ü–∏—é\n",
    "    else:\n",
    "        return mutate(arch, base_mut, param_mut, struct_mut)\n",
    "        \n",
    "# –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –æ–±–æ–∏—Ö —Ç–∏–ø–æ–≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\n",
    "def universal_crossover(parent_a, parent_b):\n",
    "    \"\"\"–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–µ–µ —Ç–∏–ø –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\"\"\"\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω DAG\n",
    "    if (isinstance(parent_a, dict) and 'parallel' in parent_a) or \\\n",
    "       (isinstance(parent_b, dict) and 'parallel' in parent_b):\n",
    "        return crossover_dag(parent_a, parent_b)\n",
    "    else:\n",
    "        return crossover(parent_a, parent_b)\n",
    "\n",
    "def universal_mutate(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, branch_mut=0.1):\n",
    "    \"\"\"–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º—É—Ç–∞—Ü–∏—è, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–∞—è —Ç–∏–ø –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\"\"\"\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        return mutate_dag(arch, base_mut, param_mut, struct_mut, branch_mut)\n",
    "    else:\n",
    "        return mutate(arch, base_mut, param_mut, struct_mut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4fb13-f987-4f13-80ef-8a61a7107e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def worker_evaluate(args):\n",
    "    \"\"\"\n",
    "    –†–∞–±–æ—á–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –º–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏.\n",
    "    args: –∫–æ—Ä—Ç–µ–∂ (arch, train_data, val_data, metric, epochs, verbose, worker_id)\n",
    "\n",
    "    –î–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ GPU –º–µ–∂–¥—É –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏.\n",
    "    \"\"\"\n",
    "    arch, train_data, val_data, metric, epochs, verbose, worker_id = args\n",
    "    \n",
    "    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º GPU-–ø–∞–º—è—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # –ó–∞–¥–∞—ë–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–º –ø–∞–º—è—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞\n",
    "            tf.config.set_visible_devices([], 'GPU')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    \n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ—Ü–µ–Ω–∫–∏ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–¥–∞\n",
    "    X_train, y_train = train_data\n",
    "    X_val, y_val = val_data\n",
    "    \n",
    "    # –ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –±–æ–ª—å—à–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏, —Å—Ç–æ–∏—Ç –¥–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫\n",
    "    try:\n",
    "        model = build_model_from_architecture(arch, X_train.shape[1:])\n",
    "        model.compile(optimizer='adam', loss=metric, metrics=[metric])\n",
    "        \n",
    "        # –ö–æ–ª–±—ç–∫ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ —Å–ª–∞–±—ã–µ –º–æ–¥–µ–ª–∏\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=f'val_{metric}', \n",
    "            patience=2,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        val_res = history.history['val_' + metric][-1]\n",
    "        # –û—á–∏—â–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –ø–∞–º—è—Ç–∏\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        return -val_res\n",
    "    except Exception as e:\n",
    "        print(f\"Error in worker {worker_id}: {e}\")\n",
    "        return float('-inf')  # –ù–∞–∏—Ö—É–¥—à–∏–π —Ñ–∏—Ç–Ω–µ—Å –¥–ª—è –æ—à–∏–±–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "\n",
    "def parallel_evaluate_fitness(population, train_data, val_data, metric='mse', epochs=5, verbose=0, n_jobs=None):\n",
    "    \"\"\"\n",
    "    –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ñ–∏—Ç–Ω–µ—Å –≤—Å–µ–π –ø–æ–ø—É–ª—è—Ü–∏–∏.\n",
    "    n_jobs: —á–∏—Å–ª–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, None = –ø–æ —á–∏—Å–ª—É —è–¥–µ—Ä.\n",
    "    \"\"\"\n",
    "    n_jobs = n_jobs or os.cpu_count()\n",
    "    \n",
    "    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏\n",
    "    args_list = [(arch, train_data, val_data, metric, epochs, verbose, i) \n",
    "                for i, arch in enumerate(population)]\n",
    "    \n",
    "    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—É–ª –ø—Ä–æ—Ü–µ—Å—Å–æ–≤\n",
    "    with Pool(processes=n_jobs) as pool:\n",
    "        fitnesses = pool.map(worker_evaluate, args_list)\n",
    "    \n",
    "    return fitnesses\n",
    "\n",
    "# –ò–∑–º–µ–Ω–µ–Ω–Ω—ã–π –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏\n",
    "def run_parallel_ga(\n",
    "    train_data, val_data,\n",
    "    pop_size=20,\n",
    "    generations=10,\n",
    "    max_params=None,\n",
    "    elitism=2,\n",
    "    metric='mse',\n",
    "    epochs=5,\n",
    "    n_jobs=None\n",
    "):\n",
    "    \"\"\"\n",
    "    –í–µ—Ä—Å–∏—è GA —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–æ–π —Ñ–∏—Ç–Ω–µ—Å–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏.\n",
    "    \"\"\"\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    population = generate_population(pop_size=pop_size, max_params=max_params)\n",
    "    fitnesses = parallel_evaluate_fitness(\n",
    "        population, train_data, val_data, metric, epochs, verbose=0, n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    best_ever = (population[0], float('-inf'))  # (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, —Ñ–∏—Ç–Ω–µ—Å)\n",
    "    \n",
    "    for gen in range(generations):\n",
    "        print(f\"Gen {gen+1}/{generations}\")\n",
    "        \n",
    "        # –û–±–Ω–æ–≤–ª—è–µ–º –ª—É—á—à—É—é –æ—Å–æ–±—å –∑–∞ –≤—Å–µ –ø–æ–∫–æ–ª–µ–Ω–∏—è\n",
    "        gen_best_idx = max(range(len(fitnesses)), key=lambda i: fitnesses[i])\n",
    "        if fitnesses[gen_best_idx] > best_ever[1]:\n",
    "            best_ever = (population[gen_best_idx], fitnesses[gen_best_idx])\n",
    "            \n",
    "        print(f\"  Best fitness: {fitnesses[gen_best_idx]:.6f}, All-time best: {best_ever[1]:.6f}\")\n",
    "        \n",
    "        # --- –≠–ª–∏—Ç–∏–∑–º: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-N –ª—É—á—à–∏—Ö ---\n",
    "        elite_idx = sorted(range(len(population)), key=lambda i: fitnesses[i], reverse=True)[:elitism]\n",
    "        new_population = [population[i] for i in elite_idx]\n",
    "\n",
    "        # --- –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –Ω–æ–≤—ã—Ö –æ—Å–æ–±–µ–π ---\n",
    "        while len(new_population) < pop_size:\n",
    "            p1, p2 = select_parents(population, fitnesses)\n",
    "            child = crossover(p1, p2)\n",
    "            child = mutate(child)\n",
    "            new_population.append(child)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = parallel_evaluate_fitness(\n",
    "            population, train_data, val_data, metric, epochs, verbose=0, n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏–∑ –≤—Å–µ—Ö –ø–æ–∫–æ–ª–µ–Ω–∏–π\n",
    "    return best_ever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd99cd9-5eaf-4e5d-8a88-dd6d43cecad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5ac6512-ffda-481e-91d1-542544b0895e",
   "metadata": {},
   "source": [
    "# –ü–æ–µ—Ö–∞–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab59d77-e750-494f-a27d-a1306e792612",
   "metadata": {},
   "source": [
    "## –ò–º–ø–æ—Ä—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea49c11-a6c6-4b62-91c5-9d1601a9e5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 21:01:57.070425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746986517.214547    5416 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746986517.246891    5416 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746986517.485434    5416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746986517.485506    5416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746986517.485508    5416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746986517.485510    5416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-11 21:01:57.517267: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv1D, GlobalAveragePooling1D, Flatten,\n",
    "    GRU, SimpleRNN, BatchNormalization, Activation, Dropout\n",
    ")\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ceeaf0-6568-4cb1-982f-145faf82ad78",
   "metadata": {},
   "source": [
    "## –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b295f11-9e64-4ef5-b556-e3df89b33ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture_to_mermaid(arch):\n",
    "    \"\"\"\n",
    "    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –≤ Mermaid –¥–∏–∞–≥—Ä–∞–º–º—É –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.\n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ –ª–∏–Ω–µ–π–Ω—ã–µ, —Ç–∞–∫ –∏ DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\n",
    "    \"\"\"\n",
    "    mermaid_code = \"graph TD\\n\"\n",
    "    mermaid_code += \"    subgraph \\\"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏\\\"\\n\"\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —É–∑–µ–ª\n",
    "    mermaid_code += \"    Input[–í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π]\\n\"\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: DAG –∏–ª–∏ –ª–∏–Ω–µ–π–Ω–∞—è\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –≤–µ—Ç–≤—è–º–∏\n",
    "        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º conv_branch\n",
    "        prev_node = \"Input\"\n",
    "        for i, layer in enumerate(arch['parallel']['conv_branch']):\n",
    "            node_name = f\"Conv{i+1}\"\n",
    "            layer_info = _layer_info_to_string(layer)\n",
    "            mermaid_code += f\"    {prev_node} --> {node_name}[{layer_info}]\\n\"\n",
    "            prev_node = node_name\n",
    "        conv_last_node = prev_node\n",
    "        \n",
    "        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º rnn_branch\n",
    "        prev_node = \"Input\"\n",
    "        for i, layer in enumerate(arch['parallel']['rnn_branch']):\n",
    "            node_name = f\"RNN{i+1}\"\n",
    "            layer_info = _layer_info_to_string(layer)\n",
    "            mermaid_code += f\"    {prev_node} --> {node_name}[{layer_info}]\\n\"\n",
    "            prev_node = node_name\n",
    "        rnn_last_node = prev_node\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Ç–≤–µ–π\n",
    "        mermaid_code += f\"    {conv_last_node} --> Merge[Concatenate]\\n\"\n",
    "        mermaid_code += f\"    {rnn_last_node} --> Merge\\n\"\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        mermaid_code += f\"    Merge --> Output[Dense<br/>1 —é–Ω–∏—Ç<br/>linear]\\n\"\n",
    "    else:\n",
    "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏–Ω–µ–π–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "        prev_node = \"Input\"\n",
    "        for i, layer in enumerate(arch):\n",
    "            if layer['layer'] == 'Dense' and layer['units'] == 1 and i == len(arch) - 1:\n",
    "                # –≠—Ç–æ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏ –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ\n",
    "                continue\n",
    "                \n",
    "            node_name = f\"Layer{i+1}\"\n",
    "            layer_info = _layer_info_to_string(layer)\n",
    "            mermaid_code += f\"    {prev_node} --> {node_name}[{layer_info}]\\n\"\n",
    "            prev_node = node_name\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        mermaid_code += f\"    {prev_node} --> Output[Dense<br/>1 —é–Ω–∏—Ç<br/>linear]\\n\"\n",
    "    \n",
    "    mermaid_code += \"    end\"\n",
    "    return mermaid_code\n",
    "\n",
    "def _layer_info_to_string(layer):\n",
    "    \"\"\"–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–ª–æ–µ\"\"\"\n",
    "    layer_type = layer.get('layer', '')\n",
    "    info = f\"{layer_type}\"\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —Ç–∏–ø–∞ —Å–ª–æ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    if layer_type == 'Dense':\n",
    "        info += f\"<br/>{layer['units']} —é–Ω–∏—Ç–æ–≤\"\n",
    "        if 'activation' in layer:\n",
    "            info += f\"<br/>{layer['activation']}\"\n",
    "        if layer.get('dropout', 0) > 0:\n",
    "            info += f\"<br/>dropout={layer['dropout']}\"\n",
    "            \n",
    "    elif layer_type == 'Conv1D':\n",
    "        info += f\"<br/>{layer['filters']} —Ñ–∏–ª—å—Ç—Ä–æ–≤\"\n",
    "        info += f\"<br/>kernel={layer['kernel_size']}\"\n",
    "        if 'activation' in layer:\n",
    "            info += f\"<br/>{layer['activation']}\"\n",
    "        if layer.get('batch_norm', False):\n",
    "            info += f\"<br/>BatchNorm\"\n",
    "        if layer.get('dropout', 0) > 0:\n",
    "            info += f\"<br/>dropout={layer['dropout']}\"\n",
    "            \n",
    "    elif layer_type in ('GRU', 'RNN'):\n",
    "        info += f\"<br/>{layer['units']} —é–Ω–∏—Ç–æ–≤\"\n",
    "        if 'return_sequences' in layer:\n",
    "            info += f\"<br/>return_seq={str(layer['return_sequences'])}\"\n",
    "        if 'activation' in layer:\n",
    "            info += f\"<br/>{layer['activation']}\"\n",
    "        if layer.get('dropout', 0) > 0:\n",
    "            info += f\"<br/>dropout={layer['dropout']}\"\n",
    "            \n",
    "    elif layer_type == 'GlobalAvgPool1D':\n",
    "        info = \"GlobalAvgPooling1D\"\n",
    "        \n",
    "    elif layer_type == 'Flatten':\n",
    "        info = \"Flatten\"\n",
    "        \n",
    "    return info\n",
    "\n",
    "def visualize_best_architectures(best_archs, output_file=None):\n",
    "    \"\"\"\n",
    "    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª—É—á—à–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, –Ω–∞–π–¥–µ–Ω–Ω—ã–µ GA\n",
    "    best_archs: —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, fitness)\n",
    "    output_file: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.display import display, Markdown\n",
    "    \n",
    "    for i, (arch, fitness) in enumerate(best_archs):\n",
    "        print(f\"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ #{i+1}, –§–∏—Ç–Ω–µ—Å: {fitness}\")\n",
    "        mermaid_diagram = architecture_to_mermaid(arch)\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ –≤ Jupyter –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª\n",
    "        if output_file:\n",
    "            with open(f\"{output_file}_{i}.md\", \"w\") as f:\n",
    "                f.write(f\"# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ #{i+1}\\n\\n\")\n",
    "                f.write(f\"–§–∏—Ç–Ω–µ—Å: {fitness}\\n\\n\")\n",
    "                f.write(\"```mermaid\\n\")\n",
    "                f.write(mermaid_diagram)\n",
    "                f.write(\"\\n```\\n\")\n",
    "        else:\n",
    "            # –î–ª—è Jupyter Notebook\n",
    "            try:\n",
    "                display(Markdown(f\"```mermaid\\n{mermaid_diagram}\\n```\"))\n",
    "            except:\n",
    "                print(\"–î–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è mermaid-–¥–∏–∞–≥—Ä–∞–º–º —Ç—Ä–µ–±—É–µ—Ç—Å—è Jupyter Notebook\")\n",
    "                print(mermaid_diagram)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "def example_visualization():\n",
    "    \"\"\"–ü—Ä–∏–º–µ—Ä –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\"\"\"\n",
    "    # –ü—Ä–∏–º–µ—Ä –ª–∏–Ω–µ–π–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "    linear_arch = [\n",
    "        {'layer': 'Conv1D', 'filters': 64, 'kernel_size': 3, 'strides': 1, \n",
    "         'padding': 'same', 'activation': 'relu', 'batch_norm': True, \n",
    "         'dropout': 0.1, 'pooling': None},\n",
    "        {'layer': 'Conv1D', 'filters': 128, 'kernel_size': 5, 'strides': 1, \n",
    "         'padding': 'same', 'activation': 'relu', 'batch_norm': False, \n",
    "         'dropout': 0.2, 'pooling': None},\n",
    "        {'layer': 'GlobalAvgPool1D'},\n",
    "        {'layer': 'Dense', 'units': 64, 'activation': 'relu', 'dropout': 0.2},\n",
    "        {'layer': 'Dense', 'units': 1, 'activation': 'linear'}\n",
    "    ]\n",
    "    \n",
    "    # –ü—Ä–∏–º–µ—Ä DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "    dag_arch = {\n",
    "        'parallel': {\n",
    "            'conv_branch': [\n",
    "                {'layer': 'Conv1D', 'filters': 64, 'kernel_size': 3, 'strides': 1, \n",
    "                 'padding': 'same', 'activation': 'relu', 'batch_norm': True, \n",
    "                 'dropout': 0.1, 'pooling': None},\n",
    "                {'layer': 'GlobalAvgPool1D'}\n",
    "            ],\n",
    "            'rnn_branch': [\n",
    "                {'layer': 'GRU', 'units': 64, 'activation': 'tanh', \n",
    "                 'return_sequences': True, 'dropout': 0.1, 'recurrent_dropout': 0.0},\n",
    "                {'layer': 'GRU', 'units': 32, 'activation': 'tanh', \n",
    "                 'return_sequences': False, 'dropout': 0.2, 'recurrent_dropout': 0.1}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "    best_archs = [(linear_arch, -0.152), (dag_arch, -0.118)]\n",
    "    visualize_best_architectures(best_archs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a65625-093a-48d4-b212-d6e52d32ba99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ #1, –§–∏—Ç–Ω–µ—Å: -0.152\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "graph TD\n",
       "    subgraph \"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏\"\n",
       "    Input[–í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π]\n",
       "    Input --> Layer1[Conv1D<br/>64 —Ñ–∏–ª—å—Ç—Ä–æ–≤<br/>kernel=3<br/>relu<br/>BatchNorm<br/>dropout=0.1]\n",
       "    Layer1 --> Layer2[Conv1D<br/>128 —Ñ–∏–ª—å—Ç—Ä–æ–≤<br/>kernel=5<br/>relu<br/>dropout=0.2]\n",
       "    Layer2 --> Layer3[GlobalAvgPooling1D]\n",
       "    Layer3 --> Layer4[Dense<br/>64 —é–Ω–∏—Ç–æ–≤<br/>relu<br/>dropout=0.2]\n",
       "    Layer4 --> Output[Dense<br/>1 —é–Ω–∏—Ç<br/>linear]\n",
       "    end\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ #2, –§–∏—Ç–Ω–µ—Å: -0.118\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "graph TD\n",
       "    subgraph \"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏\"\n",
       "    Input[–í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π]\n",
       "    Input --> Conv1[Conv1D<br/>64 —Ñ–∏–ª—å—Ç—Ä–æ–≤<br/>kernel=3<br/>relu<br/>BatchNorm<br/>dropout=0.1]\n",
       "    Conv1 --> Conv2[GlobalAvgPooling1D]\n",
       "    Input --> RNN1[GRU<br/>64 —é–Ω–∏—Ç–æ–≤<br/>return_seq=True<br/>tanh<br/>dropout=0.1]\n",
       "    RNN1 --> RNN2[GRU<br/>32 —é–Ω–∏—Ç–æ–≤<br/>return_seq=False<br/>tanh<br/>dropout=0.2]\n",
       "    Conv2 --> Merge[Concatenate]\n",
       "    RNN2 --> Merge\n",
       "    Merge --> Output[Dense<br/>1 —é–Ω–∏—Ç<br/>linear]\n",
       "    end\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccbf29-8c40-4c9a-b2e7-d3cf74d57416",
   "metadata": {},
   "source": [
    "## –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e4a05ac-f96f-4baf-8976-cc617b2874d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_dense_layer(units_choices=None):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞—ë—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "      units_choices: —Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —á–∏—Å–µ–ª –Ω–µ–π—Ä–æ–Ω–æ–≤.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–∞–º–∏:\n",
    "      layer, units, activation, kernel_regularizer, coef_regularizer (–æ–ø—Ü.), dropout\n",
    "    \"\"\"\n",
    "    units_choices = units_choices or [32, 64, 128, 256]\n",
    "    layer = {\n",
    "        'layer': 'Dense',\n",
    "        'units': random.choice(units_choices),\n",
    "        'activation': random.choice(['relu', 'sigmoid', 'tanh', 'linear']),\n",
    "        'kernel_regularizer': random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    }\n",
    "    # –ï—Å–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –≤—ã–±—Ä–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç\n",
    "    if layer['kernel_regularizer']:\n",
    "        layer['coef_regularizer'] = random.choice([0.0001, 0.001, 0.01, 0.1])\n",
    "    # Dropout –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    return layer\n",
    "\n",
    "def random_conv1d_block():\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ –æ–¥–Ω–æ-–º–µ—Ä–Ω–æ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ –±–ª–æ–∫–∞.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Å–ª–æ–≤–∞—Ä–µ:\n",
    "      layer, filters, kernel_size, strides, padding, activation,\n",
    "      batch_norm, dropout, pooling.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': 'Conv1D',\n",
    "        'filters': random.choice([32, 64, 128, 256]),\n",
    "        'kernel_size': random.choice([3, 5, 7]),\n",
    "        'strides': random.choice([1, 2]),\n",
    "        'padding': random.choice(['valid', 'same']),\n",
    "        'activation': random.choice(['relu', 'tanh', 'sigmoid', 'elu']),\n",
    "        'batch_norm': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'pooling': random.choice([None, 'max2', 'max3'])\n",
    "    }\n",
    "\n",
    "# TODO stateful –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è GRU + LSTM\n",
    "def random_rnn_block(rnn_type='GRU'):\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–≥–æ –±–ª–æ–∫–∞ GRU –∏–ª–∏ RNN.\n",
    "    –ü–æ–ª—è:\n",
    "      layer, units, activation, return_sequences,\n",
    "      dropout, recurrent_dropout\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'layer': rnn_type,\n",
    "        'units': random.choice([32, 64, 128]),\n",
    "        'activation': random.choice(['tanh', 'relu']),\n",
    "        'return_sequences': random.choice([True, False]),\n",
    "        'dropout': random.choice([0.0, 0.1, 0.2]),\n",
    "        'recurrent_dropout': random.choice([0.0, 0.1])\n",
    "    }\n",
    "\n",
    "\n",
    "def flatten_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è Flatten.\"\"\"\n",
    "    return {'layer': 'Flatten'}\n",
    "\n",
    "\n",
    "def global_pool_block():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–ª–æ—è GlobalAveragePooling1D.\"\"\"\n",
    "    return {'layer': 'GlobalAvgPool1D'}\n",
    "\n",
    "\n",
    "\n",
    "# --- –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏ ---\n",
    "# –°–ª—É—á–∞–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω—ã–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏\n",
    "\n",
    "# 1) Conv‚ÜíPool‚ÜíDense skeleton\n",
    "\n",
    "def skeleton_conv_dense(min_conv=1, max_conv=3, min_dense=1, max_dense=2):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_conv, max_conv)):\n",
    "        layers.append(random_conv1d_block())\n",
    "    layers.append(global_pool_block())\n",
    "    for _ in range(random.randint(min_dense, max_dense)):\n",
    "        layers.append(random_dense_layer())\n",
    "    return layers\n",
    "\n",
    "# 2) –ß–∏—Å—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π skeleton\n",
    "\n",
    "def skeleton_rnn(min_rnn=1, max_rnn=2, rnn_type='GRU'):\n",
    "    layers = []\n",
    "    p = random.randint(min_rnn, max_rnn)\n",
    "    for i in range(p):\n",
    "        block = random_rnn_block(rnn_type)\n",
    "        block['return_sequences'] = (i < p - 1)\n",
    "        layers.append(block)\n",
    "    layers.append(random_dense_layer(units_choices=[64, 128]))\n",
    "    return layers\n",
    "\n",
    "# 3) –°–ª—É—á–∞–π–Ω—ã–µ –±–ª–æ–∫–∏\n",
    "\n",
    "def block_randomized(min_blocks=2, max_blocks=5):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_blocks, max_blocks)):\n",
    "        choice = random.choice(['conv', 'rnn', 'dense', 'pool'])\n",
    "        if choice == 'conv':\n",
    "            layers.append(random_conv1d_block())\n",
    "        elif choice == 'rnn':\n",
    "            layers.append(random_rnn_block(random.choice(['GRU', 'RNN'])))\n",
    "        elif choice == 'dense':\n",
    "            layers.append(random_dense_layer())\n",
    "        else:\n",
    "            layers.append(random.choice([flatten_block(), global_pool_block()]))\n",
    "    return layers\n",
    "\n",
    "# 4) –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG: Conv-–≤–µ—Ç–∫–∞ –∏ RNN-–≤–µ—Ç–∫–∞\n",
    "\n",
    "def dag_parallel(min_depth=1, max_depth=3):\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏:\n",
    "      - conv_branch: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å Conv1D + global pool\n",
    "      - rnn_branch: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å RNN/GRU —Å return_sequences=True —É –≤—Å–µ—Ö, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–æ–º 'parallel'.\n",
    "    \"\"\"\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º —Å–≤—ë—Ä—Ç–æ—á–Ω—É—é –≤–µ—Ç–∫—É\n",
    "    a = [random_conv1d_block() for _ in range(random.randint(min_depth, max_depth))]\n",
    "    a.append(global_pool_block())\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º RNN –≤–µ—Ç–∫—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º return_sequences\n",
    "    depth = random.randint(min_depth, max_depth)\n",
    "    b = []\n",
    "    for i in range(depth):\n",
    "        block = random_rnn_block(random.choice(['GRU', 'RNN']))\n",
    "        # –≤—Å–µ, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ, –¥–æ–ª–∂–Ω—ã –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "        block['return_sequences'] = (i < depth - 1)\n",
    "        b.append(block)\n",
    "    # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º DAG –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å —Å –¥–≤—É–º—è –≤–µ—Ç–≤—è–º–∏\n",
    "    return {'parallel': {'conv_branch': a, 'rnn_branch': b}}\n",
    "\n",
    "# 5) –ú–∏–Ω–∏-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞\n",
    "\n",
    "def micro_arch(min_layers=2, max_layers=3):\n",
    "    layers = []\n",
    "    for _ in range(random.randint(min_layers, max_layers)):\n",
    "        layers.append(random.choice([\n",
    "            random_conv1d_block(), random_rnn_block(), random_dense_layer()\n",
    "        ]))\n",
    "    return layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a34f09-bd87-46eb-9ed7-e6e1b1b754ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(pop_size=20, strategies=None, max_params=None):\n",
    "    \"\"\"\n",
    "    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ø—É–ª—è—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\n",
    "    pop_size: —Ä–∞–∑–º–µ—Ä.\n",
    "    strategies: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤.\n",
    "    max_params: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "    \"\"\"\n",
    "    strategies = strategies or [\n",
    "        skeleton_conv_dense,\n",
    "        skeleton_rnn,\n",
    "        block_randomized,\n",
    "        dag_parallel,\n",
    "        micro_arch\n",
    "    ]\n",
    "    population = []\n",
    "    while len(population) < pop_size:\n",
    "        strat = random.choice(strategies)\n",
    "        arch = strat()  # –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å dict (DAG) –∏–ª–∏ list\n",
    "        if isinstance(arch, dict):\n",
    "            population.append(arch)\n",
    "            continue\n",
    "        # –õ–∏–Ω–µ–π–Ω–∞—è —Ü–µ–ø–æ—á–∫–∞: —É–¥–∞–ª—è–µ–º Conv/RNN –ø–æ—Å–ª–µ —É–ø–ª–æ—â–µ–Ω–∏—è\n",
    "        clean_arch = []\n",
    "        collapsed = False\n",
    "        for l in arch:\n",
    "            if collapsed and l['layer'] in ('Conv1D', 'GRU', 'RNN'):\n",
    "                # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Å–ª–æ–π\n",
    "                continue\n",
    "            clean_arch.append(l)\n",
    "            if l['layer'] in ('Flatten', 'GlobalAvgPool1D'):\n",
    "                collapsed = True\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "        clean_arch.append({'layer': 'Dense', 'units': 1, 'activation': 'linear'})\n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ max_params\n",
    "        if max_params and estimate_params(clean_arch) > max_params:\n",
    "            continue\n",
    "        population.append(clean_arch)\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ef7e8d1-655b-4f32-8d6a-7903acb2473d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'layer': 'Conv1D',\n",
       "   'filters': 32,\n",
       "   'kernel_size': 3,\n",
       "   'strides': 2,\n",
       "   'padding': 'same',\n",
       "   'activation': 'sigmoid',\n",
       "   'batch_norm': True,\n",
       "   'dropout': 0.2,\n",
       "   'pooling': None},\n",
       "  {'layer': 'Conv1D',\n",
       "   'filters': 64,\n",
       "   'kernel_size': 7,\n",
       "   'strides': 2,\n",
       "   'padding': 'valid',\n",
       "   'activation': 'tanh',\n",
       "   'batch_norm': False,\n",
       "   'dropout': 0.0,\n",
       "   'pooling': 'max2'},\n",
       "  {'layer': 'GlobalAvgPool1D'},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 64,\n",
       "   'activation': 'sigmoid',\n",
       "   'kernel_regularizer': None,\n",
       "   'dropout': 0.2},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 64,\n",
       "   'activation': 'tanh',\n",
       "   'kernel_regularizer': 'L2',\n",
       "   'coef_regularizer': 0.01,\n",
       "   'dropout': 0.1},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " {'parallel': {'conv_branch': [{'layer': 'Conv1D',\n",
       "     'filters': 64,\n",
       "     'kernel_size': 3,\n",
       "     'strides': 1,\n",
       "     'padding': 'same',\n",
       "     'activation': 'tanh',\n",
       "     'batch_norm': True,\n",
       "     'dropout': 0.0,\n",
       "     'pooling': 'max2'},\n",
       "    {'layer': 'Conv1D',\n",
       "     'filters': 256,\n",
       "     'kernel_size': 3,\n",
       "     'strides': 1,\n",
       "     'padding': 'valid',\n",
       "     'activation': 'tanh',\n",
       "     'batch_norm': False,\n",
       "     'dropout': 0.1,\n",
       "     'pooling': 'max3'},\n",
       "    {'layer': 'Conv1D',\n",
       "     'filters': 64,\n",
       "     'kernel_size': 3,\n",
       "     'strides': 2,\n",
       "     'padding': 'valid',\n",
       "     'activation': 'tanh',\n",
       "     'batch_norm': True,\n",
       "     'dropout': 0.0,\n",
       "     'pooling': 'max3'},\n",
       "    {'layer': 'GlobalAvgPool1D'}],\n",
       "   'rnn_branch': [{'layer': 'RNN',\n",
       "     'units': 64,\n",
       "     'activation': 'tanh',\n",
       "     'return_sequences': True,\n",
       "     'dropout': 0.2,\n",
       "     'recurrent_dropout': 0.1},\n",
       "    {'layer': 'RNN',\n",
       "     'units': 128,\n",
       "     'activation': 'tanh',\n",
       "     'return_sequences': False,\n",
       "     'dropout': 0.2,\n",
       "     'recurrent_dropout': 0.0}]}},\n",
       " {'parallel': {'conv_branch': [{'layer': 'Conv1D',\n",
       "     'filters': 32,\n",
       "     'kernel_size': 3,\n",
       "     'strides': 2,\n",
       "     'padding': 'valid',\n",
       "     'activation': 'tanh',\n",
       "     'batch_norm': True,\n",
       "     'dropout': 0.2,\n",
       "     'pooling': None},\n",
       "    {'layer': 'GlobalAvgPool1D'}],\n",
       "   'rnn_branch': [{'layer': 'GRU',\n",
       "     'units': 128,\n",
       "     'activation': 'relu',\n",
       "     'return_sequences': True,\n",
       "     'dropout': 0.0,\n",
       "     'recurrent_dropout': 0.1},\n",
       "    {'layer': 'GRU',\n",
       "     'units': 32,\n",
       "     'activation': 'tanh',\n",
       "     'return_sequences': True,\n",
       "     'dropout': 0.2,\n",
       "     'recurrent_dropout': 0.1},\n",
       "    {'layer': 'RNN',\n",
       "     'units': 64,\n",
       "     'activation': 'tanh',\n",
       "     'return_sequences': False,\n",
       "     'dropout': 0.1,\n",
       "     'recurrent_dropout': 0.0}]}},\n",
       " [{'layer': 'Conv1D',\n",
       "   'filters': 128,\n",
       "   'kernel_size': 7,\n",
       "   'strides': 1,\n",
       "   'padding': 'valid',\n",
       "   'activation': 'elu',\n",
       "   'batch_norm': False,\n",
       "   'dropout': 0.2,\n",
       "   'pooling': 'max3'},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 64,\n",
       "   'activation': 'sigmoid',\n",
       "   'kernel_regularizer': 'L1',\n",
       "   'coef_regularizer': 0.01,\n",
       "   'dropout': 0.2},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'GRU',\n",
       "   'units': 32,\n",
       "   'activation': 'relu',\n",
       "   'return_sequences': True,\n",
       "   'dropout': 0.0,\n",
       "   'recurrent_dropout': 0.1},\n",
       "  {'layer': 'GRU',\n",
       "   'units': 64,\n",
       "   'activation': 'tanh',\n",
       "   'return_sequences': False,\n",
       "   'dropout': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 128,\n",
       "   'activation': 'sigmoid',\n",
       "   'kernel_regularizer': 'L1L2',\n",
       "   'coef_regularizer': 0.01,\n",
       "   'dropout': 0.1},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'GRU',\n",
       "   'units': 64,\n",
       "   'activation': 'relu',\n",
       "   'return_sequences': True,\n",
       "   'dropout': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'layer': 'GRU',\n",
       "   'units': 64,\n",
       "   'activation': 'tanh',\n",
       "   'return_sequences': True,\n",
       "   'dropout': 0.0,\n",
       "   'recurrent_dropout': 0.1},\n",
       "  {'layer': 'Conv1D',\n",
       "   'filters': 128,\n",
       "   'kernel_size': 3,\n",
       "   'strides': 1,\n",
       "   'padding': 'same',\n",
       "   'activation': 'elu',\n",
       "   'batch_norm': False,\n",
       "   'dropout': 0.2,\n",
       "   'pooling': 'max3'},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'Dense',\n",
       "   'units': 64,\n",
       "   'activation': 'tanh',\n",
       "   'kernel_regularizer': 'L1',\n",
       "   'coef_regularizer': 0.01,\n",
       "   'dropout': 0.0},\n",
       "  {'layer': 'GlobalAvgPool1D'},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'Conv1D',\n",
       "   'filters': 128,\n",
       "   'kernel_size': 3,\n",
       "   'strides': 1,\n",
       "   'padding': 'same',\n",
       "   'activation': 'elu',\n",
       "   'batch_norm': True,\n",
       "   'dropout': 0.1,\n",
       "   'pooling': 'max3'},\n",
       "  {'layer': 'Conv1D',\n",
       "   'filters': 64,\n",
       "   'kernel_size': 7,\n",
       "   'strides': 1,\n",
       "   'padding': 'same',\n",
       "   'activation': 'tanh',\n",
       "   'batch_norm': True,\n",
       "   'dropout': 0.2,\n",
       "   'pooling': 'max3'},\n",
       "  {'layer': 'Conv1D',\n",
       "   'filters': 128,\n",
       "   'kernel_size': 5,\n",
       "   'strides': 2,\n",
       "   'padding': 'valid',\n",
       "   'activation': 'relu',\n",
       "   'batch_norm': True,\n",
       "   'dropout': 0.0,\n",
       "   'pooling': 'max3'},\n",
       "  {'layer': 'GlobalAvgPool1D'},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 256,\n",
       "   'activation': 'tanh',\n",
       "   'kernel_regularizer': 'L2',\n",
       "   'coef_regularizer': 0.1,\n",
       "   'dropout': 0.0},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 256,\n",
       "   'activation': 'sigmoid',\n",
       "   'kernel_regularizer': 'L1',\n",
       "   'coef_regularizer': 0.0001,\n",
       "   'dropout': 0.0},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " {'parallel': {'conv_branch': [{'layer': 'Conv1D',\n",
       "     'filters': 256,\n",
       "     'kernel_size': 5,\n",
       "     'strides': 1,\n",
       "     'padding': 'same',\n",
       "     'activation': 'tanh',\n",
       "     'batch_norm': False,\n",
       "     'dropout': 0.0,\n",
       "     'pooling': 'max3'},\n",
       "    {'layer': 'GlobalAvgPool1D'}],\n",
       "   'rnn_branch': [{'layer': 'GRU',\n",
       "     'units': 128,\n",
       "     'activation': 'tanh',\n",
       "     'return_sequences': True,\n",
       "     'dropout': 0.1,\n",
       "     'recurrent_dropout': 0.1},\n",
       "    {'layer': 'GRU',\n",
       "     'units': 64,\n",
       "     'activation': 'relu',\n",
       "     'return_sequences': False,\n",
       "     'dropout': 0.0,\n",
       "     'recurrent_dropout': 0.1}]}},\n",
       " [{'layer': 'Conv1D',\n",
       "   'filters': 32,\n",
       "   'kernel_size': 5,\n",
       "   'strides': 1,\n",
       "   'padding': 'valid',\n",
       "   'activation': 'relu',\n",
       "   'batch_norm': True,\n",
       "   'dropout': 0.2,\n",
       "   'pooling': None},\n",
       "  {'layer': 'GlobalAvgPool1D'},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 128,\n",
       "   'activation': 'tanh',\n",
       "   'kernel_regularizer': 'L2',\n",
       "   'coef_regularizer': 0.001,\n",
       "   'dropout': 0.1},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 32,\n",
       "   'activation': 'sigmoid',\n",
       "   'kernel_regularizer': None,\n",
       "   'dropout': 0.2},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'GRU',\n",
       "   'units': 128,\n",
       "   'activation': 'tanh',\n",
       "   'return_sequences': False,\n",
       "   'dropout': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 128,\n",
       "   'activation': 'sigmoid',\n",
       "   'kernel_regularizer': None,\n",
       "   'dropout': 0.1},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'Conv1D',\n",
       "   'filters': 32,\n",
       "   'kernel_size': 5,\n",
       "   'strides': 1,\n",
       "   'padding': 'valid',\n",
       "   'activation': 'sigmoid',\n",
       "   'batch_norm': True,\n",
       "   'dropout': 0.1,\n",
       "   'pooling': None},\n",
       "  {'layer': 'Flatten'},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'Conv1D',\n",
       "   'filters': 64,\n",
       "   'kernel_size': 7,\n",
       "   'strides': 2,\n",
       "   'padding': 'same',\n",
       "   'activation': 'elu',\n",
       "   'batch_norm': False,\n",
       "   'dropout': 0.1,\n",
       "   'pooling': 'max3'},\n",
       "  {'layer': 'GRU',\n",
       "   'units': 32,\n",
       "   'activation': 'tanh',\n",
       "   'return_sequences': True,\n",
       "   'dropout': 0.0,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'Conv1D',\n",
       "   'filters': 32,\n",
       "   'kernel_size': 3,\n",
       "   'strides': 1,\n",
       "   'padding': 'same',\n",
       "   'activation': 'elu',\n",
       "   'batch_norm': False,\n",
       "   'dropout': 0.0,\n",
       "   'pooling': 'max2'},\n",
       "  {'layer': 'GlobalAvgPool1D'},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 128,\n",
       "   'activation': 'linear',\n",
       "   'kernel_regularizer': None,\n",
       "   'dropout': 0.0},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 256,\n",
       "   'activation': 'sigmoid',\n",
       "   'kernel_regularizer': None,\n",
       "   'dropout': 0.1},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'RNN',\n",
       "   'units': 32,\n",
       "   'activation': 'relu',\n",
       "   'return_sequences': True,\n",
       "   'dropout': 0.1,\n",
       "   'recurrent_dropout': 0.1},\n",
       "  {'layer': 'Flatten'},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'GRU',\n",
       "   'units': 64,\n",
       "   'activation': 'relu',\n",
       "   'return_sequences': False,\n",
       "   'dropout': 0.0,\n",
       "   'recurrent_dropout': 0.1},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 32,\n",
       "   'activation': 'linear',\n",
       "   'kernel_regularizer': 'L2',\n",
       "   'coef_regularizer': 0.0001,\n",
       "   'dropout': 0.1},\n",
       "  {'layer': 'GRU',\n",
       "   'units': 64,\n",
       "   'activation': 'tanh',\n",
       "   'return_sequences': True,\n",
       "   'dropout': 0.2,\n",
       "   'recurrent_dropout': 0.1},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'GRU',\n",
       "   'units': 32,\n",
       "   'activation': 'tanh',\n",
       "   'return_sequences': True,\n",
       "   'dropout': 0.2,\n",
       "   'recurrent_dropout': 0.1},\n",
       "  {'layer': 'GRU',\n",
       "   'units': 64,\n",
       "   'activation': 'relu',\n",
       "   'return_sequences': False,\n",
       "   'dropout': 0.1,\n",
       "   'recurrent_dropout': 0.1},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 64,\n",
       "   'activation': 'sigmoid',\n",
       "   'kernel_regularizer': 'L2',\n",
       "   'coef_regularizer': 0.0001,\n",
       "   'dropout': 0.2},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'Conv1D',\n",
       "   'filters': 256,\n",
       "   'kernel_size': 7,\n",
       "   'strides': 2,\n",
       "   'padding': 'same',\n",
       "   'activation': 'tanh',\n",
       "   'batch_norm': False,\n",
       "   'dropout': 0.1,\n",
       "   'pooling': None},\n",
       "  {'layer': 'GlobalAvgPool1D'},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 32,\n",
       "   'activation': 'sigmoid',\n",
       "   'kernel_regularizer': None,\n",
       "   'dropout': 0.2},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'Conv1D',\n",
       "   'filters': 64,\n",
       "   'kernel_size': 5,\n",
       "   'strides': 2,\n",
       "   'padding': 'valid',\n",
       "   'activation': 'sigmoid',\n",
       "   'batch_norm': True,\n",
       "   'dropout': 0.0,\n",
       "   'pooling': 'max2'},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 128,\n",
       "   'activation': 'linear',\n",
       "   'kernel_regularizer': 'L2',\n",
       "   'coef_regularizer': 0.0001,\n",
       "   'dropout': 0.3},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}],\n",
       " [{'layer': 'GRU',\n",
       "   'units': 64,\n",
       "   'activation': 'relu',\n",
       "   'return_sequences': True,\n",
       "   'dropout': 0.2,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'layer': 'GRU',\n",
       "   'units': 64,\n",
       "   'activation': 'tanh',\n",
       "   'return_sequences': False,\n",
       "   'dropout': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'layer': 'Dense',\n",
       "   'units': 128,\n",
       "   'activation': 'relu',\n",
       "   'kernel_regularizer': 'L1L2',\n",
       "   'coef_regularizer': 0.01,\n",
       "   'dropout': 0.2},\n",
       "  {'layer': 'Dense', 'units': 1, 'activation': 'linear'}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_population()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f015bd-638c-4f12-b68c-2f48282ee48d",
   "metadata": {},
   "source": [
    "## –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94dcd71b-e45c-4988-bcf4-c1999d9f7a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from multiprocessing import Pool\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, LSTM, GRU, SimpleRNN, Conv1D, Dense,\n",
    "                                     Flatten, GlobalAveragePooling1D, Concatenate, \n",
    "                                     Activation, Dropout, BatchNormalization)\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "\n",
    "def build_model_from_architecture(arch, input_shape):\n",
    "    \"\"\"\n",
    "    –ö–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç Keras Model –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ arch.\n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:\n",
    "      - –õ–∏–Ω–µ–π–Ω—ã–µ —Å–ø–∏—Å–∫–∏ —Å–ª–æ—ë–≤ (list of dict)\n",
    "      - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π DAG —Å –∫–ª—é—á–æ–º 'parallel', –≥–¥–µ –≤–µ—Ç–≤–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –ª—é–±—ã–º–∏\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    def apply_branch(x, branch):\n",
    "        current = x\n",
    "        for l in branch:\n",
    "            t = l['layer']\n",
    "            if t == 'Conv1D':\n",
    "                current = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'],\n",
    "                                 strides=l['strides'], padding=l['padding'], activation=None)(current)\n",
    "                if l['batch_norm']:\n",
    "                    current = BatchNormalization()(current)\n",
    "                current = Activation(l['activation'])(current)\n",
    "                if l['dropout'] > 0:\n",
    "                    current = Dropout(l['dropout'])(current)\n",
    "            elif t in ('GRU', 'RNN'):\n",
    "                cls = GRU if t == 'GRU' else SimpleRNN\n",
    "                current = cls(units=l['units'], activation=l['activation'],\n",
    "                              return_sequences=l['return_sequences'],\n",
    "                              dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])(current)\n",
    "            elif t == 'GlobalAvgPool1D':\n",
    "                current = GlobalAveragePooling1D()(current)\n",
    "            elif t == 'Flatten':\n",
    "                current = Flatten()(current)\n",
    "            elif t == 'Dense':\n",
    "                reg = None\n",
    "                if l.get('kernel_regularizer') == 'L1': reg = l1(l['coef_regularizer'])\n",
    "                elif l.get('kernel_regularizer') == 'L2': reg = l2(l['coef_regularizer'])\n",
    "                elif l.get('kernel_regularizer') == 'L1L2': reg = l1_l2(l['coef_regularizer'])\n",
    "                current = Dense(l['units'], activation=l['activation'], kernel_regularizer=reg)(current)\n",
    "                if l.get('dropout', 0) > 0:\n",
    "                    current = Dropout(l['dropout'])(current)\n",
    "        return current\n",
    "\n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ DAG-–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        branches = []\n",
    "        for branch_layers in arch['parallel'].values():\n",
    "            branches.append(apply_branch(inp, branch_layers))\n",
    "        merged = Concatenate()(branches)\n",
    "        out = Dense(1, activation='linear')(merged)\n",
    "        return Model(inputs=inp, outputs=out)\n",
    "\n",
    "    # –û–±—ã—á–Ω–∞—è –ª–∏–Ω–µ–π–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (list)\n",
    "    x = inp\n",
    "    input_shape_rank = len(input_shape)\n",
    "    current_rank = input_shape_rank\n",
    "\n",
    "    for l in arch:\n",
    "        t = l['layer']\n",
    "\n",
    "        if current_rank < 3 and t in ('Conv1D', 'GRU', 'RNN', 'GlobalAvgPool1D'):\n",
    "            continue\n",
    "\n",
    "        if t == 'Conv1D':\n",
    "            x = Conv1D(filters=l['filters'], kernel_size=l['kernel_size'], strides=l['strides'],\n",
    "                       padding=l['padding'], activation=None)(x)\n",
    "            if l['batch_norm']: x = BatchNormalization()(x)\n",
    "            x = Activation(l['activation'])(x)\n",
    "            if l['dropout'] > 0: x = Dropout(l['dropout'])(x)\n",
    "            if l['pooling'] in ('max2', 'max3'): \n",
    "                x = GlobalAveragePooling1D()(x)\n",
    "                current_rank = 2\n",
    "        elif t in ('GRU', 'RNN'):\n",
    "            layer_cls = GRU if t == 'GRU' else SimpleRNN\n",
    "            x = layer_cls(l['units'], activation=l['activation'], return_sequences=l['return_sequences'],\n",
    "                          dropout=l['dropout'], recurrent_dropout=l['recurrent_dropout'])(x)\n",
    "            if not l['return_sequences']:\n",
    "                current_rank = 2\n",
    "        elif t == 'Flatten':\n",
    "            x = Flatten()(x)\n",
    "            current_rank = 2\n",
    "        elif t == 'GlobalAvgPool1D':\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "            current_rank = 2\n",
    "        elif t == 'Dense':\n",
    "            reg = None\n",
    "            if l.get('kernel_regularizer') == 'L1': reg = l1(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L2': reg = l2(l['coef_regularizer'])\n",
    "            elif l.get('kernel_regularizer') == 'L1L2': reg = l1_l2(l['coef_regularizer'])\n",
    "            x = Dense(l['units'], activation=l['activation'], kernel_regularizer=reg)(x)\n",
    "            if l.get('dropout',0) > 0: x = Dropout(l['dropout'])(x)\n",
    "\n",
    "    if not (len(arch) > 0 and arch[-1]['layer'] == 'Dense' and arch[-1]['units'] == 1):\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "\n",
    "    return Model(inputs=inp, outputs=x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ad7e0-ab22-4769-a5a3-a88c772951ef",
   "metadata": {},
   "source": [
    "## –û–ø–µ—Ä–∞—Ç–æ—Ä—ã –ì–ê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e73dc4-6b0c-42ba-b105-d6fb5de8e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "def crossover_dag(parent_a, parent_b):\n",
    "    \"\"\"\n",
    "    –°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–ª—è DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä (—Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –≤–µ—Ç–≤—è–º–∏).\n",
    "    –°—Ç—Ä–∞—Ç–µ–≥–∏—è: —Å–º–µ—à–∏–≤–∞–Ω–∏–µ –≤–µ—Ç–≤–µ–π –º–µ–∂–¥—É —Ä–æ–¥–∏—Ç–µ–ª—è–º–∏.\n",
    "    \"\"\"\n",
    "    # –ï—Å–ª–∏ –æ–±–∞ —Ä–æ–¥–∏—Ç–µ–ª—è - DAG, –≤—ã–ø–æ–ª–Ω—è–µ–º —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ –≤–µ—Ç–≤–µ–π\n",
    "    if isinstance(parent_a, dict) and isinstance(parent_b, dict) and 'parallel' in parent_a and 'parallel' in parent_b:\n",
    "        child = {'parallel': {}}\n",
    "        \n",
    "        # –î–ª—è –∫–∞–∂–¥–æ–π –≤–µ—Ç–≤–∏ –≤—ã–±–∏—Ä–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—è –∏–ª–∏ –≤—ã–ø–æ–ª–Ω—è–µ–º —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–µ–≤\n",
    "        for branch in ['conv_branch', 'rnn_branch']:\n",
    "            if random.random() < 0.5:\n",
    "                # –ë–µ—Ä–µ–º –≤–µ—Ç–≤—å —Ü–µ–ª–∏–∫–æ–º –æ—Ç –æ–¥–Ω–æ–≥–æ –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª–µ–π\n",
    "                source = random.choice([parent_a, parent_b])\n",
    "                child['parallel'][branch] = copy.deepcopy(source['parallel'][branch])\n",
    "            else:\n",
    "                # –°–∫—Ä–µ—â–∏–≤–∞–µ–º —Å–ª–æ–∏ –∏–∑ –æ–±–µ–∏—Ö –≤–µ—Ç–≤–µ–π\n",
    "                branch_a = parent_a['parallel'][branch]\n",
    "                branch_b = parent_b['parallel'][branch]\n",
    "                \n",
    "                # –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ –≤–µ—Ç–≤–∏\n",
    "                cut = random.randint(1, min(len(branch_a), len(branch_b)) - 1)\n",
    "                child['parallel'][branch] = copy.deepcopy(branch_a[:cut] + branch_b[cut:])\n",
    "        \n",
    "        return child\n",
    "        \n",
    "    # –ï—Å–ª–∏ –æ–¥–∏–Ω –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª–µ–π - DAG, –¥—Ä—É–≥–æ–π - –ª–∏–Ω–µ–π–Ω—ã–π —Å–ø–∏—Å–æ–∫, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DAG\n",
    "    elif isinstance(parent_a, dict) and isinstance(parent_a.get('parallel'), dict) and isinstance(parent_b, list):\n",
    "        # –í—ã–±–∏—Ä–∞–µ–º, –∫–∞–∫—É—é –≤–µ—Ç–≤—å –∑–∞–º–µ–Ω–∏—Ç—å –∏–∑ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è\n",
    "        target_branch = random.choice(['conv_branch', 'rnn_branch'])\n",
    "        child = copy.deepcopy(parent_a)\n",
    "        \n",
    "        # –ù–∞—Ö–æ–¥–∏–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Å–ª–æ–∏ –∏–∑ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è\n",
    "        if target_branch == 'conv_branch':\n",
    "            suitable_layers = [l for l in parent_b if l.get('layer') == 'Conv1D']\n",
    "        else:  # rnn_branch\n",
    "            suitable_layers = [l for l in parent_b if l.get('layer') in ('GRU', 'RNN')]\n",
    "        \n",
    "        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Å–ª–æ–∏, –∑–∞–º–µ–Ω—è–µ–º –≤–µ—Ç–≤—å\n",
    "        if suitable_layers:\n",
    "            child['parallel'][target_branch] = copy.deepcopy(suitable_layers)\n",
    "            \n",
    "            # –î–ª—è RNN-–≤–µ—Ç–≤–∏ –Ω—É–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å return_sequences\n",
    "            if target_branch == 'rnn_branch':\n",
    "                for i, layer in enumerate(child['parallel'][target_branch]):\n",
    "                    layer['return_sequences'] = (i < len(child['parallel'][target_branch]) - 1)\n",
    "        \n",
    "        return child\n",
    "        \n",
    "    elif isinstance(parent_b, dict) and isinstance(parent_b.get('parallel'), dict) and isinstance(parent_a, list):\n",
    "        # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É —Å–ª—É—á–∞—é, –Ω–æ —Ä–æ–¥–∏—Ç–µ–ª–∏ –º–µ–Ω—è—é—Ç—Å—è –º–µ—Å—Ç–∞–º–∏\n",
    "        return crossover_dag(parent_b, parent_a)\n",
    "        \n",
    "    # –ï—Å–ª–∏ –æ–±–∞ —Ä–æ–¥–∏—Ç–µ–ª—è - –ª–∏–Ω–µ–π–Ω—ã–µ —Å–ø–∏—Å–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ\n",
    "    else:\n",
    "        return crossover(parent_a, parent_b)\n",
    "\n",
    "def mutate_dag(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, branch_mut=0.1):\n",
    "    \"\"\"\n",
    "    –ú—É—Ç–∞—Ü–∏—è DAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –º—É—Ç–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤–µ—Ç–≤–µ–π.\n",
    "    \"\"\"\n",
    "    # –ï—Å–ª–∏ —ç—Ç–æ DAG —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –≤–µ—Ç–≤—è–º–∏\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        result = copy.deepcopy(arch)\n",
    "        \n",
    "        # –ú—É—Ç–∞—Ü–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ –≤–µ—Ç–≤–µ–π: –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞, –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ—Ç–≤–∏ –∏–ª–∏ —Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏—è\n",
    "        if random.random() < branch_mut:\n",
    "            branch_to_mutate = random.choice(['conv_branch', 'rnn_branch'])\n",
    "            mutation_type = random.choice(['replace', 'restructure'])\n",
    "            \n",
    "            if mutation_type == 'replace':\n",
    "                # –ü–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ –≤–µ—Ç–≤–∏ –Ω–æ–≤–æ–π —Å–ª—É—á–∞–π–Ω–æ–π\n",
    "                if branch_to_mutate == 'conv_branch':\n",
    "                    depth = random.randint(1, 3)\n",
    "                    result['parallel'][branch_to_mutate] = [random_conv1d_block() for _ in range(depth)]\n",
    "                    result['parallel'][branch_to_mutate].append(global_pool_block())\n",
    "                else:  # rnn_branch\n",
    "                    depth = random.randint(1, 3)\n",
    "                    result['parallel'][branch_to_mutate] = []\n",
    "                    for i in range(depth):\n",
    "                        block = random_rnn_block(random.choice(['GRU', 'RNN']))\n",
    "                        block['return_sequences'] = (i < depth - 1)\n",
    "                        result['parallel'][branch_to_mutate].append(block)\n",
    "            \n",
    "            elif mutation_type == 'restructure':\n",
    "                # –†–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–æ—è\n",
    "                branch = result['parallel'][branch_to_mutate]\n",
    "                \n",
    "                if random.random() < 0.5 and len(branch) > 1:\n",
    "                    # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è (–Ω–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ Pool/Flatten –¥–ª—è conv_branch)\n",
    "                    if branch_to_mutate == 'conv_branch' and branch[-1]['layer'] in ('GlobalAvgPool1D', 'Flatten'):\n",
    "                        pos = random.randint(0, len(branch) - 2)\n",
    "                    else:\n",
    "                        pos = random.randint(0, len(branch) - 1)\n",
    "                    branch.pop(pos)\n",
    "                    \n",
    "                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ return_sequences –¥–ª—è RNN-–≤–µ—Ç–≤–∏\n",
    "                    if branch_to_mutate == 'rnn_branch':\n",
    "                        for i, layer in enumerate(branch):\n",
    "                            if layer['layer'] in ('GRU', 'RNN'):\n",
    "                                layer['return_sequences'] = (i < len(branch) - 1)\n",
    "                else:\n",
    "                    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ—è\n",
    "                    if branch_to_mutate == 'conv_branch':\n",
    "                        # –î–ª—è —Å–≤—ë—Ä—Ç–æ—á–Ω–æ–π –≤–µ—Ç–≤–∏ –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–¥ –ø–æ—Å–ª–µ–¥–Ω–∏–º —Å–ª–æ–µ–º (–µ—Å–ª–∏ —ç—Ç–æ GlobalAvgPool)\n",
    "                        if branch[-1]['layer'] in ('GlobalAvgPool1D', 'Flatten'):\n",
    "                            branch.insert(len(branch) - 1, random_conv1d_block())\n",
    "                        else:\n",
    "                            branch.append(random_conv1d_block())\n",
    "                    else:  # rnn_branch\n",
    "                        # –î–ª—è RNN –≤–µ—Ç–≤–∏ –æ–±–Ω–æ–≤–ª—è–µ–º return_sequences\n",
    "                        new_layer = random_rnn_block(random.choice(['GRU', 'RNN']))\n",
    "                        pos = random.randint(0, len(branch))\n",
    "                        branch.insert(pos, new_layer)\n",
    "                        \n",
    "                        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥–∏ return_sequences\n",
    "                        for i, layer in enumerate(branch):\n",
    "                            if layer['layer'] in ('GRU', 'RNN'):\n",
    "                                layer['return_sequences'] = (i < len(branch) - 1)\n",
    "        \n",
    "        # –ú—É—Ç–∞—Ü–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–µ–≤ –≤ –∫–∞–∂–¥–æ–π –≤–µ—Ç–≤–∏\n",
    "        for branch_name, branch in result['parallel'].items():\n",
    "            for i, layer in enumerate(branch):\n",
    "                r = random.random()\n",
    "                if r < base_mut:\n",
    "                    # –ü–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Å–ª–æ—è\n",
    "                    if branch_name == 'conv_branch' and layer['layer'] == 'Conv1D':\n",
    "                        branch[i] = random_conv1d_block()\n",
    "                    elif branch_name == 'rnn_branch' and layer['layer'] in ('GRU', 'RNN'):\n",
    "                        new_layer = random_rnn_block(random.choice(['GRU', 'RNN']))\n",
    "                        new_layer['return_sequences'] = layer['return_sequences']\n",
    "                        branch[i] = new_layer\n",
    "                elif r < base_mut + param_mut:\n",
    "                    # –ú—É—Ç–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "                    l = copy.deepcopy(layer)\n",
    "                    if 'units' in l:\n",
    "                        l['units'] = max(1, int(l['units'] * random.uniform(0.5, 1.5)))\n",
    "                    if 'filters' in l:\n",
    "                        l['filters'] = max(1, int(l['filters'] * random.uniform(0.5, 1.5)))\n",
    "                    if 'dropout' in l:\n",
    "                        l['dropout'] = min(0.5, max(0.0, l['dropout'] + random.uniform(-0.1, 0.1)))\n",
    "                    branch[i] = l\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # –î–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º—É—Ç–∞—Ü–∏—é\n",
    "    else:\n",
    "        return mutate(arch, base_mut, param_mut, struct_mut)\n",
    "        \n",
    "# –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –æ–±–æ–∏—Ö —Ç–∏–ø–æ–≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\n",
    "def universal_crossover(parent_a, parent_b):\n",
    "    \"\"\"–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–µ–µ —Ç–∏–ø –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\"\"\"\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω DAG\n",
    "    if (isinstance(parent_a, dict) and 'parallel' in parent_a) or \\\n",
    "       (isinstance(parent_b, dict) and 'parallel' in parent_b):\n",
    "        return crossover_dag(parent_a, parent_b)\n",
    "    else:\n",
    "        return crossover(parent_a, parent_b)\n",
    "\n",
    "def universal_mutate(arch, base_mut=0.1, param_mut=0.05, struct_mut=0.02, branch_mut=0.1):\n",
    "    \"\"\"–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º—É—Ç–∞—Ü–∏—è, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–∞—è —Ç–∏–ø –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\"\"\"\n",
    "    if isinstance(arch, dict) and 'parallel' in arch:\n",
    "        return mutate_dag(arch, base_mut, param_mut, struct_mut, branch_mut)\n",
    "    else:\n",
    "        return mutate(arch, base_mut, param_mut, struct_mut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb581920-ff17-484b-bebc-938212ab4c43",
   "metadata": {},
   "source": [
    "## –ì–ê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dbae65-1527-419b-b441-6636919ab9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def worker_evaluate(args):\n",
    "    \"\"\"\n",
    "    –†–∞–±–æ—á–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –º–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏.\n",
    "    args: –∫–æ—Ä—Ç–µ–∂ (arch, train_data, val_data, metric, epochs, verbose, worker_id)\n",
    "\n",
    "    –î–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ GPU –º–µ–∂–¥—É –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏.\n",
    "    \"\"\"\n",
    "    arch, train_data, val_data, metric, epochs, verbose, worker_id = args\n",
    "    \n",
    "    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º GPU-–ø–∞–º—è—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # –ó–∞–¥–∞—ë–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–º –ø–∞–º—è—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞\n",
    "            tf.config.set_visible_devices([], 'GPU')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    \n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ—Ü–µ–Ω–∫–∏ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–¥–∞\n",
    "    X_train, y_train = train_data\n",
    "    X_val, y_val = val_data\n",
    "    \n",
    "    # –ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –±–æ–ª—å—à–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏, —Å—Ç–æ–∏—Ç –¥–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫\n",
    "    try:\n",
    "        model = build_model_from_architecture(arch, X_train.shape[1:])\n",
    "        model.compile(optimizer='adam', loss=metric, metrics=[metric])\n",
    "        \n",
    "        # –ö–æ–ª–±—ç–∫ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ —Å–ª–∞–±—ã–µ –º–æ–¥–µ–ª–∏\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=f'val_{metric}', \n",
    "            patience=2,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        val_res = history.history['val_' + metric][-1]\n",
    "        # –û—á–∏—â–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –ø–∞–º—è—Ç–∏\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        return -val_res\n",
    "    except Exception as e:\n",
    "        print(f\"Error in worker {worker_id}: {e}\")\n",
    "        return float('-inf')  # –ù–∞–∏—Ö—É–¥—à–∏–π —Ñ–∏—Ç–Ω–µ—Å –¥–ª—è –æ—à–∏–±–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "\n",
    "def parallel_evaluate_fitness(population, train_data, val_data, metric='mse', epochs=5, verbose=0, n_jobs=None):\n",
    "    \"\"\"\n",
    "    –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ñ–∏—Ç–Ω–µ—Å –≤—Å–µ–π –ø–æ–ø—É–ª—è—Ü–∏–∏.\n",
    "    n_jobs: —á–∏—Å–ª–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, None = –ø–æ —á–∏—Å–ª—É —è–¥–µ—Ä.\n",
    "    \"\"\"\n",
    "    n_jobs = n_jobs or os.cpu_count()\n",
    "    \n",
    "    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏\n",
    "    args_list = [(arch, train_data, val_data, metric, epochs, verbose, i) \n",
    "                for i, arch in enumerate(population)]\n",
    "    \n",
    "    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—É–ª –ø—Ä–æ—Ü–µ—Å—Å–æ–≤\n",
    "    with Pool(processes=n_jobs) as pool:\n",
    "        fitnesses = pool.map(worker_evaluate, args_list)\n",
    "    \n",
    "    return fitnesses\n",
    "\n",
    "# –ò–∑–º–µ–Ω–µ–Ω–Ω—ã–π –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏\n",
    "def run_parallel_ga(\n",
    "    train_data, val_data,\n",
    "    pop_size=20,\n",
    "    generations=10,\n",
    "    max_params=None,\n",
    "    elitism=2,\n",
    "    metric='mse',\n",
    "    epochs=5,\n",
    "    n_jobs=None\n",
    "):\n",
    "    \"\"\"\n",
    "    –í–µ—Ä—Å–∏—è GA —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–æ–π —Ñ–∏—Ç–Ω–µ—Å–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏.\n",
    "    \"\"\"\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    population = generate_population(pop_size=pop_size, max_params=max_params)\n",
    "    fitnesses = parallel_evaluate_fitness(\n",
    "        population, train_data, val_data, metric, epochs, verbose=0, n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    best_ever = (population[0], float('-inf'))  # (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, —Ñ–∏—Ç–Ω–µ—Å)\n",
    "    \n",
    "    for gen in range(generations):\n",
    "        print(f\"Gen {gen+1}/{generations}\")\n",
    "        \n",
    "        # –û–±–Ω–æ–≤–ª—è–µ–º –ª—É—á—à—É—é –æ—Å–æ–±—å –∑–∞ –≤—Å–µ –ø–æ–∫–æ–ª–µ–Ω–∏—è\n",
    "        gen_best_idx = max(range(len(fitnesses)), key=lambda i: fitnesses[i])\n",
    "        if fitnesses[gen_best_idx] > best_ever[1]:\n",
    "            best_ever = (population[gen_best_idx], fitnesses[gen_best_idx])\n",
    "            \n",
    "        print(f\"  Best fitness: {fitnesses[gen_best_idx]:.6f}, All-time best: {best_ever[1]:.6f}\")\n",
    "        \n",
    "        # --- –≠–ª–∏—Ç–∏–∑–º: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø-N –ª—É—á—à–∏—Ö ---\n",
    "        elite_idx = sorted(range(len(population)), key=lambda i: fitnesses[i], reverse=True)[:elitism]\n",
    "        new_population = [population[i] for i in elite_idx]\n",
    "\n",
    "        # --- –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –Ω–æ–≤—ã—Ö –æ—Å–æ–±–µ–π ---\n",
    "        while len(new_population) < pop_size:\n",
    "            p1, p2 = select_parents(population, fitnesses)\n",
    "            child = crossover(p1, p2)\n",
    "            child = mutate(child)\n",
    "            new_population.append(child)\n",
    "\n",
    "        population = new_population\n",
    "        fitnesses = parallel_evaluate_fitness(\n",
    "            population, train_data, val_data, metric, epochs, verbose=0, n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏–∑ –≤—Å–µ—Ö –ø–æ–∫–æ–ª–µ–Ω–∏–π\n",
    "    return best_ever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc9d5c-5e82-4ade-acea-5897b044dcb7",
   "metadata": {},
   "source": [
    "## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4fa03a-4f06-4b96-8c95-5a156b450c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "class HPOptimizer:\n",
    "    \"\"\"–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\"\"\"\n",
    "    \n",
    "    def __init__(self, train_data, val_data, test_data=None):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "        \n",
    "    def optimize_hyperparameters(self, architecture, trials=10, epochs=30, patience=5):\n",
    "        \"\"\"\n",
    "        –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∏–ª—É—á—à—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –º–æ–¥–µ–ª—å.\n",
    "        \"\"\"\n",
    "        best_hp = None\n",
    "        best_val_loss = float('inf')\n",
    "        best_model = None\n",
    "        \n",
    "        X_train, y_train = self.train_data\n",
    "        X_val, y_val = self.val_data\n",
    "        \n",
    "        for trial in range(trials):\n",
    "            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "            hp = self._sample_hyperparameters()\n",
    "            print(f\"–ü—Ä–æ–±—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {hp}\")\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "            model = build_model_from_architecture(architecture, X_train.shape[1:])\n",
    "            \n",
    "            # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "            optimizer = self._get_optimizer(hp['optimizer_name'], hp['learning_rate'])\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=hp['loss'],\n",
    "                metrics=['mse', 'mae']\n",
    "            )\n",
    "            \n",
    "            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–ª–±—ç–∫–∏\n",
    "            callbacks = [\n",
    "                EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=patience,\n",
    "                    restore_best_weights=True\n",
    "                ),\n",
    "                ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.5,\n",
    "                    patience=patience // 2,\n",
    "                    min_lr=1e-6\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=epochs,\n",
    "                batch_size=hp['batch_size'],\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ\n",
    "            val_loss = min(history.history['val_loss'])\n",
    "            \n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_hp = hp\n",
    "                best_model = model\n",
    "            else:\n",
    "                # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å\n",
    "                del model\n",
    "                tf.keras.backend.clear_session()\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "        test_metrics = None\n",
    "        if self.test_data is not None and best_model is not None:\n",
    "            X_test, y_test = self.test_data\n",
    "            test_metrics = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "            print(f\"–¢–µ—Å—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: MSE={test_metrics[1]}, MAE={test_metrics[2]}\")\n",
    "        \n",
    "        return best_hp, best_model, best_val_loss, test_metrics\n",
    "    \n",
    "    def _sample_hyperparameters(self):\n",
    "        \"\"\"–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\"\"\"\n",
    "        return {\n",
    "            'batch_size': random.choice([16, 32, 64, 128]),\n",
    "            'learning_rate': 10 ** random.uniform(-4, -1),  # –æ—Ç 1e-4 –¥–æ 1e-1\n",
    "            'optimizer_name': random.choice(['adam', 'rmsprop', 'sgd']),\n",
    "            'loss': random.choice(['mse', 'mae', 'huber_loss']),\n",
    "        }\n",
    "    \n",
    "    def _get_optimizer(self, name, learning_rate):\n",
    "        \"\"\"–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–æ –∏–º–µ–Ω–∏ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
    "        if name == 'adam':\n",
    "            return Adam(learning_rate=learning_rate)\n",
    "        elif name == 'rmsprop':\n",
    "            return RMSprop(learning_rate=learning_rate)\n",
    "        elif name == 'sgd':\n",
    "            return SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "        else:\n",
    "            return Adam(learning_rate=learning_rate)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "\n",
    "\n",
    "class EnsembleBuilder:\n",
    "    \"\"\"–°—Ç—Ä–æ–∏—Ç –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π\"\"\"\n",
    "    \n",
    "    def __init__(self, train_data, val_data, test_data=None):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def build_ensemble(self, architectures, hp_optimizer=None, ensemble_size=5, \n",
    "                       diversity_weight=0.3, max_trials=10):\n",
    "        \"\"\"\n",
    "        –°–æ–∑–¥–∞–µ—Ç –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        architectures : list\n",
    "            –°–ø–∏—Å–æ–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã–±–∏—Ä–∞—é—Ç—Å—è –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è\n",
    "        hp_optimizer : HPOptimizer, optional\n",
    "            –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "        ensemble_size : int\n",
    "            –†–∞–∑–º–µ—Ä –∞–Ω—Å–∞–º–±–ª—è (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π)\n",
    "        diversity_weight : float\n",
    "            –í–µ—Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –ø—Ä–∏ –æ—Ç–±–æ—Ä–µ –º–æ–¥–µ–ª–µ–π (0-1)\n",
    "        max_trials : int\n",
    "            –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list of models\n",
    "            –°–ø–∏—Å–æ–∫ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è\n",
    "        \"\"\"\n",
    "        if hp_optimizer is None:\n",
    "            hp_optimizer = HPOptimizer(self.train_data, self.val_data, self.test_data)\n",
    "        \n",
    "        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\n",
    "        if len(architectures) < ensemble_size:\n",
    "            print(f\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ {len(architectures)} –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä \" \n",
    "                  f\"–¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è –∏–∑ {ensemble_size} –º–æ–¥–µ–ª–µ–π\")\n",
    "            ensemble_size = min(ensemble_size, len(architectures))\n",
    "            \n",
    "        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "        models = []\n",
    "        performances = []\n",
    "        \n",
    "        for i, arch in enumerate(architectures[:ensemble_size * 2]):  # –ë–µ—Ä–µ–º —Å –∑–∞–ø–∞—Å–æ–º\n",
    "            print(f\"\\n–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ {i+1}/{ensemble_size*2}\")\n",
    "            best_hp, model, val_loss, _ = hp_optimizer.optimize_hyperparameters(\n",
    "                arch, trials=max_trials, epochs=30, patience=5\n",
    "            )\n",
    "            \n",
    "            models.append(model)\n",
    "            performances.append(-val_loss)  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º, —Ç.–∫. –º–µ–Ω—å—à–µ –ª—É—á—à–µ\n",
    "            \n",
    "            # –ï—Å–ª–∏ —É –Ω–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–æ–¥–µ–ª–µ–π, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è\n",
    "            if len(models) >= ensemble_size * 2:\n",
    "                break\n",
    "                \n",
    "        # –û—Ç–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è, —É—á–∏—Ç—ã–≤–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ\n",
    "        selected_models = self._select_diverse_models(\n",
    "            models, performances, ensemble_size, diversity_weight\n",
    "        )\n",
    "        \n",
    "        return selected_models\n",
    "    \n",
    "    def _select_diverse_models(self, models, performances, ensemble_size, diversity_weight):\n",
    "        \"\"\"\n",
    "        –û—Ç–±–∏—Ä–∞–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π –Ω–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è,\n",
    "        —É—á–∏—Ç—ã–≤–∞—è –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Ç–∞–∫ –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.\n",
    "        \"\"\"\n",
    "        X_val, y_val = self.val_data\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ\n",
    "        predictions = [model.predict(X_val, verbose=0).flatten() for model in models]\n",
    "        \n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "        normalized_performances = np.array(performances)\n",
    "        normalized_performances = (normalized_performances - normalized_performances.min()) / \\\n",
    "                                 (normalized_performances.max() - normalized_performances.min() + 1e-10)\n",
    "        \n",
    "        selected_indices = []\n",
    "        remaining_indices = list(range(len(models)))\n",
    "        \n",
    "        # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å (–ª—É—á—à—É—é –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)\n",
    "        best_idx = np.argmax(normalized_performances)\n",
    "        selected_indices.append(best_idx)\n",
    "        remaining_indices.remove(best_idx)\n",
    "        \n",
    "        # –í—ã–±–∏—Ä–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏, —É—á–∏—Ç—ã–≤–∞—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ\n",
    "        for _ in range(ensemble_size - 1):\n",
    "            if not remaining_indices:\n",
    "                break\n",
    "                \n",
    "            best_score = -float('inf')\n",
    "            best_idx = -1\n",
    "            \n",
    "            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∞–Ω—Å–∞–º–±–ª—è\n",
    "            ensemble_pred = np.mean([predictions[i] for i in selected_indices], axis=0)\n",
    "            \n",
    "            for idx in remaining_indices:\n",
    "                # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "                performance_score = normalized_performances[idx]\n",
    "                \n",
    "                # –û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ç–µ–∫—É—â–∏–º –∞–Ω—Å–∞–º–±–ª–µ–º)\n",
    "                model_pred = predictions[idx]\n",
    "                correlation = np.corrcoef(ensemble_pred, model_pred)[0, 1]\n",
    "                diversity_score = 1.0 - abs(correlation)  # –í—ã—Å–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ = –≤—ã—Å–æ–∫–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ\n",
    "                \n",
    "                # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞\n",
    "                combined_score = (1 - diversity_weight) * performance_score + \\\n",
    "                                 diversity_weight * diversity_score\n",
    "                \n",
    "                if combined_score > best_score:\n",
    "                    best_score = combined_score\n",
    "                    best_idx = idx\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º –æ–±—â–∏–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–º\n",
    "            selected_indices.append(best_idx)\n",
    "            remaining_indices.remove(best_idx)\n",
    "        \n",
    "        return [models[i] for i in selected_indices]\n",
    "    \n",
    "    def evaluate_ensemble(self, ensemble_models, method='mean'):\n",
    "        \"\"\"\n",
    "        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–Ω—Å–∞–º–±–ª—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        ensemble_models : list\n",
    "            –°–ø–∏—Å–æ–∫ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "        method : str, optional\n",
    "            –ú–µ—Ç–æ–¥ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π ('mean', 'median', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        \"\"\"\n",
    "        if self.test_data is None:\n",
    "            print(\"–û—à–∏–±–∫–∞: —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã\")\n",
    "            return None\n",
    "            \n",
    "        X_test, y_test = self.test_data\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "        predictions = [model.predict(X_test, verbose=0).flatten() for model in ensemble_models]\n",
    "        \n",
    "        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "        if method == 'mean':\n",
    "            ensemble_pred = np.mean(predictions, axis=0)\n",
    "        elif method == 'median':\n",
    "            ensemble_pred = np.median(predictions, axis=0)\n",
    "        elif method == 'weighted':\n",
    "            # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "            X_val, y_val = self.val_data\n",
    "            val_errors = []\n",
    "            for model in ensemble_models:\n",
    "                val_pred = model.predict(X_val, verbose=0).flatten()\n",
    "                val_mse = np.mean((val_pred - y_val) ** 2)\n",
    "                val_errors.append(val_mse)\n",
    "            \n",
    "            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—à–∏–±–∫–∏ –≤ –≤–µ—Å–∞ (–º–µ–Ω—å—à–µ –æ—à–∏–±–∫–∞ = –±–æ–ª—å—à–µ –≤–µ—Å)\n",
    "            weights = 1.0 / (np.array(val_errors) + 1e-10)\n",
    "            weights /= weights.sum()\n",
    "            \n",
    "            # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ\n",
    "            ensemble_pred = np.sum([weights[i] * predictions[i] for i in range(len(predictions))], axis=0)\n",
    "        else:\n",
    "            raise ValueError(f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {method}\")\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "        mse = np.mean((ensemble_pred - y_test) ** 2)\n",
    "        mae = np.mean(np.abs(ensemble_pred - y_test))\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ R^2\n",
    "        ss_total = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "        ss_res = np.sum((y_test - ensemble_pred) ** 2)\n",
    "        r2 = 1 - (ss_res / (ss_total + 1e-10))\n",
    "        \n",
    "        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏\n",
    "        individual_mse = [np.mean((pred - y_test) ** 2) for pred in predictions]\n",
    "        best_individual_mse = min(individual_mse)\n",
    "        \n",
    "        metrics = {\n",
    "            'ensemble_mse': mse,\n",
    "            'ensemble_mae': mae,\n",
    "            'ensemble_rmse': rmse,\n",
    "            'ensemble_r2': r2,\n",
    "            'best_individual_mse': best_individual_mse,\n",
    "            'improvement_pct': ((best_individual_mse - mse) / best_individual_mse) * 100\n",
    "        }\n",
    "        \n",
    "        print(f\"–ú–µ—Ç—Ä–∏–∫–∏ –∞–Ω—Å–∞–º–±–ª—è (–º–µ—Ç–æ–¥: {method}):\")\n",
    "        print(f\"  MSE: {mse:.6f}\")\n",
    "        print(f\"  MAE: {mae:.6f}\")\n",
    "        print(f\"  RMSE: {rmse:.6f}\")\n",
    "        print(f\"  R¬≤: {r2:.6f}\")\n",
    "        print(f\"  –£–ª—É—á—à–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {metrics['improvement_pct']:.2f}%\")\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1643c4cb-a6a9-4b4a-9d5f-1a73dd240b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "\n",
    "class NeuralArchitectureSearch:\n",
    "    \"\"\"\n",
    "    –ö–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π\n",
    "    —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 train_data,\n",
    "                 val_data, \n",
    "                 test_data=None,\n",
    "                 population_size=20,\n",
    "                 generations=10,\n",
    "                 max_params=50000,\n",
    "                 elitism=2,\n",
    "                 crossover_rate=0.8,\n",
    "                 mutation_rate=0.2,\n",
    "                 metric='mse',\n",
    "                 weights=None,\n",
    "                 n_jobs=None,\n",
    "                 log_dir='nas_logs'):\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        train_data, val_data, test_data : tuple\n",
    "            –ö–æ—Ä—Ç–µ–∂–∏ (X, y) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "        population_size : int\n",
    "            –†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "        generations : int\n",
    "            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∫–æ–ª–µ–Ω–∏–π\n",
    "        max_params : int\n",
    "            –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–æ–¥–µ–ª–∏\n",
    "        elitism : int\n",
    "            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–∏—Ç–Ω—ã—Ö –æ—Å–æ–±–µ–π, –ø–µ—Ä–µ—Ö–æ–¥—è—â–∏—Ö –≤ —Å–ª–µ–¥—É—é—â–µ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ\n",
    "        crossover_rate : float\n",
    "            –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫—Ä–æ—Å—Å–æ–≤–µ—Ä–∞\n",
    "        mutation_rate : float\n",
    "            –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º—É—Ç–∞—Ü–∏–∏\n",
    "        metric : str\n",
    "            –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ ('mse', 'mae', –∏ —Ç.–¥.)\n",
    "        weights : dict\n",
    "            –í–µ—Å–∞ –¥–ª—è –º–Ω–æ–≥–æ—Ü–µ–ª–µ–≤–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ {'performance': 1.0, 'complexity': 0.2, 'size': 0.1}\n",
    "        n_jobs : int\n",
    "            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π\n",
    "        log_dir : str\n",
    "            –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π\n",
    "        \"\"\"\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "        \n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.max_params = max_params\n",
    "        self.elitism = elitism\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.metric = metric\n",
    "        \n",
    "        # –í–µ—Å–∞ –¥–ª—è –º–Ω–æ–≥–æ—Ü–µ–ª–µ–≤–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–æ–ª—å–∫–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)\n",
    "        self.weights = weights or {'performance': 1.0, 'complexity': 0.0, 'size': 0.0}\n",
    "        \n",
    "        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        self.log_dir = log_dir\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        \n",
    "        # –ò—Å—Ç–æ—Ä–∏—è –ø–æ–∏—Å–∫–∞\n",
    "        self.history = {\n",
    "            'best_fitness': [],\n",
    "            'mean_fitness': [],\n",
    "            'best_architectures': [],\n",
    "            'generation_stats': []\n",
    "        }\n",
    "        \n",
    "    def search(self, strategy=None, custom_strategies=None):\n",
    "        \"\"\"\n",
    "        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –ø–æ–∏—Å–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        strategy : str, optional\n",
    "            –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞ ('standard', 'accelerated', 'diverse')\n",
    "        custom_strategies : list, optional\n",
    "            –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞\n",
    "        \"\"\"\n",
    "        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏\n",
    "        if strategy == 'accelerated':\n",
    "            # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ —Å –º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —ç–ø–æ—Ö\n",
    "            epochs_per_generation = [1, 1, 1, 2, 3] + [5] * (self.generations - 5)\n",
    "            adaptive_pop_size = True\n",
    "        elif strategy == 'diverse':\n",
    "            # –ü–æ–∏—Å–∫ —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ\n",
    "            epochs_per_generation = [3] * self.generations\n",
    "            adaptive_pop_size = False\n",
    "            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –º—É—Ç–∞—Ü–∏—é –¥–ª—è –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è\n",
    "            self.mutation_rate *= 1.5\n",
    "        else:  # standard\n",
    "            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–∏—Å–∫\n",
    "            epochs_per_generation = [3] * self.generations\n",
    "            adaptive_pop_size = False\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º –æ—Ü–µ–Ω—â–∏–∫\n",
    "        evaluator = ModelEvaluator(\n",
    "            self.train_data, self.val_data, self.test_data,\n",
    "            main_metric=self.metric,\n",
    "            weights=self.weights\n",
    "        )\n",
    "        \n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ø—É–ª—è—Ü–∏—é\n",
    "        print(\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏...\")\n",
    "        strategies_list = custom_strategies or [\n",
    "            skeleton_conv_dense,\n",
    "            skeleton_rnn,\n",
    "            block_randomized,\n",
    "            dag_parallel,\n",
    "            micro_arch\n",
    "        ]\n",
    "        \n",
    "        population = generate_population(\n",
    "            pop_size=self.population_size,\n",
    "            strategies=strategies_list,\n",
    "            max_params=self.max_params\n",
    "        )\n",
    "        \n",
    "        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞\n",
    "        print(\"–ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã...\")\n",
    "        start_time = time.time()\n",
    "        best_architecture = None\n",
    "        best_fitness = float('-inf')\n",
    "        best_fitness_info = None\n",
    "        \n",
    "        for gen in range(self.generations):\n",
    "            gen_start_time = time.time()\n",
    "            epochs = epochs_per_generation[min(gen, len(epochs_per_generation) - 1)]\n",
    "            \n",
    "            print(f\"\\n–ü–æ–∫–æ–ª–µ–Ω–∏–µ {gen+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
