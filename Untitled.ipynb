{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9098c1-6d6e-4dbc-aa1a-9744f2255890",
   "metadata": {},
   "source": [
    "# –ù–∞—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –¥–∏–ø–ª–æ–º–∞ –Ω–∞ —Ç–µ–º—É \"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b129c-7acc-4f4a-a941-5bb075e3adf4",
   "metadata": {},
   "source": [
    "## –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed01eca-110e-41b3-9c0e-3b3641007bc3",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑ —Å–ª–æ–µ–≤:\n",
    "- –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π\n",
    "- –°–≤–µ—Ä—Ç–æ—á–Ω—ã–π\n",
    "- –†–µ–∫—É—Ä–µ–Ω—Ç–Ω—ã–π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8cd352-6d82-4fc4-9346-9bc25d7fa331",
   "metadata": {},
   "source": [
    "### –î–∞—Ç–∞—Å–µ—Ç—ã:\n",
    "- –£—Ä–∞–≤–Ω–µ–Ω–∏–µ –ú–∞–∫–∫–µ—è-–ì–ª–∞—Å—Å–∞ (–≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è)\n",
    "- Daily Sunspots Dataset (–≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è)\n",
    "- Forest Fires Data Set (–≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å—Ü–µ–Ω–∞—Ä–∏—è —Å –≤—ã—Å–æ–∫–æ–π –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å—é –∏ —à—É–º–æ–º)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc921f-b60f-4530-8a75-6578634e4d1a",
   "metadata": {},
   "source": [
    "\n",
    "–£—Ä–∞–≤–Ω–µ–Ω–∏–µ –ú–∞–∫–∫–µ—è-–ì–ª–∞—Å—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ö–∞–æ—Ç–∏—á–µ—Å–∫–∏—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤:\n",
    "\n",
    "$$\n",
    "\\frac{dx(t)}{dt} = \\frac{\\beta x(t - \\tau)}{1 + x(t - \\tau)^n} - \\gamma x(t)\n",
    "$$\n",
    "\n",
    "–≥–¥–µ:\n",
    "\n",
    "- $x(t)$ ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –≤ –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ $t$\n",
    "- $\\beta$, $\\gamma$, $n$, $\\tau$ ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—â–µ –≤—Å–µ–≥–æ –ø—Ä–∏–≤–æ–¥—è—Ç—Å—è –≤ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ:\n",
    "\n",
    "- $\\beta = 0.2$\n",
    "- $\\gamma = 0.1$\n",
    "- $n = 10$\n",
    "- $\\tau = 17$ (—Ç–∞–∫ –∂–µ –ø–æ–ø—Ä–æ–±—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ 30)\n",
    "\n",
    "–î–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è —É—Ä–∞–≤–Ω–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ –≠–π–ª–µ—Ä–∞:\n",
    "1) –ó–∞–¥–∞–µ–º —à–∞–≥ dt –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–¥–µ—Ä–∂–∫—É $\\tau$ –≤ –∫–æ–ª-–≤–æ —à–∞–≥–æ–≤: $tau\\_steps = \\tau/dt$\n",
    "2) –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ tau_steps –∑–Ω–∞—á–µ–Ω–∏–π x (–ª—É—á—à–µ –≤—Å–µ–≥–æ —Ä–∞–≤–Ω—ã–º–∏ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é —Å –Ω–µ–±–æ–ª—å—à–∏–º —à—É–º–æ–º).\n",
    "3) –î–ª—è –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞ ùë° ‚â• tau_steps –≤—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —Ñ–æ—Ä–º—É–ª–µ:\n",
    "$$\n",
    "x[t] = x[t-1] + dt \\left( \\frac{\\beta \\, x[t-tau\\_steps]}{1 + x[t-tau\\_steps]^n} - \\gamma \\, x[t-1] \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c02e400-06a8-4002-802d-dec69ce42958",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1060640044.py, line 26)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"units\": 64 # int\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "chromosome = [\n",
    "    {\n",
    "        \"layer\": \"Dense\",\n",
    "        \"units\": 256, # int\n",
    "        \"activation\": 'relu', # relu, sigmoid, softmax, tanh\n",
    "        \"kernel_regularizer\": 'L1', # L1, L2, L1L2\n",
    "        \"coef_regularizer\": [0.01, 0.02], # [L1, L2] - int, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    },\n",
    "#\"\"\"    \n",
    "#  –¢—É—Ç –ø–æ—è–≤–∏–ª–∞—Å—å –∏–¥–µ—è –æ–± –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã—Ö RNN, –Ω–æ —ç—Ç–æ –ø–æ—Ç–æ–º\n",
    "#  {\n",
    "#        \"layer\": \"RNN\",\n",
    "#        \"cells\":[ # SimpleRNNCell, LSTMCell, GRUCell\n",
    "#            { \n",
    "#                \"cell\": \"LSTMcell\"\n",
    "#            },\n",
    "#            {\n",
    "#                \"cell\": \"GRUcell\"\n",
    "#            }\n",
    "#        ]\n",
    "#    },\n",
    "#\"\"\"\n",
    "    {\n",
    "        \"layer\": \"RNN\",\n",
    "        # cell - SimpleRNNCell\n",
    "        \"units\": 64 # int\n",
    "        # return_sequences=True –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ–π ‚Äî —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π (LSTM, GRU, RNN, Conv1D) \n",
    "        # return_sequences=False –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ–π - Dense\n",
    "        # 'return_state' –¥—É–º–∞—é –ø—É—Å–∫–∞–π –æ—Å—Ç–∞–µ—Ç—Å—è False\n",
    "        # 'go_backwards': False # –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç False, —Ç. –∫. –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä bidirectional, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–±—ã—á–Ω–æ –ª—É—á—à–µ —á–µ–º go_backwards\n",
    "        'bidirectional': False # True / False\n",
    "        'stateful': True # True / False\n",
    "        # unroll: False\n",
    "        # time_major True, –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç —Ñ–æ—Ä–º–∞—Ç [time, batch, features].\n",
    "        # time_major False (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), —Ñ–æ—Ä–º–∞—Ç [batch, time, features].\n",
    " \n",
    "        \"activation\": 'relu', # relu, sigmoid, softmax, tanh\n",
    "        'dropout': 0 # float –î–æ–ª—è —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —é–Ω–∏—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (–º–µ–∂–¥—É 0 –∏ 1).\n",
    "        \"kernel_regularizer\": 'L1', # L1, L2, L1L2\n",
    "        \"coef_regularizer\": [0.01, 0.02], # [L1, L2] - int, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    },\n",
    "    # LSTM –ø–æ–∫–∞ –Ω–µ—Ç, –Ω–æ –µ—Å–ª–∏ —á—Ç–æ - –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å (—É–∂ —Ç—è–∂–µ–ª–∞—è –æ–Ω–∞ —Å–ª–∏—à–∫–æ–º)\n",
    "    {\n",
    "        \"layer\": \"GRU\",\n",
    "        \"units\": 64, # int\n",
    "        # return_sequences=True –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ–π ‚Äî —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π (LSTM, GRU, RNN, Conv1D) \n",
    "        # return_sequences=False –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ–π - Dense\n",
    "        # 'return_state' –¥—É–º–∞—é –ø—É—Å–∫–∞–π –æ—Å—Ç–∞–µ—Ç—Å—è False\n",
    "        # 'go_backwards': False # –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç False, —Ç. –∫. –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä bidirectional, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–±—ã—á–Ω–æ –ª—É—á—à–µ —á–µ–º go_backwards\n",
    "        'bidirectional': False # True / False\n",
    "        'stateful': True # True / False —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ (—Ç—Ä–µ–±—É–µ—Ç —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ batch_size).\n",
    "        # unroll: False\n",
    "        # time_major True, –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç —Ñ–æ—Ä–º–∞—Ç [time, batch, features].\n",
    "        # time_major False (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), —Ñ–æ—Ä–º–∞—Ç [batch, time, features].\n",
    "        \"activation\": 'relu', # relu, sigmoid, softmax, tanh\n",
    "        # recurrent_activation –ø—É—Å—Ç—å –æ—Å—Ç–∞–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é sigmoid\n",
    "        'dropout': 0 # float –î–æ–ª—è —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —é–Ω–∏—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (–º–µ–∂–¥—É 0 –∏ 1).\n",
    "        \"kernel_regularizer\": 'L1', # L1, L2, L1L2\n",
    "        \"coef_regularizer\": [0.01, 0.02], # [L1, L2] - int, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    },\n",
    "    {\n",
    "        \"layer\": \"Conv1D\",\n",
    "        'filters': 32, # int\n",
    "        'kernel_size': 3, # int\n",
    "        #'strides' : 1 –ü–æ–∫–∞ —á—Ç–æ –ø—É—Å–∫–∞–π –±—É–¥–µ—Ç 1, –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ –ø—Ä–∏–¥—É–º–∞—Ç—å —á—Ç–æ-—Ç–æ –ø–æ —Ç–∏–ø—É —Ç–æ–≥–æ, —á—Ç–æ —Å—Ç—Ä–∞–π–¥ –º–µ–Ω—å—à–µ –æ–∫–Ω–∞\n",
    "        # padding –ü—É—Å–∫–∞–π –ø–æ–∫–∞ –±—É–¥–µ—Ç –≤–µ–∑–¥–µ valid\n",
    "        \"activation\": 'relu', # relu, sigmoid, softmax, tanh\n",
    "        # dilation_rate –ü–æ–∫–∞ –±—É–¥–µ—Ç 1\n",
    "        \"kernel_regularizer\": 'L1', # L1, L2, L1L2\n",
    "        \"coef_regularizer\": [0.01, 0.02], # [L1, L2] - int, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "        # groups 1\n",
    "        # data_format 'channels_last' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é): [batch, steps, channels].\n",
    "        # data_format 'channels_first': [batch, channels, steps].\n",
    "    }\n",
    "    # Conv2D –ø–æ–∫–∞ –Ω–µ—Ç\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd291b60-082d-49ae-a5cd-2d9f6c8e6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_mackey_glass(beta=0.2, gamma=0.1, n=10, tau=17, dt=0.1, total_time=1000, burn_in_time=100):\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö–∞–æ—Ç–∏—á–µ—Å–∫–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –ø–æ —É—Ä–∞–≤–Ω–µ–Ω–∏—é –ú–∞–∫–∫–µ—è-–ì–ª–∞—Å—Å–∞\n",
    "    —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º burn-in –ø–µ—Ä–∏–æ–¥–∞ –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—á–∞–ª—å–Ω—ã—Ö —Å–∫–∞—á–∫–æ–≤.\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    - beta, gamma, n, tau: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "    - dt: —à–∞–≥ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "    - total_time: –≤—Ä–µ–º—è, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥—É—Ç —Å–æ–±—Ä–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ burn-in\n",
    "    - burn_in_time: –≤—Ä–µ–º—è –ø—Ä–æ–≥—Ä–µ–≤–∞, –¥–∞–Ω–Ω—ã–µ –∑–∞ –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è (–∏–Ω–∞—á–µ –Ω–∞—á–∞–ª–æ —Ä—è–¥–∞ –±—É–¥–µ—Ç —Å–ª–∏—à–∫–æ–º —Ö–∞–æ—Ç–∏—á–Ω—ã–º)\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    - t_axis: –≤—Ä–µ–º–µ–Ω–Ω–∞—è –æ—Å—å –¥–ª—è –∑–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    - x: –º–∞—Å—Å–∏–≤ –∑–Ω–∞—á–µ–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "    \"\"\"\n",
    "    total_steps = int((total_time + burn_in_time) / dt)\n",
    "    burn_in_steps = int(burn_in_time / dt)\n",
    "    tau_steps = int(tau / dt)\n",
    "    \n",
    "    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–≤–Ω–æ–≤–µ—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ x0\n",
    "    x0 = ((beta / gamma) - 1)**(1/n)  # –Ω—É–∂–Ω–æ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏, –±–ª–∏–∑–∫–∏–º–∏ –∫ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é\n",
    "    \n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞: –ø–µ—Ä–≤—ã–µ tau_steps –∑–∞–¥–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ–º x0 —Å –Ω–µ–±–æ–ª—å—à–∏–º —à—É–º–æ–º\n",
    "    x = np.zeros(total_steps)\n",
    "    x[:tau_steps] = x0 + 0.01 * np.random.randn(tau_steps)\n",
    "    \n",
    "    # –°–∏–º—É–ª—è—Ü–∏—è —É—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–º –≠–π–ª–µ—Ä–∞\n",
    "    for t in range(tau_steps, total_steps):\n",
    "        dx = dt * (beta * x[t - tau_steps] / (1 + x[t - tau_steps]**n) - gamma * x[t - 1])\n",
    "        x[t] = x[t - 1] + dx\n",
    "\n",
    "    \n",
    "    # –û—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—Ä–µ–º—è –ø—Ä–æ–≥—Ä–µ–≤–∞\n",
    "    x = x[burn_in_steps:]\n",
    "    t_axis = np.linspace(0, total_time, len(x))\n",
    "    \n",
    "    return t_axis, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e2a068-2f60-463e-bc4b-5769e2ff659b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "t, x = generate_mackey_glass(\n",
    "    beta=0.2, \n",
    "    gamma=0.1, \n",
    "    n=10, \n",
    "    tau=17, \n",
    "    dt=0.1, \n",
    "    total_time=1000, \n",
    "    burn_in_time=100\n",
    ")\n",
    "\n",
    "# –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t, x, label=\"Mackey-Glass\")\n",
    "plt.xlabel(\"–í—Ä–µ–º—è\")\n",
    "plt.ylabel(\"x(t)\")\n",
    "plt.title(\"–•–∞–æ—Ç–∏—á–µ—Å–∫–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –ø–æ —É—Ä–∞–≤–Ω–µ–Ω–∏—é –ú–∞–∫–∫–µ—è-–ì–ª–∞—Å—Å–∞\\n(–ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ–≤–∞)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe63e43-ba2c-46e4-96a1-692f6b92bbc8",
   "metadata": {},
   "source": [
    "# Daily Sunspots Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d856c16-583f-4e51-b07e-2c34fdd1c16d",
   "metadata": {},
   "source": [
    "—Å—Å—ã–ª–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç: https://www.kaggle.com/datasets/patrickfleith/daily-sunspots-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6d9820-4003-429f-978f-470214811642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: –ö–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ + —Ä–∞–∑–≤–µ–¥—ã–≤–∞—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de9c952-4935-418b-9a7d-535e5c26774a",
   "metadata": {},
   "source": [
    "# Forest Fires Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687dde50-05e4-49f6-9a8a-f48f9da755f1",
   "metadata": {},
   "source": [
    "—Å—Å—ã–ª–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç: https://www.kaggle.com/datasets/elikplim/forest-fires-data-set/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431524e6-1e47-47fb-ad6e-53fac2ba5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: –ö–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ + —Ä–∞–∑–≤–µ–¥—ã–≤–∞—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b639ca57-0afb-489d-960c-df58f4f2bee2",
   "metadata": {},
   "source": [
    "# –ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5742cf-9011-4614-b5c0-5a9a820c0af1",
   "metadata": {},
   "source": [
    "## –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ —Ö—Ä–æ–º–æ—Å–æ–º—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03df72be-9659-4a25-9d0d-149941b197b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 14:39:36.477684: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746617976.608506    1881 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746617976.643370    1881 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746617976.928487    1881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746617976.928528    1881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746617976.928530    1881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746617976.928531    1881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-07 14:39:36.958725: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –º–æ–¥–µ–ª—å Keras\n",
    "def build_model(chromosome): # –í–∏–¥ —Ö—Ä–æ–º–æ—Å–æ–º—ã: [[—Ç–∏–ø_—Å–ª–æ—è, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã...], [—Ç–∏–ø_—Å–ª–æ—è, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã...]...]\n",
    "    model = Sequential()\n",
    "    i = 0\n",
    "    \n",
    "    for layer in chromosome:\n",
    "        # Dense [... 0, units, activation, ...]\n",
    "        if layer[0] == 0:  # Dense\n",
    "            units = layer[1]\n",
    "            activation = layer[2]\n",
    "            model.add(Dense(units, activation=activation))\n",
    "        # TODO: RNN, GRU, LSTM, Conv1D\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c549edf-4627-4cb0-b052-fbc2c86d299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: –†–∞—Å–ø–∏—Å–∞—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b449934f-560b-4d50-b20d-543a286770cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GRU, SimpleRNN, Flatten, GlobalAveragePooling1D, Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cacc0877-c6fd-4641-8fc5-fcc625ac0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_dense_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'dense'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'sigmoid', 'softmax', 'tanh'])\n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    \n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [ 0.0001, 0.001, 0.01, 0.1 ]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_RNN_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'RNN'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3, 0.4])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False]) if not layer['bidirectional'] else False\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "def random_GRU_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'GRU'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    \n",
    "    layer['activation'] = random.choice(['tanh', 'relu', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False]) if not layer['bidirectional'] else False\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_Conv1D_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'Conv1D'\n",
    "    layer['filters'] = random.choice([])\n",
    "    layer['kernel_size'] = random.choice([])\n",
    "    layer['activation'] = random.choice(['tanh', 'relu', 'sigmoid'])\n",
    "    \n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [ 0.0001, 0.001, 0.01, 0.1 ]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_Conv1D_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'Conv1D'\n",
    "    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "    layer['strides'] = random.choice([1, 2])\n",
    "    layer['padding'] = random.choice(['valid', 'same'])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid', None])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dilation_rate'] = random.choice([1, 2])\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc0d797-323e-4734-8aca-ce79f2b90926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_layer():\n",
    "    layer_type = random.choice([\n",
    "        'dense', 'conv1d', 'gru', 'rnn',\n",
    "        'flatten', 'global_avg_pooling1d'\n",
    "    ])\n",
    "        \n",
    "    if layer_type == 'dense':\n",
    "        return random_dense_layer()\n",
    "\n",
    "    elif layer_type == 'conv1d':\n",
    "        return random_Conv1D_layer()\n",
    "        \n",
    "    elif layer_type == 'gru':\n",
    "        return random_GRU_layer()\n",
    "\n",
    "    elif layer_type == 'rnn':\n",
    "        return random_RNN_layer()\n",
    "        \n",
    "    return {'layer':layer_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00bc4ea-f39a-4fa8-8812-daafd2472769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_population(pop_size, min_layers=3, max_layers=6):\n",
    "    population = []\n",
    "    \n",
    "    for _ in range(pop_size):\n",
    "        # –°–ª—É—á–∞–π–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤\n",
    "        num_layers = random.randint(min_layers, max_layers)\n",
    "        \n",
    "        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–µ–≤\n",
    "        genome = []\n",
    "        for _ in range(num_layers):\n",
    "            layer = create_random_layer()\n",
    "            \n",
    "            # –£—Å–ª–æ–≤–∏—è –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π\n",
    "            if layer['layer'] in ['flatten', 'global_avg_pooling1d']:\n",
    "                # –†–∞–∑–º–µ—â–∞–µ–º —ç—Ç–∏ —Å–ª–æ–∏ –≤ –∫–æ–Ω—Ü–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å —à–∞–Ω—Å–æ–º 0.7 \n",
    "                if random.random() < 0.7:\n",
    "                    genome.append(layer)\n",
    "                    break  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            genome.append(layer)\n",
    "        \n",
    "        population.append(genome)\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99624e-d77b-485b-94c4-c6afdc5533a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–ª–≥–æ—Ä–∏—Ç–º–∞\n",
    "POPULATION_SIZE = 20\n",
    "GENERATIONS = 10\n",
    "TOURNAMENT_SIZE = 3\n",
    "MUTATION_RATE = 0.2\n",
    "ELITE_SIZE = 2\n",
    "EPOCHS = 5\n",
    "    \n",
    "\n",
    "\n",
    "def generate_population(pop_size):\n",
    "    return [[create_random_layer() for _ in range(random.randint(2, 5))] \n",
    "            for _ in range(pop_size)]\n",
    "\n",
    "def build_model(genome, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    for layer_config in genome:\n",
    "        if layer_config['type'] == 'dense':\n",
    "            model.add(Dense(units=layer_config['units'], \n",
    "                          activation=layer_config['activation']))\n",
    "            \n",
    "        elif layer_config['type'] == 'conv1d':\n",
    "            model.add(Conv1D(filters=layer_config['filters'],\n",
    "                          kernel_size=layer_config['kernel_size'],\n",
    "                          activation=layer_config['activation']))\n",
    "            \n",
    "        elif layer_config['type'] == 'gru':\n",
    "            model.add(GRU(units=layer_config['units'],\n",
    "                        activation=layer_config['activation']))\n",
    "            \n",
    "        elif layer_config['type'] == 'rnn':\n",
    "            model.add(SimpleRNN(units=layer_config['units'],\n",
    "                              activation=layer_config['activation']))\n",
    "            \n",
    "        elif layer_config['type'] == 'flatten':\n",
    "            model.add(Flatten())\n",
    "            \n",
    "        elif layer_config['type'] == 'global_avg_pooling1d':\n",
    "            model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def evaluate(genome, X_train, y_train, X_val, y_val, input_shape):\n",
    "    try:\n",
    "        model = build_model(genome, input_shape)\n",
    "        history = model.fit(X_train, y_train,\n",
    "                          epochs=EPOCHS,\n",
    "                          validation_data=(X_val, y_val),\n",
    "                          verbose=0)\n",
    "        return history.history['val_loss'][-1]\n",
    "    except:\n",
    "        return float('inf')\n",
    "\n",
    "def mutate(genome):\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        if len(genome) > 1 and random.random() < 0.3:\n",
    "            del genome[random.randint(0, len(genome)-1)]\n",
    "            \n",
    "    if random.random() < MUTATION_RATE:\n",
    "        genome.insert(random.randint(0, len(genome)), create_random_layer())\n",
    "        \n",
    "    for layer in genome:\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            if layer['type'] in ['dense', 'gru', 'rnn']:\n",
    "                layer['units'] = random.choice([32, 64, 128, 256])\n",
    "            elif layer['type'] == 'conv1d':\n",
    "                layer['filters'] = random.choice([32, 64, 128])\n",
    "                layer['kernel_size'] = random.choice([3, 5, 7])\n",
    "                \n",
    "    return genome\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    min_length = min(len(parent1), len(parent2))\n",
    "    crossover_point = random.randint(1, min_length-1)\n",
    "    return parent1[:crossover_point] + parent2[crossover_point:]\n",
    "\n",
    "def select_parent(population, fitness):\n",
    "    tournament = random.sample(list(zip(population, fitness)), TOURNAMENT_SIZE)\n",
    "    tournament.sort(key=lambda x: x[1])\n",
    "    return tournament[0][0]\n",
    "\n",
    "def genetic_algorithm(X_train, y_train, X_val, y_val, input_shape):\n",
    "    population = generate_population(POPULATION_SIZE)\n",
    "    \n",
    "    for generation in range(GENERATIONS):\n",
    "        fitness = [evaluate(genome, X_train, y_train, X_val, y_val, input_shape)\n",
    "                  for genome in population]\n",
    "        \n",
    "        sorted_pop = [x for _, x in sorted(zip(fitness, population), \n",
    "                     key=lambda x: x[0])]\n",
    "        \n",
    "        new_population = sorted_pop[:ELITE_SIZE]\n",
    "        \n",
    "        while len(new_population) < POPULATION_SIZE:\n",
    "            parent1 = select_parent(population, fitness)\n",
    "            parent2 = select_parent(population, fitness)\n",
    "            child = crossover(parent1, parent2)\n",
    "            child = mutate(child)\n",
    "            new_population.append(child)\n",
    "            \n",
    "        population = new_population\n",
    "        print(f'Generation {generation+1}, Best Loss: {min(fitness):.4f}')\n",
    "    \n",
    "    best_idx = np.argmin(fitness)\n",
    "    return population[best_idx]\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "if __name__ == \"__main__\":\n",
    "    # –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
    "    # X_train, y_train, X_val, y_val, input_shape = ...\n",
    "    \n",
    "    # best_architecture = genetic_algorithm(X_train, y_train, X_val, y_val, input_shape)\n",
    "    # print(\"Best Architecture:\", best_architecture)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d693b-c534-4d55-9068-57437a8c4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GRU, SimpleRNN, Flatten, GlobalAveragePooling1D, Input\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö —Å–ª–æ–µ–≤\n",
    "def random_dense_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'dense'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    \n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_RNN_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'RNN'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_GRU_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'GRU'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['tanh', 'relu', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_Conv1D_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'Conv1D'\n",
    "    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "    layer['strides'] = random.choice([1, 2])\n",
    "    layer['padding'] = random.choice(['valid', 'same'])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid', 'elu'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dilation_rate'] = random.choice([1, 2])\n",
    "    layer['max_pooling'] = random.choice([None, 2, 3])\n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def create_random_layer(prev_layer=None):\n",
    "    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ª–æ–µ–≤\n",
    "    if prev_layer is None or prev_layer.get('layer') not in ['RNN', 'GRU'] or not prev_layer.get('return_sequences', False):\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    else:\n",
    "        # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–ª–æ–π - —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å return_sequences=True\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    \n",
    "    # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ flatten/pooling\n",
    "    if prev_layer and prev_layer.get('layer') in ['flatten', 'global_avg_pooling1d']:\n",
    "        layer_types = ['dense']\n",
    "        \n",
    "    layer_type = random.choice(layer_types)\n",
    "        \n",
    "    if layer_type == 'dense':\n",
    "        return random_dense_layer()\n",
    "    elif layer_type == 'conv1d':\n",
    "        return random_Conv1D_layer()\n",
    "    elif layer_type == 'gru':\n",
    "        return random_GRU_layer()\n",
    "    elif layer_type == 'rnn':\n",
    "        return random_RNN_layer()\n",
    "        \n",
    "    return {'layer': layer_type}\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "def generate_random_architecture(min_layers=2, max_layers=10):\n",
    "    num_layers = random.randint(min_layers, max_layers)\n",
    "    architecture = []\n",
    "    \n",
    "    # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π\n",
    "    prev_layer = None\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        new_layer = create_random_layer(prev_layer)\n",
    "        architecture.append(new_layer)\n",
    "        prev_layer = new_layer\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ —Å–ª–æ–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
    "        if i < num_layers - 1 and new_layer.get('layer') in ['Conv1D', 'RNN', 'GRU'] and \\\n",
    "           new_layer.get('return_sequences', True) and random.random() > 0.5:\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–π —É–ø–ª–æ—â–µ–Ω–∏—è –∏–ª–∏ –ø—É–ª–∏–Ω–≥–∞ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.5\n",
    "            flatten_type = random.choice(['flatten', 'global_avg_pooling1d'])\n",
    "            architecture.append({'layer': flatten_type})\n",
    "            prev_layer = {'layer': flatten_type}\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    architecture.append({\n",
    "        'layer': 'dense',\n",
    "        'units': 1,\n",
    "        'activation': 'linear'\n",
    "    })\n",
    "    \n",
    "    return architecture\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ –º–æ–¥–µ–ª—å Keras\n",
    "def architecture_to_model(architecture, input_shape):\n",
    "    model = Sequential()\n",
    "    first_layer = True\n",
    "    \n",
    "    for layer in architecture:\n",
    "        layer_type = layer['layer']\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º Input shape –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è\n",
    "        if first_layer:\n",
    "            if layer_type == 'dense':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D(input_shape=input_shape))\n",
    "                \n",
    "            first_layer = False\n",
    "            \n",
    "        else:\n",
    "            # –°–ª–æ–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ\n",
    "            if layer_type == 'dense':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten())\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "def evaluate_architecture(architecture, X_train, y_train, X_val, y_val, input_shape, epochs=50, batch_size=32):\n",
    "    try:\n",
    "        model = architecture_to_model(architecture, input_shape)\n",
    "        \n",
    "        # –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "        optimizer_choice = random.choice(['adam', 'rmsprop', 'sgd'])\n",
    "        learning_rate = random.choice([0.001, 0.01, 0.0001])\n",
    "        \n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_choice == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=learning_rate)\n",
    "        else:\n",
    "            optimizer = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        # Early stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        val_loss = min(history.history['val_loss'])  # –ë–µ—Ä–µ–º –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º —à—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏\n",
    "        num_params = model.count_params()\n",
    "        complexity_penalty = np.log(num_params) / 10.0  # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å\n",
    "        \n",
    "        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_score = val_loss + complexity_penalty\n",
    "        \n",
    "        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏\n",
    "        tf.keras.backend.clear_session()\n",
    "        del model\n",
    "        \n",
    "        return fitness_score, val_loss, num_params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {e}\")\n",
    "        return float('inf'), float('inf'), 0\n",
    "\n",
    "# –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º\n",
    "class GeneticNNOptimizer:\n",
    "    def __init__(self, input_shape, X_train, y_train, X_val, y_val, \n",
    "                 population_size=20, num_generations=10, \n",
    "                 mutation_rate=0.2, crossover_rate=0.7):\n",
    "        self.input_shape = input_shape\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.population_size = population_size\n",
    "        self.num_generations = num_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.best_architecture = None\n",
    "        self.best_fitness = float('inf')\n",
    "        self.history = []\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            architecture = generate_random_architecture()\n",
    "            population.append(architecture)\n",
    "        return population\n",
    "    \n",
    "    def evaluate_population(self, population):\n",
    "        fitness_scores = []\n",
    "        for architecture in population:\n",
    "            fitness, val_loss, num_params = evaluate_architecture(\n",
    "                architecture, \n",
    "                self.X_train, self.y_train, \n",
    "                self.X_val, self.y_val, \n",
    "                self.input_shape\n",
    "            )\n",
    "            fitness_scores.append((fitness, architecture, val_loss, num_params))\n",
    "        \n",
    "        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏—Å–ø–æ—Å–æ–±–ª–µ–Ω–Ω–æ—Å—Ç–∏ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_scores.sort(key=lambda x: x[0])\n",
    "        return fitness_scores\n",
    "    \n",
    "    def selection(self, fitness_scores):\n",
    "        # –û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –æ—Å–æ–±–µ–π (—ç–ª–∏—Ç–∏–∑–º) + —Ç—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä\n",
    "        elite_count = max(1, int(self.population_size * 0.1))  # 10% —ç–ª–∏—Ç–∏–∑–º–∞\n",
    "        selected = [score[1] for score in fitness_scores[:elite_count]]\n",
    "        \n",
    "        # –¢—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø–æ–∑–∏—Ü–∏–π\n",
    "        while len(selected) < self.population_size:\n",
    "            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ 3 –æ—Å–æ–±–∏ –¥–ª—è —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "            tournament = random.sample(fitness_scores, k=3)\n",
    "            tournament.sort(key=lambda x: x[0])\n",
    "            selected.append(tournament[0][1])  # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –∏–∑ —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def crossover(self, parent1, parent2):\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1.copy(), parent2.copy()\n",
    "        \n",
    "        # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π (–≤—ã—Ö–æ–¥–Ω–æ–π) –ø–µ—Ä–µ–¥ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ–º\n",
    "        p1 = parent1[:-1].copy()\n",
    "        p2 = parent2[:-1].copy()\n",
    "        \n",
    "        # –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ\n",
    "        if len(p1) > 1 and len(p2) > 1:\n",
    "            crossover_point1 = random.randint(1, len(p1) - 1)\n",
    "            crossover_point2 = random.randint(1, len(p2) - 1)\n",
    "            \n",
    "            child1 = p1[:crossover_point1] + p2[crossover_point2:]\n",
    "            child2 = p2[:crossover_point2] + p1[crossover_point1:]\n",
    "        else:\n",
    "            child1, child2 = p1.copy(), p2.copy()\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        output_layer = {\n",
    "            'layer': 'dense',\n",
    "            'units': 1,\n",
    "            'activation': 'linear'\n",
    "        }\n",
    "        \n",
    "        child1.append(output_layer)\n",
    "        child2.append(output_layer)\n",
    "        \n",
    "        return child1, child2\n",
    "    \n",
    "    def mutate(self, architecture):\n",
    "        if random.random() > self.mutation_rate:\n",
    "            return architecture\n",
    "        \n",
    "        # –ö–ª–æ–Ω–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –±–µ–∑ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "        arch_copy = architecture[:-1].copy()\n",
    "        output_layer = architecture[-1].copy()\n",
    "        \n",
    "        mutation_type = random.choice(['add', 'remove', 'modify'])\n",
    "        \n",
    "        if mutation_type == 'add' and len(arch_copy) < 10:\n",
    "            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            insert_position = random.randint(0, len(arch_copy))\n",
    "            if insert_position == 0:\n",
    "                new_layer = create_random_layer()\n",
    "            else:\n",
    "                new_layer = create_random_layer(arch_copy[insert_position-1])\n",
    "            arch_copy.insert(insert_position, new_layer)\n",
    "            \n",
    "        elif mutation_type == 'remove' and len(arch_copy) > 1:\n",
    "            # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            remove_position = random.randint(0, len(arch_copy) - 1)\n",
    "            arch_copy.pop(remove_position)\n",
    "            \n",
    "        elif mutation_type == 'modify' and len(arch_copy) > 0:\n",
    "            # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            modify_position = random.randint(0, len(arch_copy) - 1)\n",
    "            layer = arch_copy[modify_position]\n",
    "            \n",
    "            if layer['layer'] == 'dense':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Dense —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "                \n",
    "            elif layer['layer'] == 'Conv1D':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Conv1D —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "                \n",
    "            elif layer['layer'] in ['RNN', 'GRU']:\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–ª–æ–∏\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['return_sequences'] = random.choice([True, False])\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        arch_copy.append(output_layer)\n",
    "        return arch_copy\n",
    "    \n",
    "    def evolve(self):\n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "        population = self.initialize_population()\n",
    "        \n",
    "        for generation in range(self.num_generations):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # –û—Ü–µ–Ω–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "            fitness_scores = self.evaluate_population(population)\n",
    "            generation_best_fitness = fitness_scores[0][0]\n",
    "            generation_best_architecture = fitness_scores[0][1]\n",
    "            generation_best_val_loss = fitness_scores[0][2]\n",
    "            generation_best_params = fitness_scores[0][3]\n",
    "            \n",
    "            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "            if generation_best_fitness < self.best_fitness:\n",
    "                self.best_fitness = generation_best_fitness\n",
    "                self.best_architecture = generation_best_architecture\n",
    "            \n",
    "            # –ó–∞–ø–∏—Å—å –∏—Å—Ç–æ—Ä–∏–∏\n",
    "            self.history.append({\n",
    "                'generation': generation,\n",
    "                'best_fitness': generation_best_fitness,\n",
    "                'best_val_loss': generation_best_val_loss,\n",
    "                'best_params': generation_best_params\n",
    "            })\n",
    "            \n",
    "            # –í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n",
    "            end_time = time.time()\n",
    "            print(f\"–ü–æ–∫–æ–ª–µ–Ω–∏–µ {generation + 1}/{self.num_generations} - –õ—É—á—à–∞—è –æ—à–∏–±–∫–∞: {generation_best_val_loss:.6f}, \"\n",
    "                  f\"–§–∏—Ç–Ω–µ—Å: {generation_best_fitness:.6f}, –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {generation_best_params}, \"\n",
    "                  f\"–í—Ä–µ–º—è: {end_time - start_time:.2f} —Å–µ–∫.\")\n",
    "            \n",
    "            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ü–∏–∫–ª–∞\n",
    "            if generation == self.num_generations - 1:\n",
    "                break\n",
    "            \n",
    "            # –û—Ç–±–æ—Ä\n",
    "            selected = self.selection(fitness_scores)\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è\n",
    "            new_population = []\n",
    "            \n",
    "            # –≠–ª–∏—Ç–∏–∑–º - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –æ—Å–æ–±–∏\n",
    "            new_population.append(generation_best_architecture)\n",
    "            \n",
    "            # –°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –∏ –º—É—Ç–∞—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–π\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(selected, k=2)\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                \n",
    "                child1 = self.mutate(child1)\n",
    "                child2 = self.mutate(child2)\n",
    "                \n",
    "                new_population.append(child1)\n",
    "                if len(new_population) < self.population_size:\n",
    "                    new_population.append(child2)\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "        final_fitness_scores = self.evaluate_population(population)\n",
    "        final_best = final_fitness_scores[0]\n",
    "        \n",
    "        if final_best[0] < self.best_fitness:\n",
    "            self.best_fitness = final_best[0]\n",
    "            self.best_architecture = final_best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a783e02-cf82-44db-8dc6-b6613a6a3a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GRU, SimpleRNN, Flatten, GlobalAveragePooling1D, Input\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö —Å–ª–æ–µ–≤\n",
    "def random_dense_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'dense'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    \n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_RNN_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'RNN'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_GRU_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'GRU'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['tanh', 'relu', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_Conv1D_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'Conv1D'\n",
    "    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "    layer['strides'] = random.choice([1, 2])\n",
    "    layer['padding'] = random.choice(['valid', 'same'])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid', 'elu'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dilation_rate'] = random.choice([1, 2])\n",
    "    layer['max_pooling'] = random.choice([None, 2, 3])\n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def create_random_layer(prev_layer=None):\n",
    "    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ª–æ–µ–≤\n",
    "    if prev_layer is None or prev_layer.get('layer') not in ['RNN', 'GRU'] or not prev_layer.get('return_sequences', False):\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    else:\n",
    "        # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–ª–æ–π - —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å return_sequences=True\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    \n",
    "    # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ flatten/pooling\n",
    "    if prev_layer and prev_layer.get('layer') in ['flatten', 'global_avg_pooling1d']:\n",
    "        layer_types = ['dense']\n",
    "        \n",
    "    layer_type = random.choice(layer_types)\n",
    "        \n",
    "    if layer_type == 'dense':\n",
    "        return random_dense_layer()\n",
    "    elif layer_type == 'conv1d':\n",
    "        return random_Conv1D_layer()\n",
    "    elif layer_type == 'gru':\n",
    "        return random_GRU_layer()\n",
    "    elif layer_type == 'rnn':\n",
    "        return random_RNN_layer()\n",
    "        \n",
    "    return {'layer': layer_type}\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "def generate_random_architecture(min_layers=2, max_layers=10):\n",
    "    num_layers = random.randint(min_layers, max_layers)\n",
    "    architecture = []\n",
    "    \n",
    "    # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π\n",
    "    prev_layer = None\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        new_layer = create_random_layer(prev_layer)\n",
    "        architecture.append(new_layer)\n",
    "        prev_layer = new_layer\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ —Å–ª–æ–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
    "        if i < num_layers - 1 and new_layer.get('layer') in ['Conv1D', 'RNN', 'GRU'] and \\\n",
    "           new_layer.get('return_sequences', True) and random.random() > 0.5:\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–π —É–ø–ª–æ—â–µ–Ω–∏—è –∏–ª–∏ –ø—É–ª–∏–Ω–≥–∞ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.5\n",
    "            flatten_type = random.choice(['flatten', 'global_avg_pooling1d'])\n",
    "            architecture.append({'layer': flatten_type})\n",
    "            prev_layer = {'layer': flatten_type}\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    architecture.append({\n",
    "        'layer': 'dense',\n",
    "        'units': 1,\n",
    "        'activation': 'linear'\n",
    "    })\n",
    "    \n",
    "    return architecture\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ –º–æ–¥–µ–ª—å Keras\n",
    "def architecture_to_model(architecture, input_shape):\n",
    "    model = Sequential()\n",
    "    first_layer = True\n",
    "    \n",
    "    for layer in architecture:\n",
    "        layer_type = layer['layer']\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º Input shape –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è\n",
    "        if first_layer:\n",
    "            if layer_type == 'dense':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D(input_shape=input_shape))\n",
    "                \n",
    "            first_layer = False\n",
    "            \n",
    "        else:\n",
    "            # –°–ª–æ–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ\n",
    "            if layer_type == 'dense':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten())\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "def evaluate_architecture(architecture, X_train, y_train, X_val, y_val, input_shape, epochs=50, batch_size=32):\n",
    "    try:\n",
    "        model = architecture_to_model(architecture, input_shape)\n",
    "        \n",
    "        # –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "        optimizer_choice = random.choice(['adam', 'rmsprop', 'sgd'])\n",
    "        learning_rate = random.choice([0.001, 0.01, 0.0001])\n",
    "        \n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_choice == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=learning_rate)\n",
    "        else:\n",
    "            optimizer = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        # Early stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        val_loss = min(history.history['val_loss'])  # –ë–µ—Ä–µ–º –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º —à—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏\n",
    "        num_params = model.count_params()\n",
    "        complexity_penalty = np.log(num_params) / 10.0  # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å\n",
    "        \n",
    "        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_score = val_loss + complexity_penalty\n",
    "        \n",
    "        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏\n",
    "        tf.keras.backend.clear_session()\n",
    "        del model\n",
    "        \n",
    "        return fitness_score, val_loss, num_params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {e}\")\n",
    "        return float('inf'), float('inf'), 0\n",
    "\n",
    "# –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º\n",
    "class GeneticNNOptimizer:\n",
    "    def __init__(self, input_shape, X_train, y_train, X_val, y_val, \n",
    "                 population_size=20, num_generations=10, \n",
    "                 mutation_rate=0.2, crossover_rate=0.7):\n",
    "        self.input_shape = input_shape\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.population_size = population_size\n",
    "        self.num_generations = num_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.best_architecture = None\n",
    "        self.best_fitness = float('inf')\n",
    "        self.history = []\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            architecture = generate_random_architecture()\n",
    "            population.append(architecture)\n",
    "        return population\n",
    "    \n",
    "    def evaluate_population(self, population):\n",
    "        fitness_scores = []\n",
    "        for architecture in population:\n",
    "            fitness, val_loss, num_params = evaluate_architecture(\n",
    "                architecture, \n",
    "                self.X_train, self.y_train, \n",
    "                self.X_val, self.y_val, \n",
    "                self.input_shape\n",
    "            )\n",
    "            fitness_scores.append((fitness, architecture, val_loss, num_params))\n",
    "        \n",
    "        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏—Å–ø–æ—Å–æ–±–ª–µ–Ω–Ω–æ—Å—Ç–∏ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_scores.sort(key=lambda x: x[0])\n",
    "        return fitness_scores\n",
    "    \n",
    "    def selection(self, fitness_scores):\n",
    "        # –û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –æ—Å–æ–±–µ–π (—ç–ª–∏—Ç–∏–∑–º) + —Ç—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä\n",
    "        elite_count = max(1, int(self.population_size * 0.1))  # 10% —ç–ª–∏—Ç–∏–∑–º–∞\n",
    "        selected = [score[1] for score in fitness_scores[:elite_count]]\n",
    "        \n",
    "        # –¢—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø–æ–∑–∏—Ü–∏–π\n",
    "        while len(selected) < self.population_size:\n",
    "            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ 3 –æ—Å–æ–±–∏ –¥–ª—è —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "            tournament = random.sample(fitness_scores, k=3)\n",
    "            tournament.sort(key=lambda x: x[0])\n",
    "            selected.append(tournament[0][1])  # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –∏–∑ —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def crossover(self, parent1, parent2):\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1.copy(), parent2.copy()\n",
    "        \n",
    "        # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π (–≤—ã—Ö–æ–¥–Ω–æ–π) –ø–µ—Ä–µ–¥ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ–º\n",
    "        p1 = parent1[:-1].copy()\n",
    "        p2 = parent2[:-1].copy()\n",
    "        \n",
    "        # –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ\n",
    "        if len(p1) > 1 and len(p2) > 1:\n",
    "            crossover_point1 = random.randint(1, len(p1) - 1)\n",
    "            crossover_point2 = random.randint(1, len(p2) - 1)\n",
    "            \n",
    "            child1 = p1[:crossover_point1] + p2[crossover_point2:]\n",
    "            child2 = p2[:crossover_point2] + p1[crossover_point1:]\n",
    "        else:\n",
    "            child1, child2 = p1.copy(), p2.copy()\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        output_layer = {\n",
    "            'layer': 'dense',\n",
    "            'units': 1,\n",
    "            'activation': 'linear'\n",
    "        }\n",
    "        \n",
    "        child1.append(output_layer)\n",
    "        child2.append(output_layer)\n",
    "        \n",
    "        return child1, child2\n",
    "    \n",
    "    def mutate(self, architecture):\n",
    "        if random.random() > self.mutation_rate:\n",
    "            return architecture\n",
    "        \n",
    "        # –ö–ª–æ–Ω–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –±–µ–∑ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "        arch_copy = architecture[:-1].copy()\n",
    "        output_layer = architecture[-1].copy()\n",
    "        \n",
    "        mutation_type = random.choice(['add', 'remove', 'modify'])\n",
    "        \n",
    "        if mutation_type == 'add' and len(arch_copy) < 10:\n",
    "            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            insert_position = random.randint(0, len(arch_copy))\n",
    "            if insert_position == 0:\n",
    "                new_layer = create_random_layer()\n",
    "            else:\n",
    "                new_layer = create_random_layer(arch_copy[insert_position-1])\n",
    "            arch_copy.insert(insert_position, new_layer)\n",
    "            \n",
    "        elif mutation_type == 'remove' and len(arch_copy) > 1:\n",
    "            # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            remove_position = random.randint(0, len(arch_copy) - 1)\n",
    "            arch_copy.pop(remove_position)\n",
    "            \n",
    "        elif mutation_type == 'modify' and len(arch_copy) > 0:\n",
    "            # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            modify_position = random.randint(0, len(arch_copy) - 1)\n",
    "            layer = arch_copy[modify_position]\n",
    "            \n",
    "            if layer['layer'] == 'dense':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Dense —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "                \n",
    "            elif layer['layer'] == 'Conv1D':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Conv1D —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "                \n",
    "            elif layer['layer'] in ['RNN', 'GRU']:\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–ª–æ–∏\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['return_sequences'] = random.choice([True, False])\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        arch_copy.append(output_layer)\n",
    "        return arch_copy\n",
    "    \n",
    "    def evolve(self):\n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "        population = self.initialize_population()\n",
    "        \n",
    "        for generation in range(self.num_generations):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # –û—Ü–µ–Ω–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "            fitness_scores = self.evaluate_population(population)\n",
    "            generation_best_fitness = fitness_scores[0][0]\n",
    "            generation_best_architecture = fitness_scores[0][1]\n",
    "            generation_best_val_loss = fitness_scores[0][2]\n",
    "            generation_best_params = fitness_scores[0][3]\n",
    "            \n",
    "            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "            if generation_best_fitness < self.best_fitness:\n",
    "                self.best_fitness = generation_best_fitness\n",
    "                self.best_architecture = generation_best_architecture\n",
    "            \n",
    "            # –ó–∞–ø–∏—Å—å –∏—Å—Ç–æ—Ä–∏–∏\n",
    "            self.history.append({\n",
    "                'generation': generation,\n",
    "                'best_fitness': generation_best_fitness,\n",
    "                'best_val_loss': generation_best_val_loss,\n",
    "                'best_params': generation_best_params\n",
    "            })\n",
    "            \n",
    "            # –í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n",
    "            end_time = time.time()\n",
    "            print(f\"–ü–æ–∫–æ–ª–µ–Ω–∏–µ {generation + 1}/{self.num_generations} - –õ—É—á—à–∞—è –æ—à–∏–±–∫–∞: {generation_best_val_loss:.6f}, \"\n",
    "                  f\"–§–∏—Ç–Ω–µ—Å: {generation_best_fitness:.6f}, –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {generation_best_params}, \"\n",
    "                  f\"–í—Ä–µ–º—è: {end_time - start_time:.2f} —Å–µ–∫.\")\n",
    "            \n",
    "            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ü–∏–∫–ª–∞\n",
    "            if generation == self.num_generations - 1:\n",
    "                break\n",
    "            \n",
    "            # –û—Ç–±–æ—Ä\n",
    "            selected = self.selection(fitness_scores)\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è\n",
    "            new_population = []\n",
    "            \n",
    "            # –≠–ª–∏—Ç–∏–∑–º - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –æ—Å–æ–±–∏\n",
    "            new_population.append(generation_best_architecture)\n",
    "            \n",
    "            # –°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –∏ –º—É—Ç–∞—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–π\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(selected, k=2)\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                \n",
    "                child1 = self.mutate(child1)\n",
    "                child2 = self.mutate(child2)\n",
    "                \n",
    "                new_population.append(child1)\n",
    "                if len(new_population) < self.population_size:\n",
    "                    new_population.append(child2)\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "        final_fitness_scores = self.evaluate_population(population)\n",
    "        final_best = final_fitness_scores[0]\n",
    "        \n",
    "        if final_best[0] < self.best_fitness:\n",
    "            self.best_fitness = final_best[0]\n",
    "            self.best_architecture = final_best[1]\n",
    "            \n",
    "    def plot_evolution(self):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ —ç–≤–æ–ª—é—Ü–∏–∏\"\"\"\n",
    "        generations = [h['generation'] for h in self.history]\n",
    "        best_fitness = [h['best_fitness'] for h in self.history]\n",
    "        val_losses = [h['best_val_loss'] for h in self.history]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(generations, best_fitness, 'b-', marker='o')\n",
    "        plt.title('–≠–≤–æ–ª—é—Ü–∏—è —Ñ–∏—Ç–Ω–µ—Å-—Ñ—É–Ω–∫—Ü–∏–∏')\n",
    "        plt.xlabel('–ü–æ–∫–æ–ª–µ–Ω–∏–µ')\n",
    "        plt.ylabel('–§–∏—Ç–Ω–µ—Å (–Ω–∏–∂–µ = –ª—É—á—à–µ)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(generations, val_losses, 'r-', marker='o')\n",
    "        plt.title('–≠–≤–æ–ª—é—Ü–∏—è –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏')\n",
    "        plt.xlabel('–ü–æ–∫–æ–ª–µ–Ω–∏–µ')\n",
    "        plt.ylabel('–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (MSE)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('evolution_progress.png')\n",
    "        plt.show()\n",
    "    \n",
    "    def train_best_model(self, X_test=None, y_test=None, epochs=100, batch_size=32):\n",
    "        \"\"\"–û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return None\n",
    "            \n",
    "        print(\"–û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...\")\n",
    "        best_model = architecture_to_model(self.best_architecture, self.input_shape)\n",
    "        \n",
    "        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "        best_model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae', 'mse']\n",
    "        )\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "        best_model.summary()\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        history = best_model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(self.X_val, self.y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], 'b-')\n",
    "        plt.plot(history.history['val_loss'], 'r-')\n",
    "        plt.title('–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å')\n",
    "        plt.xlabel('–≠–ø–æ—Ö–∞')\n",
    "        plt.ylabel('–ü–æ—Ç–µ—Ä–∏ (MSE)')\n",
    "        plt.legend(['–û–±—É—á–µ–Ω–∏–µ', '–í–∞–ª–∏–¥–∞—Ü–∏—è'])\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['mae'], 'b-')\n",
    "        plt.plot(history.history['val_mae'], 'r-')\n",
    "        plt.title('–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')\n",
    "        plt.xlabel('–≠–ø–æ—Ö–∞')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend(['–û–±—É—á–µ–Ω–∏–µ', '–í–∞–ª–∏–¥–∞—Ü–∏—è'])\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã\n",
    "        if X_test is not None and y_test is not None:\n",
    "            test_results = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "            print(f\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "            print(f\"MSE: {test_results[1]:.6f}\")\n",
    "            print(f\"MAE: {test_results[0]:.6f}\")\n",
    "            \n",
    "            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            \n",
    "            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(y_test[:100], 'b-', label='–†–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
    "            plt.plot(y_pred[:100], 'r-', label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')\n",
    "            plt.title('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ vs —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
    "            plt.xlabel('–û–±—Ä–∞–∑–µ—Ü')\n",
    "            plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig('predictions.png')\n",
    "            plt.show()\n",
    "        \n",
    "        return best_model\n",
    "    \n",
    "    def save_best_architecture(self, filename='best_architecture.json'):\n",
    "        \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ —Ñ–∞–π–ª\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return\n",
    "            \n",
    "        import json\n",
    "        \n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç\n",
    "        architecture_dict = {\n",
    "            'fitness': self.best_fitness,\n",
    "            'architecture': self.best_architecture\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(architecture_dict, f, indent=4)\n",
    "            \n",
    "        print(f\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filename}\")\n",
    "    \n",
    "    def visualize_architecture(self):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–∏–¥–µ\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return\n",
    "            \n",
    "        print(\"–õ—É—á—à–∞—è –Ω–∞–π–¥–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:\")\n",
    "        print(f\"–§–∏—Ç–Ω–µ—Å: {self.best_fitness:.6f}\")\n",
    "        print(\"–°—Ç—Ä—É–∫—Ç—É—Ä–∞:\")\n",
    "        \n",
    "        for i, layer in enumerate(self.best_architecture):\n",
    "            layer_type = layer['layer']\n",
    "            \n",
    "            if layer_type == 'dense':\n",
    "                print(f\"  {i+1}. Dense: {layer.get('units')} units, activation={layer.get('activation')}\")\n",
    "                if layer.get('batch_normalization', False):\n",
    "                    print(f\"     + BatchNormalization\")\n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                print(f\"  {i+1}. Conv1D: filters={layer.get('filters')}, kernel_size={layer.get('kernel_size')}, \"\n",
    "                      f\"stride={layer.get('strides')}, activation={layer.get('activation')}\")\n",
    "                if layer.get('max_pooling'):\n",
    "                    print(f\"     + MaxPooling1D({layer.get('max_pooling')})\")\n",
    "                if layer.get('batch_normalization', False):\n",
    "                    print(f\"     + BatchNormalization\")\n",
    "                    \n",
    "            elif layer_type == 'RNN':\n",
    "                print(f\"  {i+1}. SimpleRNN: {layer.get('units')} units, activation={layer.get('activation')}, \"\n",
    "                      f\"return_sequences={layer.get('return_sequences')}\")\n",
    "                if layer.get('bidirectional', False):\n",
    "                    print(f\"     + Bidirectional\")\n",
    "                if layer.get('dropout', 0) > 0 or layer.get('recurrent_dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')}), RecurrentDropout({layer.get('recurrent_dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                print(f\"  {i+1}. GRU: {layer.get('units')} units, activation={layer.get('activation')}, \"\n",
    "                      f\"return_sequences={layer.get('return_sequences')}\")\n",
    "                if layer.get('bidirectional', False):\n",
    "                    print(f\"     + Bidirectional\")\n",
    "                if layer.get('dropout', 0) > 0 or layer.get('recurrent_dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')}), RecurrentDropout({layer.get('recurrent_dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                print(f\"  {i+1}. Flatten\")\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                print(f\"  {i+1}. GlobalAveragePooling1D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98648933-d120-4e2d-9b42-66402dfe83d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a340221-ef55-4b2d-8ddb-a674a7ef56b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124b4d1-c096-46e0-9deb-6d79f674c35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb4d44-fb0e-4e04-8f22-bb2a1e98eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GRU, SimpleRNN, Flatten, GlobalAveragePooling1D, Input\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö —Å–ª–æ–µ–≤\n",
    "def random_dense_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'dense'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    \n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_RNN_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'RNN'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_GRU_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'GRU'\n",
    "    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "    layer['activation'] = random.choice(['tanh', 'relu', 'sigmoid'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dropout'] = random.choice([0.0, 0.1, 0.2, 0.3])\n",
    "    layer['recurrent_dropout'] = random.choice([0.0, 0.1, 0.2])\n",
    "    \n",
    "    layer['bidirectional'] = random.choice([True, False])\n",
    "    layer['return_sequences'] = random.choice([True, False])\n",
    "    layer['stateful'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def random_Conv1D_layer():\n",
    "    layer = {}\n",
    "    layer['layer'] = 'Conv1D'\n",
    "    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "    layer['strides'] = random.choice([1, 2])\n",
    "    layer['padding'] = random.choice(['valid', 'same'])\n",
    "    layer['activation'] = random.choice(['relu', 'tanh', 'sigmoid', 'elu'])\n",
    "    \n",
    "    layer['kernel_regularizer'] = random.choice(['L1', 'L2', 'L1L2', None])\n",
    "    if layer['kernel_regularizer'] is not None:\n",
    "        coefs = [0.0001, 0.001, 0.01, 0.1]\n",
    "        layer['coef_regularizer'] = [random.choice(coefs), random.choice(coefs)]\n",
    "    \n",
    "    layer['dilation_rate'] = random.choice([1, 2])\n",
    "    layer['max_pooling'] = random.choice([None, 2, 3])\n",
    "    layer['batch_normalization'] = random.choice([True, False])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def create_random_layer(prev_layer=None):\n",
    "    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ª–æ–µ–≤\n",
    "    if prev_layer is None or prev_layer.get('layer') not in ['RNN', 'GRU'] or not prev_layer.get('return_sequences', False):\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    else:\n",
    "        # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–ª–æ–π - —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å return_sequences=True\n",
    "        layer_types = ['dense', 'conv1d', 'gru', 'rnn', 'flatten', 'global_avg_pooling1d']\n",
    "    \n",
    "    # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ flatten/pooling\n",
    "    if prev_layer and prev_layer.get('layer') in ['flatten', 'global_avg_pooling1d']:\n",
    "        layer_types = ['dense']\n",
    "        \n",
    "    layer_type = random.choice(layer_types)\n",
    "        \n",
    "    if layer_type == 'dense':\n",
    "        return random_dense_layer()\n",
    "    elif layer_type == 'conv1d':\n",
    "        return random_Conv1D_layer()\n",
    "    elif layer_type == 'gru':\n",
    "        return random_GRU_layer()\n",
    "    elif layer_type == 'rnn':\n",
    "        return random_RNN_layer()\n",
    "        \n",
    "    return {'layer': layer_type}\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "def generate_random_architecture(min_layers=2, max_layers=10):\n",
    "    num_layers = random.randint(min_layers, max_layers)\n",
    "    architecture = []\n",
    "    \n",
    "    # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π\n",
    "    prev_layer = None\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        new_layer = create_random_layer(prev_layer)\n",
    "        architecture.append(new_layer)\n",
    "        prev_layer = new_layer\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ —Å–ª–æ–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
    "        if i < num_layers - 1 and new_layer.get('layer') in ['Conv1D', 'RNN', 'GRU'] and \\\n",
    "           new_layer.get('return_sequences', True) and random.random() > 0.5:\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–π —É–ø–ª–æ—â–µ–Ω–∏—è –∏–ª–∏ –ø—É–ª–∏–Ω–≥–∞ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.5\n",
    "            flatten_type = random.choice(['flatten', 'global_avg_pooling1d'])\n",
    "            architecture.append({'layer': flatten_type})\n",
    "            prev_layer = {'layer': flatten_type}\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    architecture.append({\n",
    "        'layer': 'dense',\n",
    "        'units': 1,\n",
    "        'activation': 'linear'\n",
    "    })\n",
    "    \n",
    "    return architecture\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ –º–æ–¥–µ–ª—å Keras\n",
    "def architecture_to_model(architecture, input_shape):\n",
    "    model = Sequential()\n",
    "    first_layer = True\n",
    "    \n",
    "    for layer in architecture:\n",
    "        layer_type = layer['layer']\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º Input shape –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è\n",
    "        if first_layer:\n",
    "            if layer_type == 'dense':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg,\n",
    "                    input_shape=input_shape\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten(input_shape=input_shape))\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D(input_shape=input_shape))\n",
    "                \n",
    "            first_layer = False\n",
    "            \n",
    "        else:\n",
    "            # –°–ª–æ–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ\n",
    "            if layer_type == 'dense':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Dense(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                    \n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    model.add(Dropout(layer['dropout']))\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                model.add(Conv1D(\n",
    "                    filters=layer['filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer.get('strides', 1),\n",
    "                    padding=layer.get('padding', 'valid'),\n",
    "                    activation=layer['activation'],\n",
    "                    dilation_rate=layer.get('dilation_rate', 1),\n",
    "                    kernel_regularizer=reg\n",
    "                ))\n",
    "                \n",
    "                if layer.get('max_pooling'):\n",
    "                    model.add(MaxPooling1D(pool_size=layer.get('max_pooling')))\n",
    "                \n",
    "                if layer.get('batch_normalization', False):\n",
    "                    model.add(BatchNormalization())\n",
    "                \n",
    "            elif layer_type == 'RNN':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                rnn_layer = SimpleRNN(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(rnn_layer))\n",
    "                else:\n",
    "                    model.add(rnn_layer)\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                reg = None\n",
    "                if layer.get('kernel_regularizer'):\n",
    "                    reg_type = layer['kernel_regularizer']\n",
    "                    coefs = layer.get('coef_regularizer', [0.01, 0.01])\n",
    "                    \n",
    "                    if reg_type == 'L1':\n",
    "                        reg = regularizers.l1(coefs[0])\n",
    "                    elif reg_type == 'L2':\n",
    "                        reg = regularizers.l2(coefs[0])\n",
    "                    elif reg_type == 'L1L2':\n",
    "                        reg = regularizers.l1_l2(l1=coefs[0], l2=coefs[1])\n",
    "                \n",
    "                gru_layer = GRU(\n",
    "                    units=layer['units'],\n",
    "                    activation=layer['activation'],\n",
    "                    return_sequences=layer.get('return_sequences', False),\n",
    "                    stateful=layer.get('stateful', False),\n",
    "                    dropout=layer.get('dropout', 0),\n",
    "                    recurrent_dropout=layer.get('recurrent_dropout', 0),\n",
    "                    kernel_regularizer=reg\n",
    "                )\n",
    "                \n",
    "                if layer.get('bidirectional', False):\n",
    "                    model.add(Bidirectional(gru_layer))\n",
    "                else:\n",
    "                    model.add(gru_layer)\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                model.add(Flatten())\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "def evaluate_architecture(architecture, X_train, y_train, X_val, y_val, input_shape, epochs=50, batch_size=32):\n",
    "    try:\n",
    "        model = architecture_to_model(architecture, input_shape)\n",
    "        \n",
    "        # –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "        optimizer_choice = random.choice(['adam', 'rmsprop', 'sgd'])\n",
    "        learning_rate = random.choice([0.001, 0.01, 0.0001])\n",
    "        \n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_choice == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=learning_rate)\n",
    "        else:\n",
    "            optimizer = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        # Early stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        val_loss = min(history.history['val_loss'])  # –ë–µ—Ä–µ–º –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º —à—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏\n",
    "        num_params = model.count_params()\n",
    "        complexity_penalty = np.log(num_params) / 10.0  # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å\n",
    "        \n",
    "        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_score = val_loss + complexity_penalty\n",
    "        \n",
    "        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏\n",
    "        tf.keras.backend.clear_session()\n",
    "        del model\n",
    "        \n",
    "        return fitness_score, val_loss, num_params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {e}\")\n",
    "        return float('inf'), float('inf'), 0\n",
    "\n",
    "# –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º\n",
    "class GeneticNNOptimizer:\n",
    "    def __init__(self, input_shape, X_train, y_train, X_val, y_val, \n",
    "                 population_size=20, num_generations=10, \n",
    "                 mutation_rate=0.2, crossover_rate=0.7):\n",
    "        self.input_shape = input_shape\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.population_size = population_size\n",
    "        self.num_generations = num_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.best_architecture = None\n",
    "        self.best_fitness = float('inf')\n",
    "        self.history = []\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            architecture = generate_random_architecture()\n",
    "            population.append(architecture)\n",
    "        return population\n",
    "    \n",
    "    def evaluate_population(self, population):\n",
    "        fitness_scores = []\n",
    "        for architecture in population:\n",
    "            fitness, val_loss, num_params = evaluate_architecture(\n",
    "                architecture, \n",
    "                self.X_train, self.y_train, \n",
    "                self.X_val, self.y_val, \n",
    "                self.input_shape\n",
    "            )\n",
    "            fitness_scores.append((fitness, architecture, val_loss, num_params))\n",
    "        \n",
    "        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏—Å–ø–æ—Å–æ–±–ª–µ–Ω–Ω–æ—Å—Ç–∏ (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ)\n",
    "        fitness_scores.sort(key=lambda x: x[0])\n",
    "        return fitness_scores\n",
    "    \n",
    "    def selection(self, fitness_scores):\n",
    "        # –û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –æ—Å–æ–±–µ–π (—ç–ª–∏—Ç–∏–∑–º) + —Ç—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä\n",
    "        elite_count = max(1, int(self.population_size * 0.1))  # 10% —ç–ª–∏—Ç–∏–∑–º–∞\n",
    "        selected = [score[1] for score in fitness_scores[:elite_count]]\n",
    "        \n",
    "        # –¢—É—Ä–Ω–∏—Ä–Ω—ã–π –æ—Ç–±–æ—Ä –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø–æ–∑–∏—Ü–∏–π\n",
    "        while len(selected) < self.population_size:\n",
    "            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ 3 –æ—Å–æ–±–∏ –¥–ª—è —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "            tournament = random.sample(fitness_scores, k=3)\n",
    "            tournament.sort(key=lambda x: x[0])\n",
    "            selected.append(tournament[0][1])  # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –∏–∑ —Ç—É—Ä–Ω–∏—Ä–∞\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def crossover(self, parent1, parent2):\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1.copy(), parent2.copy()\n",
    "        \n",
    "        # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π (–≤—ã—Ö–æ–¥–Ω–æ–π) –ø–µ—Ä–µ–¥ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ–º\n",
    "        p1 = parent1[:-1].copy()\n",
    "        p2 = parent2[:-1].copy()\n",
    "        \n",
    "        # –û–¥–Ω–æ—Ç–æ—á–µ—á–Ω–æ–µ —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ\n",
    "        if len(p1) > 1 and len(p2) > 1:\n",
    "            crossover_point1 = random.randint(1, len(p1) - 1)\n",
    "            crossover_point2 = random.randint(1, len(p2) - 1)\n",
    "            \n",
    "            child1 = p1[:crossover_point1] + p2[crossover_point2:]\n",
    "            child2 = p2[:crossover_point2] + p1[crossover_point1:]\n",
    "        else:\n",
    "            child1, child2 = p1.copy(), p2.copy()\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        output_layer = {\n",
    "            'layer': 'dense',\n",
    "            'units': 1,\n",
    "            'activation': 'linear'\n",
    "        }\n",
    "        \n",
    "        child1.append(output_layer)\n",
    "        child2.append(output_layer)\n",
    "        \n",
    "        return child1, child2\n",
    "    \n",
    "    def mutate(self, architecture):\n",
    "        if random.random() > self.mutation_rate:\n",
    "            return architecture\n",
    "        \n",
    "        # –ö–ª–æ–Ω–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –±–µ–∑ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "        arch_copy = architecture[:-1].copy()\n",
    "        output_layer = architecture[-1].copy()\n",
    "        \n",
    "        mutation_type = random.choice(['add', 'remove', 'modify'])\n",
    "        \n",
    "        if mutation_type == 'add' and len(arch_copy) < 10:\n",
    "            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            insert_position = random.randint(0, len(arch_copy))\n",
    "            if insert_position == 0:\n",
    "                new_layer = create_random_layer()\n",
    "            else:\n",
    "                new_layer = create_random_layer(arch_copy[insert_position-1])\n",
    "            arch_copy.insert(insert_position, new_layer)\n",
    "            \n",
    "        elif mutation_type == 'remove' and len(arch_copy) > 1:\n",
    "            # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            remove_position = random.randint(0, len(arch_copy) - 1)\n",
    "            arch_copy.pop(remove_position)\n",
    "            \n",
    "        elif mutation_type == 'modify' and len(arch_copy) > 0:\n",
    "            # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–ª–æ—è\n",
    "            modify_position = random.randint(0, len(arch_copy) - 1)\n",
    "            layer = arch_copy[modify_position]\n",
    "            \n",
    "            if layer['layer'] == 'dense':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Dense —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['activation'] = random.choice(['relu', 'sigmoid', 'tanh', 'elu', 'linear'])\n",
    "                \n",
    "            elif layer['layer'] == 'Conv1D':\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º Conv1D —Å–ª–æ–π\n",
    "                if random.random() < 0.5:\n",
    "                    layer['filters'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['kernel_size'] = random.choice([3, 5, 7, 9])\n",
    "                \n",
    "            elif layer['layer'] in ['RNN', 'GRU']:\n",
    "                # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–ª–æ–∏\n",
    "                if random.random() < 0.5:\n",
    "                    layer['units'] = random.choice([32, 64, 128, 256])\n",
    "                if random.random() < 0.5:\n",
    "                    layer['return_sequences'] = random.choice([True, False])\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π\n",
    "        arch_copy.append(output_layer)\n",
    "        return arch_copy\n",
    "    \n",
    "    def evolve(self):\n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "        population = self.initialize_population()\n",
    "        \n",
    "        for generation in range(self.num_generations):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # –û—Ü–µ–Ω–∫–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏\n",
    "            fitness_scores = self.evaluate_population(population)\n",
    "            generation_best_fitness = fitness_scores[0][0]\n",
    "            generation_best_architecture = fitness_scores[0][1]\n",
    "            generation_best_val_loss = fitness_scores[0][2]\n",
    "            generation_best_params = fitness_scores[0][3]\n",
    "            \n",
    "            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "            if generation_best_fitness < self.best_fitness:\n",
    "                self.best_fitness = generation_best_fitness\n",
    "                self.best_architecture = generation_best_architecture\n",
    "            \n",
    "            # –ó–∞–ø–∏—Å—å –∏—Å—Ç–æ—Ä–∏–∏\n",
    "            self.history.append({\n",
    "                'generation': generation,\n",
    "                'best_fitness': generation_best_fitness,\n",
    "                'best_val_loss': generation_best_val_loss,\n",
    "                'best_params': generation_best_params\n",
    "            })\n",
    "            \n",
    "            # –í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n",
    "            end_time = time.time()\n",
    "            print(f\"–ü–æ–∫–æ–ª–µ–Ω–∏–µ {generation + 1}/{self.num_generations} - –õ—É—á—à–∞—è –æ—à–∏–±–∫–∞: {generation_best_val_loss:.6f}, \"\n",
    "                  f\"–§–∏—Ç–Ω–µ—Å: {generation_best_fitness:.6f}, –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {generation_best_params}, \"\n",
    "                  f\"–í—Ä–µ–º—è: {end_time - start_time:.2f} —Å–µ–∫.\")\n",
    "            \n",
    "            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ü–∏–∫–ª–∞\n",
    "            if generation == self.num_generations - 1:\n",
    "                break\n",
    "            \n",
    "            # –û—Ç–±–æ—Ä\n",
    "            selected = self.selection(fitness_scores)\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è\n",
    "            new_population = []\n",
    "            \n",
    "            # –≠–ª–∏—Ç–∏–∑–º - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –æ—Å–æ–±–∏\n",
    "            new_population.append(generation_best_architecture)\n",
    "            \n",
    "            # –°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –∏ –º—É—Ç–∞—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–π\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(selected, k=2)\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                \n",
    "                child1 = self.mutate(child1)\n",
    "                child2 = self.mutate(child2)\n",
    "                \n",
    "                new_population.append(child1)\n",
    "                if len(new_population) < self.population_size:\n",
    "                    new_population.append(child2)\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "        final_fitness_scores = self.evaluate_population(population)\n",
    "        final_best = final_fitness_scores[0]\n",
    "        \n",
    "        if final_best[0] < self.best_fitness:\n",
    "            self.best_fitness = final_best[0]\n",
    "            self.best_architecture = final_best[1]\n",
    "            \n",
    "    def plot_evolution(self):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ —ç–≤–æ–ª—é—Ü–∏–∏\"\"\"\n",
    "        generations = [h['generation'] for h in self.history]\n",
    "        best_fitness = [h['best_fitness'] for h in self.history]\n",
    "        val_losses = [h['best_val_loss'] for h in self.history]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(generations, best_fitness, 'b-', marker='o')\n",
    "        plt.title('–≠–≤–æ–ª—é—Ü–∏—è —Ñ–∏—Ç–Ω–µ—Å-—Ñ—É–Ω–∫—Ü–∏–∏')\n",
    "        plt.xlabel('–ü–æ–∫–æ–ª–µ–Ω–∏–µ')\n",
    "        plt.ylabel('–§–∏—Ç–Ω–µ—Å (–Ω–∏–∂–µ = –ª—É—á—à–µ)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(generations, val_losses, 'r-', marker='o')\n",
    "        plt.title('–≠–≤–æ–ª—é—Ü–∏—è –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏')\n",
    "        plt.xlabel('–ü–æ–∫–æ–ª–µ–Ω–∏–µ')\n",
    "        plt.ylabel('–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (MSE)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('evolution_progress.png')\n",
    "        plt.show()\n",
    "    \n",
    "    def train_best_model(self, X_test=None, y_test=None, epochs=100, batch_size=32):\n",
    "        \"\"\"–û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return None\n",
    "            \n",
    "        print(\"–û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...\")\n",
    "        best_model = architecture_to_model(self.best_architecture, self.input_shape)\n",
    "        \n",
    "        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "        best_model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae', 'mse']\n",
    "        )\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "        best_model.summary()\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        history = best_model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(self.X_val, self.y_val),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], 'b-')\n",
    "        plt.plot(history.history['val_loss'], 'r-')\n",
    "        plt.title('–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å')\n",
    "        plt.xlabel('–≠–ø–æ—Ö–∞')\n",
    "        plt.ylabel('–ü–æ—Ç–µ—Ä–∏ (MSE)')\n",
    "        plt.legend(['–û–±—É—á–µ–Ω–∏–µ', '–í–∞–ª–∏–¥–∞—Ü–∏—è'])\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['mae'], 'b-')\n",
    "        plt.plot(history.history['val_mae'], 'r-')\n",
    "        plt.title('–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')\n",
    "        plt.xlabel('–≠–ø–æ—Ö–∞')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend(['–û–±—É—á–µ–Ω–∏–µ', '–í–∞–ª–∏–¥–∞—Ü–∏—è'])\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã\n",
    "        if X_test is not None and y_test is not None:\n",
    "            test_results = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "            print(f\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "            print(f\"MSE: {test_results[1]:.6f}\")\n",
    "            print(f\"MAE: {test_results[0]:.6f}\")\n",
    "            \n",
    "            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            \n",
    "            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(y_test[:100], 'b-', label='–†–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
    "            plt.plot(y_pred[:100], 'r-', label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')\n",
    "            plt.title('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ vs —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
    "            plt.xlabel('–û–±—Ä–∞–∑–µ—Ü')\n",
    "            plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig('predictions.png')\n",
    "            plt.show()\n",
    "        \n",
    "        return best_model\n",
    "    \n",
    "    def save_best_architecture(self, filename='best_architecture.json'):\n",
    "        \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ —Ñ–∞–π–ª\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return\n",
    "            \n",
    "        import json\n",
    "        \n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç\n",
    "        architecture_dict = {\n",
    "            'fitness': self.best_fitness,\n",
    "            'architecture': self.best_architecture\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(architecture_dict, f, indent=4)\n",
    "            \n",
    "        print(f\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filename}\")\n",
    "    \n",
    "    def visualize_architecture(self):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ª—É—á—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–∏–¥–µ\"\"\"\n",
    "        if self.best_architecture is None:\n",
    "            print(\"–õ—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ evolve().\")\n",
    "            return\n",
    "            \n",
    "        print(\"–õ—É—á—à–∞—è –Ω–∞–π–¥–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:\")\n",
    "        print(f\"–§–∏—Ç–Ω–µ—Å: {self.best_fitness:.6f}\")\n",
    "        print(\"–°—Ç—Ä—É–∫—Ç—É—Ä–∞:\")\n",
    "        \n",
    "        for i, layer in enumerate(self.best_architecture):\n",
    "            layer_type = layer['layer']\n",
    "            \n",
    "            if layer_type == 'dense':\n",
    "                print(f\"  {i+1}. Dense: {layer.get('units')} units, activation={layer.get('activation')}\")\n",
    "                if layer.get('batch_normalization', False):\n",
    "                    print(f\"     + BatchNormalization\")\n",
    "                if layer.get('dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'Conv1D':\n",
    "                print(f\"  {i+1}. Conv1D: filters={layer.get('filters')}, kernel_size={layer.get('kernel_size')}, \"\n",
    "                      f\"stride={layer.get('strides')}, activation={layer.get('activation')}\")\n",
    "                if layer.get('max_pooling'):\n",
    "                    print(f\"     + MaxPooling1D({layer.get('max_pooling')})\")\n",
    "                if layer.get('batch_normalization', False):\n",
    "                    print(f\"     + BatchNormalization\")\n",
    "                    \n",
    "            elif layer_type == 'RNN':\n",
    "                print(f\"  {i+1}. SimpleRNN: {layer.get('units')} units, activation={layer.get('activation')}, \"\n",
    "                      f\"return_sequences={layer.get('return_sequences')}\")\n",
    "                if layer.get('bidirectional', False):\n",
    "                    print(f\"     + Bidirectional\")\n",
    "                if layer.get('dropout', 0) > 0 or layer.get('recurrent_dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')}), RecurrentDropout({layer.get('recurrent_dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'GRU':\n",
    "                print(f\"  {i+1}. GRU: {layer.get('units')} units, activation={layer.get('activation')}, \"\n",
    "                      f\"return_sequences={layer.get('return_sequences')}\")\n",
    "                if layer.get('bidirectional', False):\n",
    "                    print(f\"     + Bidirectional\")\n",
    "                if layer.get('dropout', 0) > 0 or layer.get('recurrent_dropout', 0) > 0:\n",
    "                    print(f\"     + Dropout({layer.get('dropout')}), RecurrentDropout({layer.get('recurrent_dropout')})\")\n",
    "                    \n",
    "            elif layer_type == 'flatten':\n",
    "                print(f\"  {i+1}. Flatten\")\n",
    "                \n",
    "            elif layer_type == 'global_avg_pooling1d':\n",
    "                print(f\"  {i+1}. GlobalAveragePooling1D\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3da7f-3f12-4ae1-a625-19650884a7af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
